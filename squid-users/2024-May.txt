From squid3 at treenet.co.nz  Thu May  2 05:35:49 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 2 May 2024 17:35:49 +1200
Subject: [squid-users] Best way to utilize time constraints with squid?
In-Reply-To: <D8D0997C-83B8-4707-B770-BBC76FE167AB@gmail.com>
References: <D2550F6D-B0A6-4D9C-A9B3-17B6189ACA6B@gmail.com>
 <D8D0997C-83B8-4707-B770-BBC76FE167AB@gmail.com>
Message-ID: <2a514ca9-41e6-4a56-96cd-0702df184fc0@treenet.co.nz>

Hi Jonathan,

There may be some misunderstanding of what I wrote earlier..

  "time" is just a check of the machine clock. When ACLs are checked it 
is always expected to work.


The problem I was referring to was that ssl_bump and https_access ACLs 
are *not* checked for already active connections. Only for new 
connections as they are setup.

For example; CONNECT tunnel and/or HTTPS connections might start on 
Monday and stay open and used until Friday.


HTH
Amos



On 30/04/24 04:54, Jonathan Lee wrote:
> Squid -k parse also does not fail with use of the time ACL
> Sent from my iPhone
> 
>> On Apr 27, 2024, at 07:49, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>
>> ?The time constraints for termination do appear to lock out all new connections until that timeframe has elapsed. My devices have connection errors during this duration.
>>
>> Just to confirm ssl_bump can not be used with time ? Because my connections don?t work during the timeframe so that is a plus.
>>
>>
>> Sent from my iPhone
>>
>>>> On Apr 27, 2024, at 00:41, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>>
>>>> ?On 26/04/24 17:15, Jonathan Lee wrote:
>>>> aclblock_hourstime01:30-05:00ssl_bumpterminateallblock_hourshttp_accessdenyallblock_hours
>>>> In this a good way to time lock squid with times lock down?
>>>
>>> That depends on your criteria/definition of "good".
>>>
>>> Be aware that http_access only checks *new* transactions. Large downloads, and long-running transactions such as CONNECT tunnel which start during an allowed time will continue running across the disallowed time(s).
>>>
>>>
>>>> To essentially terminate all connections and block http access.
>>>
>>> The "terminate all connections" is not enforced by 'time` ACL. Once a transaction is allowed to start, it can continue until completion - be that milliseconds or days later.
>>>
>>>
>>> HTH
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Thu May  2 20:18:42 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 2 May 2024 16:18:42 -0400
Subject: [squid-users] Error from icap during respmod
In-Reply-To: <166088187.5074521.1714410400274@mail.yahoo.com>
References: <166088187.5074521.1714410400274.ref@mail.yahoo.com>
 <166088187.5074521.1714410400274@mail.yahoo.com>
Message-ID: <6ad59ee8-714a-48d3-bfec-a8d239bade05@measurement-factory.com>

On 2024-04-29 13:06, Arun Kumar wrote:
> Configured python based icap server (pyicap) and getting 500 Internal 
> Server error during respmod.

AFAICT, this ICAP RESPMOD service is buggy: It sends what looks like an 
HTTP response body chunk after sending an ICAP 100 Continue control 
message. Instead, it is supposed to send the final ICAP response headers 
and HTTP response headers _before_ sending that HTTP response body chunk.


     00:50:54.989 ... ReadNow: conn33 ... size 65535, retval 25
     ICAP/1.0 100 Continue


     00:50:54.991 ReadNow: conn33 ... size 65535, retval 137
     83
     {"activity":...}


HTH,

Alex.

> https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing <https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing>
> 
> Squid configuration:
> icap_enable on
> icap_send_client_ip on
> icap_send_client_username on
> icap_client_username_encode off
> icap_client_username_header X-Authenticated-User
> icap_preview_enable on
> icap_preview_size 1024
> 
> icap_service service_req reqmod_precache bypass=0 
> icap://127.0.0.1:13440/example
> icap_service service_resp respmod_precache bypass=0 
> icap://127.0.0.1:13441/example
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Thu May  2 21:07:00 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 2 May 2024 17:07:00 -0400
Subject: [squid-users] Error during ICAP RESPMOD
In-Reply-To: <37699563.3545988.1714008214587@mail.yahoo.com>
References: <334246463.6454176.1710802007981.ref@mail.yahoo.com>
 <334246463.6454176.1710802007981@mail.yahoo.com>
 <400fe870-9742-4fd8-a66e-22a9b281c932@measurement-factory.com>
 <283160880.349514.1711127497866@mail.yahoo.com>
 <9d34831b-1f9c-41d0-b123-e022c872ecc9@measurement-factory.com>
 <2101931183.3556436.1714007783880@mail.yahoo.com>
 <37699563.3545988.1714008214587@mail.yahoo.com>
Message-ID: <92f96450-59f2-44c9-8d81-44d0b02fb294@measurement-factory.com>

On 2024-04-24 21:23, Arun Kumar wrote:
> I managed to reproduce the problem in my personal setup. Please find the 
> cache logs when the problem is reproduced. Squid version is 5.8

Just to close this old thread: My response[1] on a newer thread 
(analyzing the same log file you shared on this thread) supports and 
details the "HTTP body instead of an ICAP response header" theory I 
suggested further below (before you shared that log file).

[1]:
https://lists.squid-cache.org/pipermail/squid-users/2024-May/026634.html

Alex.


> On Friday, March 22, 2024 at 11:02:51 PM EDT, Alex Rousskov wrote:
> 
> 
> On 2024-03-22 13:11, Arun Kumar wrote:
>  > The lines above are. The content-length is 138 (8a in hex), but the
>  > bytes are 144. Could this be the reason?
>  >
>  > parseMore: have 144 bytes to parse [FD 14;RBG/Comm(14)wr job24]
>  > parseMore:
>  > 8a^M
>  > {"activity":"Make a simple musical
>  > 
> instrument","type":"music","participants":1,"price:0.4,"link":"","key":"7091374","accessibility":0.25}^M
>  > parseHeaders: parse ICAP headers
>  > parsePart: have 144 head bytes to parse; state: 0
>  > parsePart: head parsing result: 0 detail: 600
> 
> 
> I cannot be sure based on the tiny snippets shared so far, but it
> _looks_ like Squid expected an ICAP response header and got an ICAP
> response body chunk instead. It is also possible that we are looking at
> log lines from two unrelated ICAP transactions, or I am simply
> misinterpreting the snippets.
> 
> If you want a more reliable diagnosis, then my earlier recommendation
> regarding sharing (privately if needed) the following information still
> stands:
> 
> * compressed ALL,9 cache.log and
> * the problematic ICAP response in a raw packet capture format.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
>  > On Monday, March 18, 2024 at 11:21:02 PM EDT, Alex Rousskov
>  > <rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>> wrote:
>  >
>  >
>  > On 2024-03-18 18:46, Arun Kumar wrote:
>  >
>  >? > Any idea, the reason for error in ModXact.cc parsePart fuction.
>  >? > Happening during parsing the response from ICAP
>  >? >
>  >? >
>  >? > parsePart: have 144 head bytes to parse; state: 0
>  >? > parsePart: head parsing result: 0 detail: 600
>  >
>  >
>  > AFAICT, Squid considers received ICAP response header malformed. More
>  > than five possible problems/cases may match the above lines. The answer
>  > to your question (or an additional clue!) is in different debugging
>  > output, possibly logged somewhere between the two lines quoted above.
>  > The right debugging lines may be visible in "debug_options ALL,2 58,5,
>  > 93,5" output, but it is usually best to share compressed ALL,9 logs
>  > (privately if needed).
>  >
>  > 
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>
>  >
>  >
>  > Sharing the problematic ICAP response (header) in a raw packet capture
>  > format (to preserve important details) may also be very useful.
>  >
>  >
>  > HTH,
>  >
>  > Alex.
>  >
>  >
> 



From emreoksum at gmail.com  Fri May  3 14:29:11 2024
From: emreoksum at gmail.com (Emre Oksum)
Date: Fri, 3 May 2024 17:29:11 +0300
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
Message-ID: <CADG8LiXv1ZsY_KyhxOCgfj0oFT0A4oFZsm89uZHk8OAnUKF+0g@mail.gmail.com>

 Hi everyone,

I'm having a issue with Squid Cache 4.10 which I cannot fix for weeks now
and kinda lost at the moment. I will be appreciated if someone can guide me
through the issue I'm having.
I need to create a IPv6 HTTP proxy which should match the entry address to
outgoing TCP address. For example, if user is connecting from fe80:abcd::1
it should exit the HTTP proxy from the same address. We got like 50k
addresses like this at the moment.
The issue is, client connecting to the proxy is receiving "EOF" or
"FLOW_CONTROL_ERROR" on their side. When I test connection by connecting to
whatismyip.com everything works fine and entry IP always matches with
outgoing IP for each of the 50k addresses. Client tells me this problem
occurs both at GET and POST requests with around 10 MB of data.
I initially thought that could be related to server resources being drained
but upon inspecting server resource usage, Squid isn't even topping at 100%
CPU or RAM anytime so not that.

My Squid.conf is like this at the moment:

auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwd
acl auth_users proxy_auth REQUIRED
http_access allow auth_users
http_access deny !auth_users
cache deny all
dns_nameservers <nameservers here>
dns_v4_first off
via off
forwarded_for delete
follow_x_forwarded_for deny all
server_persistent_connections off
max_filedesc 1048576
max_filedescriptors 1048576
workers 8
http_port [::0]:1182
acl binding1 myip  fe80:abcd::1
tcp_outgoing_address  fe80:abcd::1 binding1
acl binding2 myip  fe80:abcd::2
tcp_outgoing_address  fe80:abcd::2 binding2
acl binding3 myip  fe80:abcd::3
tcp_outgoing_address  fe80:abcd::3 binding3
...
...
...
access_log /var/log/squid/access.log squid
cache_store_log none
cache deny all

I've tried to get a PCAP file and realized when client tries to connect
with a new IPv6 address, Squid is not trying to open a new connection
instead tries to resume a previously opened one on a different outgoing
IPv6 address. I set server_persistent_connections off which should have
disabled this behavior but it's still the same. I tried using a newer
version of Squid but it behaved differently and did not follow my outgoing
address specifications and kept connecting on IPv4.

I would be appreciated if someone can help me out here.
Thank you.
Emre
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240503/1c293605/attachment.htm>

From squid3 at treenet.co.nz  Fri May  3 16:31:25 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 4 May 2024 04:31:25 +1200
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <CADG8LiXv1ZsY_KyhxOCgfj0oFT0A4oFZsm89uZHk8OAnUKF+0g@mail.gmail.com>
References: <CADG8LiXv1ZsY_KyhxOCgfj0oFT0A4oFZsm89uZHk8OAnUKF+0g@mail.gmail.com>
Message-ID: <0fafca47-b7fe-460c-8f42-3f15f89f1f26@treenet.co.nz>

On 4/05/24 02:29, Emre Oksum wrote:
> Hi everyone,
> 
> I'm having a issue with Squid Cache 4.10 which I cannot fix for weeks 
> now and kinda lost at the moment. I will be appreciated if someone can 
> guide me through the issue I'm having.
> I need to create a IPv6 HTTP proxy which should match the entry address 
> to outgoing TCP address. For example, if user is connecting from 
> fe80:abcd::1 it should exit the HTTP proxy from the same address. We got 
> like 50k addresses like this at the moment.

What your "for example,..." describes is Transparent Proxy (TPROXY).


However, what you have in the config below is very different. The IP the 
client is connected **to** (not "from") is being pinned on outgoing 
connections.


> The issue is, client connecting to the proxy is receiving "EOF" or 
> "FLOW_CONTROL_ERROR" on their side.

The FLOW_CONTROL_ERROR is not something produced by Squid. Likely it 
comes from the TCP stack and/or OS routing system.

The EOF may be coming from either Squid or the OS. It also may be 
perfectly normal for the circumstances, or a side effect of an error 
elsewhere.


To solve will require identifying exactly what is sending those signals, 
and why. Since they are signals going to the client, focus on the 
client->Squid connections (not the Squid->server ones you talk about 
testing below).



> When I test connection by connecting 
> to whatismyip.com <http://whatismyip.com> everything works fine and 
> entry IP always matches with outgoing IP for each of the 50k addresses. 
> Client tells me this problem occurs both at GET and POST requests with 
> around 10 MB of data.

Well, you are trying to manually force certain flow patterns that 
prohibit or break some major HTTP performance features. Some problems 
are to be expected.

The issues which I expect to occur in your proxy would not show up in a 
trivial outgoing-IP or connectivity test.


> I initially thought that could be related to server resources being 
> drained but upon inspecting server resource usage, Squid isn't even 
> topping at 100% CPU or RAM anytime so not that.
> 

IMO, "FLOW_CONTROL_ERROR" is likely related to quantity of traffic 
flooding through the proxy to specific origin servers.

The concept you are implementing of the outgoing TCP connection having 
the same IP as the incoming connection reduces the available TCP sockets 
by 25%. Prohibiting the OS from allocating ports on otherwise unused 
outgoing addresses when



> My Squid.conf is like this at the moment:

Some improvements highlighted inline below.
Nothing stands out to me as being related to your issues.

> 
> auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwd
> acl auth_users proxy_auth REQUIRED
> http_access allow auth_users
> http_access deny !auth_users

Above two lines are backwards. Deny first, then allow.


> cache deny all
> dns_nameservers <nameservers here>
> dns_v4_first off
> via off
> forwarded_for delete
> follow_x_forwarded_for deny all
> server_persistent_connections off

*If* the issue turns out to be congestion on Squid->server connections
enabling this might be worthwhile. Otherwise it should be fine.


> max_filedesc 1048576

You can remove that line. "max_filedesc" was a RedHat hack from 20+ 
years ago when the feature was experimental.

Any value you set on the line above, will be erased and replaced by the 
line below:


> max_filedescriptors 1048576
> workers 8
> http_port [::0]:1182

Above is just a complicated way to write:

  http_port 1182


Any particular reason not to use the registered port 3128 ?
(Not important, just wondering.)


> acl binding1 myip fe80:abcd::1
> tcp_outgoing_address fe80:abcd::1 binding1
> acl binding2 myip fe80:abcd::2
> tcp_outgoing_address fe80:abcd::2 binding2
> acl binding3 myip fe80:abcd::3
> tcp_outgoing_address fe80:abcd::3 binding3
> ...
> ...
> ...
> access_log /var/log/squid/access.log squid

> cache_store_log none

You can erase this line.
This is default setting. No need to manually set it.


> cache deny all

You can erase this line.
This "cache deny all" exists earlier in the config.


> 
> I've tried to get a PCAP file and realized when client tries to connect 
> with a new IPv6 address, Squid is not trying to open a new connection 
> instead tries to resume a previously opened one on a different outgoing 
> IPv6 address.

Can you provide the trace demonstrating that issue?

Although, as noted earlier your problems are apparently on the client 
connections. This is about server connections behaviour.


> I set server_persistent_connections off which should have 
> disabled this behavior but it's still the same.

Nod. Yes that should forbid re-use of connections.

I/we will need to see the PCAP trace along with a cache.log generated 
using "debug_options ALL,6" to confirm a bug or identify other breakage 
though.



> I tried using a newer 
> version of Squid but it behaved differently and did not follow my 
> outgoing address specifications and kept connecting on IPv4.

That would seem to indicate that your IPv4 connectivity is better than 
your IPv6 connectivity. Later Squid use various "Happy Eyeballs" 
implementations for the server selection.

You can usually work around this by configuring the DNS server specified 
by dns_nameservers to only deliver IPv6 results when a mixed set are 
available.


HTH
Amos


From emreoksum at gmail.com  Fri May  3 17:36:44 2024
From: emreoksum at gmail.com (Emre Oksum)
Date: Fri, 3 May 2024 20:36:44 +0300
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <0fafca47-b7fe-460c-8f42-3f15f89f1f26@treenet.co.nz>
References: <CADG8LiXv1ZsY_KyhxOCgfj0oFT0A4oFZsm89uZHk8OAnUKF+0g@mail.gmail.com>
 <0fafca47-b7fe-460c-8f42-3f15f89f1f26@treenet.co.nz>
Message-ID: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>

Hi Amos, thank you for your reply.

>What your "for example,..." describes is Transparent Proxy (TPROXY).
>However, what you have in the config below is very different. The IP the
>client is connected **to** (not "from") is being pinned on outgoing
>connections.

Sorry for the misunderstanding. Maybe I wasn't clear with my wording. I
only need to create a proxy instance where the IPv6 address that client
uses to connect to Squid, is used by Squid to connect to remote locations.
In this setup, server running Squid has around 50k IPv6 addresses assigned
to it and client is expected to connect to Squid proxy with 50k different
IPv6 addresses of the Squid and Squid should always use the IP address
client connects to it as outgoing address. I'm not sure if I explained that
well.

So if client connects to Squid proxy by the address of Squid let's say is
feef:1234::1, Squid should use that IP for outgoing connections. That's not
transparent proxy TPROXY because client and proxy is on different networks
in this setup. Just like ordinary HTTP proxies.

>The FLOW_CONTROL_ERROR is not something produced by Squid. Likely it
>comes from the TCP stack and/or OS routing system.
Client connects to Squid by a script written in Golang. Thats where they
get that error. On the Squid's access.log, I can see that error as
TCP_TUNNEL_ABORTED/200

>Some improvements highlighted inline below.
>Nothing stands out to me as being related to your issues.
Thank you, I'll fix them however I don't think this issue is any related to
the config.

>Any particular reason not to use the registered port 3128 ?
>(Not important, just wondering.)
My client wants to prevent proxies from being detected by bots so we picked
a different port number but it's not the one I shared here. I edited
numbers and addresses from the config before sharing it here.

>I/we will need to see the PCAP trace along with a cache.log generated
>using "debug_options ALL,6" to confirm a bug or identify other breakage
>though.
Interestingly, debug_options ALL does not log anything related to this
issue to cache.log. That left me very confused about this problem.
I'm currently sending you the PCAP file. It's being uploaded. I would be
appreciated if you can take a look at it.

Thanks
Amos Jeffries <squid3 at treenet.co.nz>, 3 May 2024 Cum, 19:31 tarihinde ?unu
yazd?:

> On 4/05/24 02:29, Emre Oksum wrote:
> > Hi everyone,
> >
> > I'm having a issue with Squid Cache 4.10 which I cannot fix for weeks
> > now and kinda lost at the moment. I will be appreciated if someone can
> > guide me through the issue I'm having.
> > I need to create a IPv6 HTTP proxy which should match the entry address
> > to outgoing TCP address. For example, if user is connecting from
> > fe80:abcd::1 it should exit the HTTP proxy from the same address. We got
> > like 50k addresses like this at the moment.
>
> What your "for example,..." describes is Transparent Proxy (TPROXY).
>
>
> However, what you have in the config below is very different. The IP the
> client is connected **to** (not "from") is being pinned on outgoing
> connections.
>
>
> > The issue is, client connecting to the proxy is receiving "EOF" or
> > "FLOW_CONTROL_ERROR" on their side.
>
> The FLOW_CONTROL_ERROR is not something produced by Squid. Likely it
> comes from the TCP stack and/or OS routing system.
>
> The EOF may be coming from either Squid or the OS. It also may be
> perfectly normal for the circumstances, or a side effect of an error
> elsewhere.
>
>
> To solve will require identifying exactly what is sending those signals,
> and why. Since they are signals going to the client, focus on the
> client->Squid connections (not the Squid->server ones you talk about
> testing below).
>
>
>
> > When I test connection by connecting
> > to whatismyip.com <http://whatismyip.com> everything works fine and
> > entry IP always matches with outgoing IP for each of the 50k addresses.
> > Client tells me this problem occurs both at GET and POST requests with
> > around 10 MB of data.
>
> Well, you are trying to manually force certain flow patterns that
> prohibit or break some major HTTP performance features. Some problems
> are to be expected.
>
> The issues which I expect to occur in your proxy would not show up in a
> trivial outgoing-IP or connectivity test.
>
>
> > I initially thought that could be related to server resources being
> > drained but upon inspecting server resource usage, Squid isn't even
> > topping at 100% CPU or RAM anytime so not that.
> >
>
> IMO, "FLOW_CONTROL_ERROR" is likely related to quantity of traffic
> flooding through the proxy to specific origin servers.
>
> The concept you are implementing of the outgoing TCP connection having
> the same IP as the incoming connection reduces the available TCP sockets
> by 25%. Prohibiting the OS from allocating ports on otherwise unused
> outgoing addresses when
>
>
>
> > My Squid.conf is like this at the moment:
>
> Some improvements highlighted inline below.
> Nothing stands out to me as being related to your issues.
>
> >
> > auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwd
> > acl auth_users proxy_auth REQUIRED
> > http_access allow auth_users
> > http_access deny !auth_users
>
> Above two lines are backwards. Deny first, then allow.
>
>
> > cache deny all
> > dns_nameservers <nameservers here>
> > dns_v4_first off
> > via off
> > forwarded_for delete
> > follow_x_forwarded_for deny all
> > server_persistent_connections off
>
> *If* the issue turns out to be congestion on Squid->server connections
> enabling this might be worthwhile. Otherwise it should be fine.
>
>
> > max_filedesc 1048576
>
> You can remove that line. "max_filedesc" was a RedHat hack from 20+
> years ago when the feature was experimental.
>
> Any value you set on the line above, will be erased and replaced by the
> line below:
>
>
> > max_filedescriptors 1048576
> > workers 8
> > http_port [::0]:1182
>
> Above is just a complicated way to write:
>
>   http_port 1182
>
>
> Any particular reason not to use the registered port 3128 ?
> (Not important, just wondering.)
>
>
> > acl binding1 myip fe80:abcd::1
> > tcp_outgoing_address fe80:abcd::1 binding1
> > acl binding2 myip fe80:abcd::2
> > tcp_outgoing_address fe80:abcd::2 binding2
> > acl binding3 myip fe80:abcd::3
> > tcp_outgoing_address fe80:abcd::3 binding3
> > ...
> > ...
> > ...
> > access_log /var/log/squid/access.log squid
>
> > cache_store_log none
>
> You can erase this line.
> This is default setting. No need to manually set it.
>
>
> > cache deny all
>
> You can erase this line.
> This "cache deny all" exists earlier in the config.
>
>
> >
> > I've tried to get a PCAP file and realized when client tries to connect
> > with a new IPv6 address, Squid is not trying to open a new connection
> > instead tries to resume a previously opened one on a different outgoing
> > IPv6 address.
>
> Can you provide the trace demonstrating that issue?
>
> Although, as noted earlier your problems are apparently on the client
> connections. This is about server connections behaviour.
>
>
> > I set server_persistent_connections off which should have
> > disabled this behavior but it's still the same.
>
> Nod. Yes that should forbid re-use of connections.
>
> I/we will need to see the PCAP trace along with a cache.log generated
> using "debug_options ALL,6" to confirm a bug or identify other breakage
> though.
>
>
>
> > I tried using a newer
> > version of Squid but it behaved differently and did not follow my
> > outgoing address specifications and kept connecting on IPv4.
>
> That would seem to indicate that your IPv4 connectivity is better than
> your IPv6 connectivity. Later Squid use various "Happy Eyeballs"
> implementations for the server selection.
>
> You can usually work around this by configuring the DNS server specified
> by dns_nameservers to only deliver IPv6 results when a mixed set are
> available.
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240503/950af113/attachment.htm>

From jonathanlee571 at gmail.com  Fri May  3 19:58:37 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 3 May 2024 12:58:37 -0700
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
Message-ID: <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240503/8506a637/attachment.htm>

From Josh.Piana at hexcel.com  Fri May  3 19:59:17 2024
From: Josh.Piana at hexcel.com (Piana, Josh)
Date: Fri, 3 May 2024 19:59:17 +0000
Subject: [squid-users] Linux Noob - Squid Config
Message-ID: <4e3f328f76fd460f83c2259e5dad8b57@hexcel.com>

Hey Everyone.

I apologize in advance for any lack of formality normally shared on mailing lists such as these, it's my first time seeking product support in this manner.

I want to start by saying that I'm new to Linux, been using Windows environments my entire life. Such is the reason for me reaching out to you all.

I have been tasked with modernizing a Squid box and feel very overwhelmed, to say the least.

Current Setup:

? CentOS 5.0

? Squid 2.3

? Apache 2.0.46

? Samba 3.0.9

Desired Setup:

? RHEL 9.2 OS

? Needs to qualify for NTLM authentication

? Would like to remove legacy apps/services

? Continue to authenticate outgoing communication via AD

My question is, how do I get all of these services/apps to work together? Do I just install the newest versions of each and migrate the existing config files?

I was hoping for a better understanding on how all of these work together and exactly how to configure or edit these as needed. I've gotten as far as installing RHEL 9.2 on a fresh VM Server and trying as best as I can to learn the basics on Linux and just the general operation of a Linux ran environment. It feels like trying to ride a bike with box wheels.

Thank you in advance for any direction or support,
Josh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240503/93b84521/attachment.htm>

From squid3 at treenet.co.nz  Fri May  3 20:20:38 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 4 May 2024 08:20:38 +1200
Subject: [squid-users] Linux Noob - Squid Config
In-Reply-To: <4e3f328f76fd460f83c2259e5dad8b57@hexcel.com>
References: <4e3f328f76fd460f83c2259e5dad8b57@hexcel.com>
Message-ID: <65e0a341-dec2-4ee9-8c20-e1074a7949c8@treenet.co.nz>

On 4/05/24 07:59, Piana, Josh wrote:
> Hey Everyone.
> 
> I apologize in advance for any lack of formality normally shared on 
> mailing lists such as these, it?s my first time seeking product support 
> in this manner.
> 

NO need to apologize. Help and questions is most of what we do here :-)


> I want to start by saying that I?m new to Linux, been using Windows 
> environments my entire life. Such is the reason for me reaching out to 
> you all.
> 
> I have been tasked with modernizing a Squid box and feel very 
> overwhelmed, to say the least.
> 
> Current Setup:
> 
> ?CentOS 5.0
> 
> ?Squid 2.3
> 
> ?Apache 2.0.46
> 
> ?Samba 3.0.9
> 
> Desired Setup:
> 
> ?RHEL 9.2 OS
> 
> ?Needs to qualify for NTLM authentication
> 

Hmm, does it *have* to be NTLM? that auth protocol was deprecated in 2006.


> ?Would like to remove legacy apps/services
> 
> ?Continue to authenticate outgoing communication via AD
> 
> My question is, how do I get all of these services/apps to work 
> together? Do I just install the newest versions of each and migrate the 
> existing config files?
> 
> I was hoping for a better understanding on how all of these work 
> together and exactly how to configure or edit these as needed. I?ve 
> gotten as far as installing RHEL 9.2 on a fresh VM Server and trying as 
> best as I can to learn the basics on Linux and just the general 
> operation of a Linux ran environment. It feels like trying to ride a 
> bike with box wheels.
> 


The installation of a basic Squid service for RHEL is easy.
Just open a terminal and enter this command:

    yum install squid


The next part is going over your old Squid configuration to see how much 
of it remains necessary or can be updated. It would be useful for the 
next steps to copy it to the RHEL machine as /etc/squid/squid.conf.old .

You can likely find it on the CentOS machine at /etc/squid/squid.conf or 
/usr/share/squid/etc/squid.conf depending on how that Squid was built.


If you are able to paste the contents of that file (without the '#' 
comment or empty lines) here, we can assist with getting the new Squid 
doing the same or equivalent actions.


Also please paste the output of "squid -v" run on both the old CentOS 
machine and on the new RHEL.


Cheers
Amos


From emreoksum at gmail.com  Fri May  3 20:33:51 2024
From: emreoksum at gmail.com (Emre Oksum)
Date: Fri, 3 May 2024 23:33:51 +0300
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
 <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
Message-ID: <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>

Hi Jonathan,

>> Have you attempted to enable debugging ??
Yes, debugging was enabled but as I have pointed out, unfortunately it
didn't give any information about the issue.
Maybe I was missing something? I don't know. debug_options was ALL in my
squid.conf.

Thanks

Jonathan Lee <jonathanlee571 at gmail.com>, 3 May 2024 Cum, 23:00 tarihinde
?unu yazd?:

> Have you attempted to enable debugging ??
>
> Researching debug_options I found you can control detailed messages in the
> cache.log
> Sent from my iPhone
>
> On May 3, 2024, at 10:37, Emre Oksum <emreoksum at gmail.com> wrote:
>
> ?
> Hi Amos, thank you for your reply.
>
> >What your "for example,..." describes is Transparent Proxy (TPROXY).
> >However, what you have in the config below is very different. The IP the
> >client is connected **to** (not "from") is being pinned on outgoing
> >connections.
>
> Sorry for the misunderstanding. Maybe I wasn't clear with my wording. I
> only need to create a proxy instance where the IPv6 address that client
> uses to connect to Squid, is used by Squid to connect to remote locations.
> In this setup, server running Squid has around 50k IPv6 addresses assigned
> to it and client is expected to connect to Squid proxy with 50k different
> IPv6 addresses of the Squid and Squid should always use the IP address
> client connects to it as outgoing address. I'm not sure if I explained that
> well.
>
> So if client connects to Squid proxy by the address of Squid let's say is
> feef:1234::1, Squid should use that IP for outgoing connections. That's not
> transparent proxy TPROXY because client and proxy is on different networks
> in this setup. Just like ordinary HTTP proxies.
>
> >The FLOW_CONTROL_ERROR is not something produced by Squid. Likely it
> >comes from the TCP stack and/or OS routing system.
> Client connects to Squid by a script written in Golang. Thats where they
> get that error. On the Squid's access.log, I can see that error as
> TCP_TUNNEL_ABORTED/200
>
> >Some improvements highlighted inline below.
> >Nothing stands out to me as being related to your issues.
> Thank you, I'll fix them however I don't think this issue is any related
> to the config.
>
> >Any particular reason not to use the registered port 3128 ?
> >(Not important, just wondering.)
> My client wants to prevent proxies from being detected by bots so we
> picked a different port number but it's not the one I shared here. I edited
> numbers and addresses from the config before sharing it here.
>
> >I/we will need to see the PCAP trace along with a cache.log generated
> >using "debug_options ALL,6" to confirm a bug or identify other breakage
> >though.
> Interestingly, debug_options ALL does not log anything related to this
> issue to cache.log. That left me very confused about this problem.
> I'm currently sending you the PCAP file. It's being uploaded. I would be
> appreciated if you can take a look at it.
>
> Thanks
> Amos Jeffries <squid3 at treenet.co.nz>, 3 May 2024 Cum, 19:31 tarihinde
> ?unu yazd?:
>
>> On 4/05/24 02:29, Emre Oksum wrote:
>> > Hi everyone,
>> >
>> > I'm having a issue with Squid Cache 4.10 which I cannot fix for weeks
>> > now and kinda lost at the moment. I will be appreciated if someone can
>> > guide me through the issue I'm having.
>> > I need to create a IPv6 HTTP proxy which should match the entry address
>> > to outgoing TCP address. For example, if user is connecting from
>> > fe80:abcd::1 it should exit the HTTP proxy from the same address. We
>> got
>> > like 50k addresses like this at the moment.
>>
>> What your "for example,..." describes is Transparent Proxy (TPROXY).
>>
>>
>> However, what you have in the config below is very different. The IP the
>> client is connected **to** (not "from") is being pinned on outgoing
>> connections.
>>
>>
>> > The issue is, client connecting to the proxy is receiving "EOF" or
>> > "FLOW_CONTROL_ERROR" on their side.
>>
>> The FLOW_CONTROL_ERROR is not something produced by Squid. Likely it
>> comes from the TCP stack and/or OS routing system.
>>
>> The EOF may be coming from either Squid or the OS. It also may be
>> perfectly normal for the circumstances, or a side effect of an error
>> elsewhere.
>>
>>
>> To solve will require identifying exactly what is sending those signals,
>> and why. Since they are signals going to the client, focus on the
>> client->Squid connections (not the Squid->server ones you talk about
>> testing below).
>>
>>
>>
>> > When I test connection by connecting
>> > to whatismyip.com <http://whatismyip.com> everything works fine and
>> > entry IP always matches with outgoing IP for each of the 50k addresses.
>> > Client tells me this problem occurs both at GET and POST requests with
>> > around 10 MB of data.
>>
>> Well, you are trying to manually force certain flow patterns that
>> prohibit or break some major HTTP performance features. Some problems
>> are to be expected.
>>
>> The issues which I expect to occur in your proxy would not show up in a
>> trivial outgoing-IP or connectivity test.
>>
>>
>> > I initially thought that could be related to server resources being
>> > drained but upon inspecting server resource usage, Squid isn't even
>> > topping at 100% CPU or RAM anytime so not that.
>> >
>>
>> IMO, "FLOW_CONTROL_ERROR" is likely related to quantity of traffic
>> flooding through the proxy to specific origin servers.
>>
>> The concept you are implementing of the outgoing TCP connection having
>> the same IP as the incoming connection reduces the available TCP sockets
>> by 25%. Prohibiting the OS from allocating ports on otherwise unused
>> outgoing addresses when
>>
>>
>>
>> > My Squid.conf is like this at the moment:
>>
>> Some improvements highlighted inline below.
>> Nothing stands out to me as being related to your issues.
>>
>> >
>> > auth_param basic program /usr/lib/squid/basic_ncsa_auth
>> /etc/squid/passwd
>> > acl auth_users proxy_auth REQUIRED
>> > http_access allow auth_users
>> > http_access deny !auth_users
>>
>> Above two lines are backwards. Deny first, then allow.
>>
>>
>> > cache deny all
>> > dns_nameservers <nameservers here>
>> > dns_v4_first off
>> > via off
>> > forwarded_for delete
>> > follow_x_forwarded_for deny all
>> > server_persistent_connections off
>>
>> *If* the issue turns out to be congestion on Squid->server connections
>> enabling this might be worthwhile. Otherwise it should be fine.
>>
>>
>> > max_filedesc 1048576
>>
>> You can remove that line. "max_filedesc" was a RedHat hack from 20+
>> years ago when the feature was experimental.
>>
>> Any value you set on the line above, will be erased and replaced by the
>> line below:
>>
>>
>> > max_filedescriptors 1048576
>> > workers 8
>> > http_port [::0]:1182
>>
>> Above is just a complicated way to write:
>>
>>   http_port 1182
>>
>>
>> Any particular reason not to use the registered port 3128 ?
>> (Not important, just wondering.)
>>
>>
>> > acl binding1 myip fe80:abcd::1
>> > tcp_outgoing_address fe80:abcd::1 binding1
>> > acl binding2 myip fe80:abcd::2
>> > tcp_outgoing_address fe80:abcd::2 binding2
>> > acl binding3 myip fe80:abcd::3
>> > tcp_outgoing_address fe80:abcd::3 binding3
>> > ...
>> > ...
>> > ...
>> > access_log /var/log/squid/access.log squid
>>
>> > cache_store_log none
>>
>> You can erase this line.
>> This is default setting. No need to manually set it.
>>
>>
>> > cache deny all
>>
>> You can erase this line.
>> This "cache deny all" exists earlier in the config.
>>
>>
>> >
>> > I've tried to get a PCAP file and realized when client tries to connect
>> > with a new IPv6 address, Squid is not trying to open a new connection
>> > instead tries to resume a previously opened one on a different outgoing
>> > IPv6 address.
>>
>> Can you provide the trace demonstrating that issue?
>>
>> Although, as noted earlier your problems are apparently on the client
>> connections. This is about server connections behaviour.
>>
>>
>> > I set server_persistent_connections off which should have
>> > disabled this behavior but it's still the same.
>>
>> Nod. Yes that should forbid re-use of connections.
>>
>> I/we will need to see the PCAP trace along with a cache.log generated
>> using "debug_options ALL,6" to confirm a bug or identify other breakage
>> though.
>>
>>
>>
>> > I tried using a newer
>> > version of Squid but it behaved differently and did not follow my
>> > outgoing address specifications and kept connecting on IPv4.
>>
>> That would seem to indicate that your IPv4 connectivity is better than
>> your IPv6 connectivity. Later Squid use various "Happy Eyeballs"
>> implementations for the server selection.
>>
>> You can usually work around this by configuring the DNS server specified
>> by dns_nameservers to only deliver IPv6 results when a mixed set are
>> available.
>>
>>
>> HTH
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240503/a03ffe3c/attachment.htm>

From squid3 at treenet.co.nz  Fri May  3 20:50:36 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 4 May 2024 08:50:36 +1200
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
 <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
 <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>
Message-ID: <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>

On 4/05/24 08:33, Emre Oksum wrote:
> Hi Jonathan,
> 
>  >> Have you attempted to enable debugging ??
> Yes, debugging was enabled but as I have pointed out, unfortunately it 
> didn't give any information about the issue.
> Maybe I was missing something? I don't know. debug_options was ALL in my 
> squid.conf.

Sure, "ALL" sections.

But what display level:

  0 (critical only)?
  1 (important)?
  2 (protocol trace)?
  3-6 (debugs)?
  9 (raw I/O data traces)?


FTR, "debug_options ALL" alone is invalid syntax and will not change 
from the default cache.log output.


Cheers
Amos


From emreoksum at gmail.com  Fri May  3 21:48:15 2024
From: emreoksum at gmail.com (Emre Oksum)
Date: Sat, 4 May 2024 00:48:15 +0300
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
 <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
 <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>
 <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>
Message-ID: <CADG8LiVMgwGWjU997jzFF3WiUN6fVyDhkBgWh2E+51+WzXskJg@mail.gmail.com>

Hi Amos,
>FTR, "debug_options ALL" alone is invalid syntax and will not change
>from the default cache.log output

Yes, you were right! I was surely missing on that one. I changed
debug_options ALL to debug_options ALL 5 and now, I found these warnings in
cache.log file:

2024/05/03 21:09:30.963 kid4| 28,5| Acl.cc(124) matches: checking
(tcp_outgoing_address [aaa:bbb:ccc:ddd:eee:fff:a81b:338c
2024/05/03 21:09:30.963 kid6| 28,3| Acl.cc(151) matches: checked:
(tcp_outgoing_address [aaa:bbbb:cccc:dddd:eeee:ffff:7eb8:b2e0 = 0
2024/05/03 21:09:30.963 kid8| 28,5| Acl.cc(124) matches: checking
tcp_outgoing_address [aaaa:bbbb:cccc:dddd:eeee:ffff:f92c:14fb]
2024/05/03 21:09:30.963 kid5| 28,3| Ip.cc(538) match: aclIpMatchIp:
'[aaaa:bbbb:cccc:dddd:eeee:ffff:4b29:abe5]:1182' NOT found
2024/05/03 21:09:30.963 kid1| 28,5| Acl.cc(124) matches: checking
(tcp_outgoing_address [aaaa:bbbb:cccc:dddd:eeee:ffff:2a45:6d20
2024/05/03 21:09:30.963 kid2| 28,3| Acl.cc(151) matches: checked:
(tcp_outgoing_address [aaaa:bbbb:cccc:dddd:eeee:ffff:9b7c:68db = 0
2024/05/03 21:09:30.963 kid7| 28,3| Checklist.cc(70) preCheck:
0x7ffd86446f80 checking fast ACLs
2024/05/03 21:09:30.963 kid3| 28,3| Ip.cc(538) match: aclIpMatchIp:
'[aaaa:bbbb:cccc:dddd:eeee:ffff:3135:f730]:1182' NOT found
2024/05/03 21:09:30.963 kid4| 28,5| Acl.cc(124) matches: checking binding597
2024/05/03 21:09:30.963 kid6| 28,3| Acl.cc(151) matches: checked:
tcp_outgoing_address [aaa:bbbb:cccc:dddd:eeee:ffff:7eb8:b2e0] = 0
2024/05/03 21:09:30.963 kid8| 28,5| Acl.cc(124) matches: checking
(tcp_outgoing_address [aaaa:bbbb:cccc:dddd:eeee:ffff:f92c:14fb
2024/05/03 21:09:30.963 kid5| 28,3| Acl.cc(151) matches: checked:
binding3010 = 0
2024/05/03 21:09:30.963 kid1| 28,5| Acl.cc(124) matches: checking binding687
2024/05/03 21:09:30.963 kid2| 28,3| Acl.cc(151) matches: checked:
tcp_outgoing_address [aaaa:bbbb:cccc:dddd:eeee:ffff:9b7c:68db] = 0
2024/05/03 21:09:30.963 kid7| 28,5| Acl.cc(124) matches: checking
tcp_outgoing_address [aaaa:bbbb:cccc:dddd:eeee:ffff:4b16:da82]
2024/05/03 21:09:30.963 kid3| 28,3| Acl.cc(151) matches: checked: binding22
= 0
2024/05/03 21:09:30.963 kid6| 28,3| Checklist.cc(63) markFinished:
0x7ffcdd512440 answer DENIED for ACLs failed to match
2024/05/03 21:09:30.963 kid4| 28,3| Ip.cc(538) match: aclIpMatchIp:
'[aaaa:bbbb:cccc:dddd:eeee:ffff:cf41:193c]:1182' NOT found

Is there any chance aclIpMatchIp warnings could be the problem here? Do
they generate TCP RST packets to client if that error happens?

Thanks
Emre

Amos Jeffries <squid3 at treenet.co.nz>, 3 May 2024 Cum, 23:50 tarihinde ?unu
yazd?:

> On 4/05/24 08:33, Emre Oksum wrote:
> > Hi Jonathan,
> >
> >  >> Have you attempted to enable debugging ??
> > Yes, debugging was enabled but as I have pointed out, unfortunately it
> > didn't give any information about the issue.
> > Maybe I was missing something? I don't know. debug_options was ALL in my
> > squid.conf.
>
> Sure, "ALL" sections.
>
> But what display level:
>
>   0 (critical only)?
>   1 (important)?
>   2 (protocol trace)?
>   3-6 (debugs)?
>   9 (raw I/O data traces)?
>
>
> FTR, "debug_options ALL" alone is invalid syntax and will not change
> from the default cache.log output.
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240504/13d60fe0/attachment.htm>

From jonathanlee571 at gmail.com  Fri May  3 21:52:02 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 3 May 2024 14:52:02 -0700
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
 <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
 <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>
 <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>
Message-ID: <4D3EC30B-512F-4C2E-B44A-B971B7B430BC@gmail.com>

The only reason I know about this is the book I just purchased has a whole section on debugging. This is in my Squid The Definitive Guide by O?REILLY Duane Wessels (Older Book Still Good)

You can use 0 up to 84(helper process maintenance)

I think 6 is disk i/o routines and 9 is for FTP right?

Change all and add ranges

Example:
debug_options ALL,1 11,3 20,3

debug_option section, level section, level? + n just like a series

> On May 3, 2024, at 13:50, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 4/05/24 08:33, Emre Oksum wrote:
>> Hi Jonathan,
>>>> Have you attempted to enable debugging ??
>> Yes, debugging was enabled but as I have pointed out, unfortunately it didn't give any information about the issue.
>> Maybe I was missing something? I don't know. debug_options was ALL in my squid.conf.
> 
> Sure, "ALL" sections.
> 
> But what display level:
> 
> 0 (critical only)?
> 1 (important)?
> 2 (protocol trace)?
> 3-6 (debugs)?
> 9 (raw I/O data traces)?
> 
> 
> FTR, "debug_options ALL" alone is invalid syntax and will not change from the default cache.log output.
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri May  3 22:45:35 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 4 May 2024 10:45:35 +1200
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <CADG8LiVMgwGWjU997jzFF3WiUN6fVyDhkBgWh2E+51+WzXskJg@mail.gmail.com>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
 <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
 <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>
 <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>
 <CADG8LiVMgwGWjU997jzFF3WiUN6fVyDhkBgWh2E+51+WzXskJg@mail.gmail.com>
Message-ID: <cd4cf0b3-58ff-4bec-9efb-bc194542ad8c@treenet.co.nz>

On 4/05/24 09:48, Emre Oksum wrote:
> Hi Amos,
>  >FTR, "debug_options ALL" alone is invalid syntax and will not change
>  >from the default cache.log output
> 
> Yes, you were right! I was surely missing on that one. I changed 
> debug_options ALL to debug_options ALL 5 and now, I found these warnings 
> in cache.log file:
> 

FYI, these are not warnings. They are debug traces saying what is going on.

In this case, all your tcp_outgoing_addr lines being tested. Most of 
them will not match.



Cheers
Amos


From emreoksum at gmail.com  Fri May  3 23:17:32 2024
From: emreoksum at gmail.com (Emre Oksum)
Date: Sat, 4 May 2024 02:17:32 +0300
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <cd4cf0b3-58ff-4bec-9efb-bc194542ad8c@treenet.co.nz>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
 <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
 <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>
 <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>
 <CADG8LiVMgwGWjU997jzFF3WiUN6fVyDhkBgWh2E+51+WzXskJg@mail.gmail.com>
 <cd4cf0b3-58ff-4bec-9efb-bc194542ad8c@treenet.co.nz>
Message-ID: <CADG8LiXPMTy4dismw+8oTpLPM1izqLA_gNo5DXsKjs_gbebuWQ@mail.gmail.com>

 >In this case, all your tcp_outgoing_addr lines being tested. Most of
>them will not match.
Sorry I'm not really a Squid guy I was working on it due to a job that I
took but I cannot figure this out. What do you mean most of them do not
match? Does it mean Squid checks every ACL one by one that is defined in
config to find the correct IPv6 address? If that's the case I still didn't
understand why Squid randomly sends Connection Reset flag to client. Is it
because too many ACL's create bottleneck?

Amos Jeffries <squid3 at treenet.co.nz>, 4 May 2024 Cmt, 01:45 tarihinde ?unu
yazd?:

> On 4/05/24 09:48, Emre Oksum wrote:
> > Hi Amos,
> >  >FTR, "debug_options ALL" alone is invalid syntax and will not change
> >  >from the default cache.log output
> >
> > Yes, you were right! I was surely missing on that one. I changed
> > debug_options ALL to debug_options ALL 5 and now, I found these warnings
> > in cache.log file:
> >
>
> FYI, these are not warnings. They are debug traces saying what is going on.
>
> In this case, all your tcp_outgoing_addr lines being tested. Most of
> them will not match.
>
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240504/82ad692f/attachment.htm>

From squid3 at treenet.co.nz  Sun May  5 07:03:31 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 5 May 2024 19:03:31 +1200
Subject: [squid-users] Squid TCP_TUNNEL_ABORTED/200
In-Reply-To: <CADG8LiXPMTy4dismw+8oTpLPM1izqLA_gNo5DXsKjs_gbebuWQ@mail.gmail.com>
References: <CADG8LiWapFmxnS5j+UUn8Pu-zFGfVFoF0Ck5H+7Pm7XUUkFV5Q@mail.gmail.com>
 <6A8618C5-4E3E-4097-A26C-2F1D29C44179@gmail.com>
 <CADG8LiX6MjY+z=8pwe7R6guudE301uF3RVywyYi1SpKULUXX9g@mail.gmail.com>
 <68b868d3-5903-43bf-9a8c-869a05c705d4@treenet.co.nz>
 <CADG8LiVMgwGWjU997jzFF3WiUN6fVyDhkBgWh2E+51+WzXskJg@mail.gmail.com>
 <cd4cf0b3-58ff-4bec-9efb-bc194542ad8c@treenet.co.nz>
 <CADG8LiXPMTy4dismw+8oTpLPM1izqLA_gNo5DXsKjs_gbebuWQ@mail.gmail.com>
Message-ID: <cab56356-a3f4-4b26-b8fd-5d53a8ba3716@treenet.co.nz>

On 4/05/24 11:17, Emre Oksum wrote:
>  >In this case, all your tcp_outgoing_addr lines being tested. Most of
>  >them will not match.
> Sorry I'm not really a Squid guy I was working on it due to a job that I 
> took but I cannot figure this out. What do you mean most of them do not 
> match? Does it mean Squid checks every ACL one by one that is defined in 
> config to find the correct IPv6 address?

Yes, exactly so.

Each tcp_outgoing_address line of squid.conf is checked top-to-bottom, 
the ACLs on that line tested left-to-right against the Squid local-IP 
the client connected to.
  Most will non-match (as seen in the trace snippet you showed).
  One should match, at which point Squid uses the IP address on that 
tcp_outgoing_address line.


As mentioned earlier, this is all on *outgoing* Squid-to-server 
connections. tcp_outgoing_* directives have no effect on the client 
connection.


> If that's the case I still 
> didn't understand why Squid randomly sends Connection Reset flag to 
> client.

That is what we are trying to figure out, yes.

I asked for the cache.log trace so I could look through and see when one 
of the problematic connections was identified by Squid as closed, and 
whether that was caused by something else Squid was doing - or whether 
the signal came to Squid from the OS.
  Which would tell us whether Squid had sent it, or if the OS had sent 
it to both Squid and client.

I/we will need a full cache.log trace from before a problematic 
connection was opened, to after it fails. At least several seconds 
before and after.

Cheers
Amos


From Albert.Shih at obspm.fr  Mon May  6 08:48:51 2024
From: Albert.Shih at obspm.fr (Albert Shih)
Date: Mon, 6 May 2024 10:48:51 +0200
Subject: [squid-users] Dynamic ACL with local auth
Message-ID: <ZjiZc8LLSYmXma5V@io.chezmoi.fr>

Hi everyone, 


I like to know how (if it's possible) to create acl dynamically. 

What I try to do is to have peoples authenticated (user1, user2, user3,
etc.) then for each user I like to create a set of acl. The problem is I
cannot have the set of acl once for all, it's dynamically change in time. 

I can put the set of acl in anything, like static file, mysql db, etc...

Performance is not a issue (no lot of users) but I really would like not to
have restart squid each time the acl static file change. 

The authentication would be through htpasswd. 

What would be the best way to do it ? 

Regards.


-- 
Albert SHIH ? ?
France
Heure locale/Local time:
lun. 06 mai 2024 10:44:28 CEST


From ngtech1ltd at gmail.com  Mon May  6 09:21:10 2024
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Mon, 6 May 2024 12:21:10 +0300
Subject: [squid-users] Dynamic ACL with local auth
In-Reply-To: <ZjiZc8LLSYmXma5V@io.chezmoi.fr>
References: <ZjiZc8LLSYmXma5V@io.chezmoi.fr>
Message-ID: <000301da9f96$bcf19270$36d4b750$@gmail.com>

Hey Albert,

The right way to do it is to use an external acl helper that will use some kind of database for the settings.
The other option is to use a reloadable ACLs file.
But you need to clarify exactly the goal if you want more then a basic advise.

Eliezer

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Albert Shih
Sent: Monday, May 6, 2024 11:49 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Dynamic ACL with local auth

Hi everyone, 


I like to know how (if it's possible) to create acl dynamically. 

What I try to do is to have peoples authenticated (user1, user2, user3,
etc.) then for each user I like to create a set of acl. The problem is I
cannot have the set of acl once for all, it's dynamically change in time. 

I can put the set of acl in anything, like static file, mysql db, etc...

Performance is not a issue (no lot of users) but I really would like not to
have restart squid each time the acl static file change. 

The authentication would be through htpasswd. 

What would be the best way to do it ? 

Regards.


-- 
Albert SHIH ? ?
France
Heure locale/Local time:
lun. 06 mai 2024 10:44:28 CEST
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Mon May  6 16:58:55 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 May 2024 04:58:55 +1200
Subject: [squid-users] Linux Noob - Squid Config
In-Reply-To: <c8182e813c3f413180791ada7717cb48@hexcel.com>
References: <4e3f328f76fd460f83c2259e5dad8b57@hexcel.com>
 <65e0a341-dec2-4ee9-8c20-e1074a7949c8@treenet.co.nz>
 <c8182e813c3f413180791ada7717cb48@hexcel.com>
Message-ID: <a7dfaf0d-0b93-4342-8be4-8fc45ce26e99@treenet.co.nz>

[ please keep responses on-list to assist any others who encounter the 
same issues in future ]

On 4/05/24 08:51, Piana, Josh wrote:
> Hey Amos,
> 
> Thank you so much for getting back to me so quickly!
> 
> To answer your question about NTLM, I meant to say NTLMv2. We're trying to become compliant with newer security standards and this old box in depersate need of some love and updating.
> 


Hmm. My question was more aiming as a yes/no answer.

Squid can certainly still support NTLM. But if possible going to just 
Negotiate/Kerberos auth would be a simpler config.

The /usr/bin/ntlm_auth authenticator you have been using is provided by 
Samba. So you will need to have Samba installed (yum install samba) and 
configured the same (or equivalent for its upgrade) as before Squid 
authentication is usable.

FYI; Modern Squid start helpers only as-needed. Meaning Squid will 
startup and run fine without a working auth helper ... until the point 
where a helper lookup is needed. So you can test Squid with some trivial 
requests before needing Samba fully working.


> --------------------------------------------------------------
> Current squid.conf file Output:
> 
> max_filedesc 4096


I advise changing this to at least:

   max_filedescriptors 65536

Why? Modern web pages can cause clients to open up to a hundred 
connections to various servers to display a single web page. Each client 
of those connection consumes 3-4 file descriptors.

You will also need to check the OS limitation to ensure


> cache_mgr itadmin at ...
> cache_effective_user squid
> cache_effective_group squid
> coredump_dir /opt/squid/var
> pid_filename /var/run/squid.pid
> shutdown_lifetime 5 seconds
> error_directory /usr/local/share/squid/errors/English_CUSTOM


Check what customizations have been done to the files inside that directory.

If it is just the new templates for the deny_info lines later in your 
config; then you can copy those templates to the new machine.
And create symlnks from the

I suggest placing the custom error templates in a directory such as
/etc/squid/errors/ and a symlink from the 
/usr/local/share/squid/errors/templates/ directory (or wherever the 
templates are put by yum install).
  [ This way upgrades that change the default templates will not erase 
your ones. At worst you should only have to re-create the symlinks 
manually. ]

(If you need it; to learn how to create symlinks type "man ln".)


> logfile_rotate 0
> debug_options ALL,1

You can remove the above line. It is a default setting.


> buffered_logs on > cache_log /var/log/squid/general> cache_access_log /var/log/squid/access


The above two lines should be more like:

   cache_log /var/log/squid/cache.log
   access_log daemon:/var/log/squid/access.log


> cache_store_log none
> log_mime_hdrs off

The above two lines can be removed. They are default settings.


> log_fqdn off

Remove this line. It is not supported in modern Squid.


> strip_query_terms off
> http_port 10.46.11.20:8080
> http_port 127.0.0.1:3128
> icp_port 0

The above line can be removed. It is a default setting.


> forwarded_for off

Change that "off" to;
  * "delete" for complete removal of the header), or
  * "transparent" for Squid to not add the header.


> ftp_user anonftpuser at ...
> ftp_list_width 32
> ftp_passive on
> connect_timeout 30 seconds
> peer_connect_timeout 20 seconds
> read_timeout 2 minutes
> request_timeout 2 minutes
> persistent_request_timeout 30 seconds
> cache_dir ufs /var/cache/squid/ufs/squid 16000 64 64
> cache_replacement_policy heap LFUDA
> memory_replacement_policy lru
> cache_mem 200 MB
> maximum_object_size 32 MB
> maximum_object_size_in_memory 128 KB
> quick_abort_min 16 KB
> quick_abort_max 1 MB
> quick_abort_pct 90
> range_offset_limit 64 KB
> acl no_cache_url url_regex -i "/etc/squid/no_cache_url"
> cache deny no_cache_url

Modern Squid define a set of "refresh_pattern" to fixup messages 
cacheability inline with HTTP/1.1 caching requirements.

Please add these lines:

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320



> acl blows_chunks dstdomain .blr.com
> header_access Accept-Encoding deny blows_chunks

This is something to look into. Be aware of how exactly that server is 
broken when it receives "Accept-Encoding" headers.

The old Squid only supported HTTP/1.0. Your new Squid supports HTTP/1.1 
which may work better with whatever that server was doing to be 
considered bad.


> auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 30
> auth_param ntlm keep_alive on
> auth_param basic program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
> auth_param basic children 5
> auth_param basic realm "..."
> auth_param basic credentialsttl 2 hours
> acl authenticated proxy_auth REQUIRED
> acl all src 0.0.0.0/0.0.0.0

Remove the above line. The "all" ACL is now built-in.


> acl src_self src 127.0.0.0/255.0.0.0
> acl src_self src 10.46.11.20

Modern Squid provide these as a built-in "localhost" ACL.

To add the machines global IP address as part of localhost, replace the 
above two lines with:
   acl localhost src 10.46.11.20/32

Then replace all uses of "src_self" with "localhost".


> acl dst_self dst 127.0.0.0/255.0.0.0
> acl dst_self dst 10.46.11.20


Modern Squid provide these as a built-in "to_localhost" ACL.

To add the machines global IP address as part of localhost, replace the 
above two lines with:
   acl to_localhost dst 10.46.11.20/32

Then replace all uses of "dst_self" with "to_localhost".


> acl from_arc src 10.0.0.0/255.255.0.0
> acl from_arc src 10.46.0.0/255.254.0.0
> acl local_dst_addr dst 10.0.0.0/255.0.0.0

FYI; while the above is acceptible to Squid. Prefer writing those as 
CIDR masks instead of NetMask syntax.

  eg.  10.0.0.0/8


> acl local_dst_addr dst bldg3.*.com.
> acl local_dst_addr dst bldg5.*.com.
> acl local_dst_dom dstdomain arcgate

The above is not a domain name, nor wildcard domain.

FYI; Squid will attempt to apply a domain search using the "domain" or 
"search" as configured in /etc/resolv.conf and resolve arcgate.* in DNS.


> acl proto_FTP proto FTP
> acl proto_HTTP proto HTTP
> acl http_ports port 80		
> acl http_ports port 81		
> acl http_ports port 82		
> acl http_ports port 807		
> acl http_ports port 8000	
> acl http_ports port 8001	
> acl http_ports port 8080	
> acl http_ports port 8081	
> acl http_ports port 9000	
> acl ssl_ports port 443
> acl ssl_ports port 818	
> acl ssl_ports port 4435	
> acl ssl_ports port 9571	
> acl ssl_ports port 9030	
> acl ssl_ports port 4502
> acl ssl_ports port 8080
> acl ssl_ports port 8081
> acl ssh_ports port 22 1776 8217
> acl ftp_ports port 21
> acl method_CONNECT method CONNECT

The "CONNECT" ACL is provided as a built-in.

Replace all uses of "method_CONNECT" with just "CONNECT" and remove the 
above line.


> acl methods_std method GET HEAD POST PUT DELETE
> acl methods_std method TRACE OPTIONS
> acl purge method PURGE
> http_access allow purge src_self
> http_access deny purge

This purge is something to consider carefully. You should not need to 
ever use it on a properly working cache that obeys HTTP standard.

If possible prefer to remove the http_access and acl lines relating to 
the curstom "PURGE" method. This allows modern Squid to improve 
performance by not tracking a lot of things.


> acl cache_manager proto cache_object

The "manager" ACL is provided as built-in by modern Squids, and has a 
different definition for the latest access mechanism(s).

Replace all uses of "cache_manager" with "manager" and remove the above 
line.


> cachemgr_passwd disabled shutdown offline_toggle
> cachemgr_passwd none all

> http_access allow cache_manager src_self
> http_access deny cache_manager

Per earlier change requests this should become:

  http_access allow manager localhost
  http_access deny manager


> http_access deny dst_self
> http_access deny src_self


Per earlier change requests this should become:

  http_access deny localhost
  http_access deny to_localhost

> http_access deny !from_arc

> http_access       allow local_dst_dom
> http_reply_access allow local_dst_dom

> http_access       allow local_dst_addr
> http_reply_access allow local_dst_addr

> acl authless_src src "/etc/squid/authless_src"
> http_access       allow authless_src
> http_reply_access allow authless_src

> acl authless_dst dstdomain "/etc/squid/authless_dst"
> http_access       allow authless_dst
> http_reply_access allow authless_dst

> acl bad_domains_preauth dstdomain "/etc/squid/bad_domains_preauth"
> http_access deny bad_domains_preauth

> http_access deny !authenticated

> acl block_user proxy_auth_regex -i "/etc/squid/block_user"
> http_access deny block_user

> acl bad_exception_urls url_regex -i "/etc/squid/bad_exception_urls"
> acl exec_files url_regex -i "/etc/squid/exec_files"
> acl exec_users proxy_auth_regex -i "/etc/squid/exec_users"
> http_access deny !bad_exception_urls !exec_users exec_files
> deny_info ERR_BLOCK_TYPE exec_files

> acl mmedia_users proxy_auth_regex -i "/etc/squid/mmedia_users"
> acl mmedia_sites dstdomain "/etc/squid/mmedia_sites"
> http_access       allow methods_std    proto_HTTP http_ports mmedia_sites mmedia_users
> http_reply_access allow methods_std    proto_HTTP http_ports mmedia_sites mmedia_users

> http_access       allow method_CONNECT            ssl_ports  mmedia_sites mmedia_users
> http_reply_access allow method_CONNECT            ssl_ports  mmedia_sites mmedia_users

> acl bad_domains dstdomain "/etc/squid/bad_domains"
> http_access deny !bad_exception_urls bad_domains
> deny_info ERR_BLOCK_DST	bad_domains

> acl bad_domains_regex dstdom_regex -i "/etc/squid/bad_domains_regex"
> http_access deny !bad_exception_urls bad_domains_regex
> deny_info ERR_BLOCK_DST	bad_domains_regex

> acl bad_urls url_regex -i "/etc/squid/bad_urls"
> http_access deny !bad_exception_urls bad_urls
> deny_info ERR_BLOCK_DST	bad_urls

> acl bad_files urlpath_regex -i "/etc/squid/bad_files"
> http_access deny !bad_exception_urls bad_files
> deny_info ERR_BLOCK_TYPE bad_files

> acl bad_types rep_mime_type -i "/etc/squid/bad_types"
> http_reply_access deny bad_types !bad_exception_urls
> deny_info ERR_BLOCK_TYPE bad_types

> acl fsoguest_user proxy_auth_regex -i fsoguest
> acl fsoguest_dst dstdomain .opm.gov
> acl fsoguest_dst dstdomain .google-analytics.com
> acl fsoguest_dst dstdomain pki.google.com
> acl fsoguest_dst dstdomain ajax.googleapis.com
> acl fsoguest_dst dstdomain fonts.googleapis.com
> acl fsoguest_dst dstdomain html5shiv.googlecode.com
> acl fsoguest_dst dstdomain fonts.gstatic.com
> acl fsoguest_dst dstdomain clients1.google.com
> acl fsoguest_dst dstdomain ajax.microsoft.com
> acl fsoguest_dst dstdomain ajax.aspnetcdn.com
> acl fsoguest_dst dstdomain .geotrust.com
> acl fsoguest_dst dstdomain .akamaihd.net
> acl fsoguest_dst dstdomain symcd.com
> http_access allow methods_std proto_HTTP http_ports fsoguest_dst fsoguest_user
> http_access allow method_CONNECT         ssl_ports  fsoguest_dst fsoguest_user
> http_access deny fsoguest_user

> http_access allow http_ports proto_HTTP methods_std

> acl ssh_users proxy_auth -i PCADMIN
> acl ssh_users proxy_auth -i BSCOTT
> http_access allow method_CONNECT ssh_ports ssh_users

> acl ssh_dst dst vthm.com
> http_access allow method_CONNECT ssh_ports ssh_dst

> acl ftp_dst dst http://www.arc-tech.com/

I hoep that above line is a typo. A full URL is not valid for a "dst" 
ACL type.

The "dst" ACL values can be;
  * a raw-IP, or
  * a CIDR range, or
  * a NetMask range (eg A-B/mask), or
  * a hostname which is resolvable in DNS at Squid startup/reconfigure time.


> acl ftp_dst dst ftp.telemeter.de
> acl ftp_dst dst ftp.lucasindustries.com
> acl ftp_dst dst ftp-upload.trendmicro.com
> http_access allow method_CONNECT ftp_dst
> http_access allow method_CONNECT ssl_ports
> http_access deny method_CONNECT

> http_access allow ftp_ports proto_FTP
> http_access deny all
> http_reply_access allow all
> 


After making the above adjustments with Squid installed you should be 
aboe to run the command "squid -k parse -f /etc/squid/squid.conf.old" to 
see what the new Squid thinks of the old configuration.

Any "ERROR" lines that are displayed by by that command will need fixing 
before you can use Squid.

Any "WARNING" or "NOTICE" or "UPGRADE" are things that should be looked 
into fixing. But not urgent enough to make Squid unusable.


You may need to run "squid -z -f /etc/squid/squid.conf.old" to create 
the cache directory.


When that is fine you can move the /etc/squid/squid.conf.old to replace 
the /etc/squid/squid.conf and use the OS method for starting Squid.

Which for RHEL 9 I believe should be:
    service squid start


... then start testing that what Squid does actually meets your 
expectations.


HTH
Amos




> --------------------------------------------------------------
> 
> Current Box squid -v Output:
> 
> Squid Cache: Version 2.6.STABLE21
> 
> configure options:  '--build=i386-redhat-linux-gnu' '--host=i386-redhat-linux-gnu' '--target=i386-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--includedir=/usr/include' '--libdir=/usr/lib' '--libexecdir=/usr/libexec' '--sharedstatedir=/usr/com' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--exec_prefix=/usr' '--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid' '--localstatedir=/var' '--datadir=/usr/share' '--sysconfdir=/etc/squid' '--enable-arp-acl' '--enable-epoll' '--enable-snmp' '--enable-removal-policies=heap,lru' '--enable-storeio=aufs,coss,diskd,null,ufs' '--enable-ssl' '--with-openssl=/usr/kerberos' '--enable-delay-pools' '--enable-linux-netfilter' '--with-pthreads' '--enable-ntlm-auth-helpers=SMB,fakeauth' '--enable-external-acl-helpers=ip_user,ldap_group,unix_group,wbinfo_group' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-digest-auth-helpers=password' '--with-winbind-auth-challenge' '--enable-useragent-log' '--enable-referer-log' '--disable-dependency-tracking' '--enable-cachemgr-hostname=localhost' '--enable-underscores' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL' '--enable-cache-digests' '--enable-ident-lookups' '--with-large-files' '--enable-follow-x-forwarded-for' '--enable-wccpv2' '--enable-fd-config' '--with-maxfd=16384' 'build_alias=i386-redhat-linux-gnu' 'host_alias=i386-redhat-linux-gnu' 'target_alias=i386-redhat-linux-gnu' 'CFLAGS=-D_FORTIFY_SOURCE=2 -fPIE -Os -g -pipe -fsigned-char' 'LDFLAGS=-pie'
> 
> --------------------------------------------------------------
> 
> New Box squid -v Output:
> 
> Squid Cache: Version 5.5
> Service Name: squid
> 
> This binary uses OpenSSL 3.0.7 1 Nov 2022. For legal restrictions on distribution see https://www.openssl.org/source/license.html
> 
> configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--localstatedir=/var' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--libexecdir=/usr/lib64/squid' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/run/squid.pid' '--disable-dependency-tracking' '--enable-eui' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,PAM,POP3,RADIUS,SASL,SMB,SMB_LM' '--enable-auth-ntlm=SMB_LM,fake' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos' '--enable-external-acl-helpers=LDAP_group,time_quota,session,unix_group,wbinfo_group,kerberos_ldap_group' '--enable-storeid-rewrite-helpers=file' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-ssl-crtd' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-diskio' '--enable-wccpv2' '--enable-esi' '--enable-ecap' '--with-aio' '--with-default-user=squid' '--with-dl' '--with-openssl' '--with-pthreads' '--disable-arch-native' '--disable-security-cert-validators' '--disable-strict-error-checking' '--with-swapdir=/var/spool/squid' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CC=gcc' 'CFLAGS=-O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection' 'LDFLAGS=-Wl,-z,relro -Wl,--as-needed  -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 ' 'CXX=g++' 'CXXFLAGS=-O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' 'LT_SYS_LIBRARY_PATH=/usr/lib64:'
> 
> --------------------------------------------------------------
> 
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
> Sent: Friday, May 3, 2024 4:21 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Linux Noob - Squid Config
> 
> [You don't often get email from squid3 at treenet.co.nz. Learn why this is important at https://aka.ms/LearnAboutSenderIdentification ]
> 
> Caution: This email originated from outside of Hexcel. Do not click links or open attachments unless you recognize the sender and know the content is safe.
> 
> 
> On 4/05/24 07:59, Piana, Josh wrote:
>> Hey Everyone.
>>
>> I apologize in advance for any lack of formality normally shared on
>> mailing lists such as these, it?s my first time seeking product
>> support in this manner.
>>
> 
> NO need to apologize. Help and questions is most of what we do here :-)
> 
> 
>> I want to start by saying that I?m new to Linux, been using Windows
>> environments my entire life. Such is the reason for me reaching out to
>> you all.
>>
>> I have been tasked with modernizing a Squid box and feel very
>> overwhelmed, to say the least.
>>
>> Current Setup:
>>
>> ?CentOS 5.0
>>
>> ?Squid 2.3
>>
>> ?Apache 2.0.46
>>
>> ?Samba 3.0.9
>>
>> Desired Setup:
>>
>> ?RHEL 9.2 OS
>>
>> ?Needs to qualify for NTLM authentication
>>
> 
> Hmm, does it *have* to be NTLM? that auth protocol was deprecated in 2006.
> 
> 
>> ?Would like to remove legacy apps/services
>>
>> ?Continue to authenticate outgoing communication via AD
>>
>> My question is, how do I get all of these services/apps to work
>> together? Do I just install the newest versions of each and migrate
>> the existing config files?
>>
>> I was hoping for a better understanding on how all of these work
>> together and exactly how to configure or edit these as needed. I?ve
>> gotten as far as installing RHEL 9.2 on a fresh VM Server and trying
>> as best as I can to learn the basics on Linux and just the general
>> operation of a Linux ran environment. It feels like trying to ride a
>> bike with box wheels.
>>
> 
> 
> The installation of a basic Squid service for RHEL is easy.
> Just open a terminal and enter this command:
> 
>      yum install squid
> 
> 
> The next part is going over your old Squid configuration to see how much of it remains necessary or can be updated. It would be useful for the next steps to copy it to the RHEL machine as /etc/squid/squid.conf.old .
> 
> You can likely find it on the CentOS machine at /etc/squid/squid.conf or /usr/share/squid/etc/squid.conf depending on how that Squid was built.
> 
> 
> If you are able to paste the contents of that file (without the '#'
> comment or empty lines) here, we can assist with getting the new Squid doing the same or equivalent actions.
> 
> 
> Also please paste the output of "squid -v" run on both the old CentOS machine and on the new RHEL.
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

From s_p_arun at yahoo.com  Mon May  6 23:39:57 2024
From: s_p_arun at yahoo.com (Arun Kumar)
Date: Mon, 6 May 2024 23:39:57 +0000 (UTC)
Subject: [squid-users] Error from icap during respmod
In-Reply-To: <6ad59ee8-714a-48d3-bfec-a8d239bade05@measurement-factory.com>
References: <166088187.5074521.1714410400274.ref@mail.yahoo.com>
 <166088187.5074521.1714410400274@mail.yahoo.com>
 <6ad59ee8-714a-48d3-bfec-a8d239bade05@measurement-factory.com>
Message-ID: <1650153442.7740770.1715038797924@mail.yahoo.com>

 Thank you very much for the response. Are you aware of any compatible Python or Java based iCAP server implemenation? We want to implement custom virus scanning of the response.?I got the book Squid: The Definitive Guide and going over for more understanding. Saw your name mentioned by the author. I am very proud to work with great people like you.

    On Thursday, May 2, 2024 at 04:18:45 PM EDT, Alex Rousskov <rousskov at measurement-factory.com> wrote:  
 
 On 2024-04-29 13:06, Arun Kumar wrote:
> Configured python based icap server (pyicap) and getting 500 Internal 
> Server error during respmod.

AFAICT, this ICAP RESPMOD service is buggy: It sends what looks like an 
HTTP response body chunk after sending an ICAP 100 Continue control 
message. Instead, it is supposed to send the final ICAP response headers 
and HTTP response headers _before_ sending that HTTP response body chunk.


? ? 00:50:54.989 ... ReadNow: conn33 ... size 65535, retval 25
? ? ICAP/1.0 100 Continue


? ? 00:50:54.991 ReadNow: conn33 ... size 65535, retval 137
? ? 83
? ? {"activity":...}


HTH,

Alex.

> https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing <https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing>
> 
> Squid configuration:
> icap_enable on
> icap_send_client_ip on
> icap_send_client_username on
> icap_client_username_encode off
> icap_client_username_header X-Authenticated-User
> icap_preview_enable on
> icap_preview_size 1024
> 
> icap_service service_req reqmod_precache bypass=0 
> icap://127.0.0.1:13440/example
> icap_service service_resp respmod_precache bypass=0 
> icap://127.0.0.1:13441/example
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240506/301e8159/attachment.htm>

From squid3 at treenet.co.nz  Tue May  7 17:59:57 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 May 2024 05:59:57 +1200
Subject: [squid-users] Linux Noob - Squid Config
In-Reply-To: <0b6fde334d6e49a09988bd8ca6bd87b8@hexcel.com>
References: <4e3f328f76fd460f83c2259e5dad8b57@hexcel.com>
 <65e0a341-dec2-4ee9-8c20-e1074a7949c8@treenet.co.nz>
 <c8182e813c3f413180791ada7717cb48@hexcel.com>
 <a7dfaf0d-0b93-4342-8be4-8fc45ce26e99@treenet.co.nz>
 <0b6fde334d6e49a09988bd8ca6bd87b8@hexcel.com>
Message-ID: <f65b1994-c8a5-4249-931c-8383dc488787@treenet.co.nz>

On 7/05/24 07:59, Piana, Josh wrote:
> Amos,
> 
> You raise a good point about Kerberos! I was not aware that Squid supported this method. Yes - I think we would preferably use this method, especially because this looks like it's much easier to setup and still checks all the boxes we need for security purposes.
> 
> With that being said, without using NTLM, can we bypass using Samba? We would rather not rely on that resource if possible.
> 

I'm not sure how much of Samba need to be setup to use the NTLM helper. 
It has been a while since I used it.


> In regards to your responses to all of the lines of code, I'll be going through that seperately and will get back to you if I have any more questions with it. After installing Squid, moving over and updating the old config, and adjusting the parameters you mentioned below, what else is there to do to finish setting up this server? I'm not entirely sure if Apache is needed anymore either. This would simplify and modernize our processes a great deal if this can be remopved as well.
> 

There is no sign in the squid.conf as to what Apache was being used for.
So that and any other services the old machine had going will still need 
your attention, but they are not related to Squid.


Cheers
Amos


> - Josh
> 
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
> Sent: Monday, May 6, 2024 12:59 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Linux Noob - Squid Config
> 
> Caution: This email originated from outside of Hexcel. Do not click links or open attachments unless you recognize the sender and know the content is safe.
> 
> 
> [ please keep responses on-list to assist any others who encounter the same issues in future ]
> 
> On 4/05/24 08:51, Piana, Josh wrote:
>> Hey Amos,
>>
>> Thank you so much for getting back to me so quickly!
>>
>> To answer your question about NTLM, I meant to say NTLMv2. We're trying to become compliant with newer security standards and this old box in depersate need of some love and updating.
>>
> 
> 
> Hmm. My question was more aiming as a yes/no answer.
> 
> Squid can certainly still support NTLM. But if possible going to just Negotiate/Kerberos auth would be a simpler config.
> 
> The /usr/bin/ntlm_auth authenticator you have been using is provided by Samba. So you will need to have Samba installed (yum install samba) and configured the same (or equivalent for its upgrade) as before Squid authentication is usable.
> 
> FYI; Modern Squid start helpers only as-needed. Meaning Squid will startup and run fine without a working auth helper ... until the point where a helper lookup is needed. So you can test Squid with some trivial requests before needing Samba fully working.
> 
> 
>> --------------------------------------------------------------
>> Current squid.conf file Output:
>>
>> max_filedesc 4096
> 
> 
> I advise changing this to at least:
> 
>     max_filedescriptors 65536
> 
> Why? Modern web pages can cause clients to open up to a hundred connections to various servers to display a single web page. Each client of those connection consumes 3-4 file descriptors.
> 
> You will also need to check the OS limitation to ensure
> 
> 
>> cache_mgr itadmin at ...
>> cache_effective_user squid
>> cache_effective_group squid
>> coredump_dir /opt/squid/var
>> pid_filename /var/run/squid.pid
>> shutdown_lifetime 5 seconds
>> error_directory /usr/local/share/squid/errors/English_CUSTOM
> 
> 
> Check what customizations have been done to the files inside that directory.
> 
> If it is just the new templates for the deny_info lines later in your config; then you can copy those templates to the new machine.
> And create symlnks from the
> 
> I suggest placing the custom error templates in a directory such as /etc/squid/errors/ and a symlink from the /usr/local/share/squid/errors/templates/ directory (or wherever the templates are put by yum install).
>    [ This way upgrades that change the default templates will not erase your ones. At worst you should only have to re-create the symlinks manually. ]
> 
> (If you need it; to learn how to create symlinks type "man ln".)
> 
> 
>> logfile_rotate 0
>> debug_options ALL,1
> 
> You can remove the above line. It is a default setting.
> 
> 
>> buffered_logs on > cache_log /var/log/squid/general> cache_access_log
>> /var/log/squid/access
> 
> 
> The above two lines should be more like:
> 
>     cache_log /var/log/squid/cache.log
>     access_log daemon:/var/log/squid/access.log
> 
> 
>> cache_store_log none
>> log_mime_hdrs off
> 
> The above two lines can be removed. They are default settings.
> 
> 
>> log_fqdn off
> 
> Remove this line. It is not supported in modern Squid.
> 
> 
>> strip_query_terms off
>> http_port 10.46.11.20:8080
>> http_port 127.0.0.1:3128
>> icp_port 0
> 
> The above line can be removed. It is a default setting.
> 
> 
>> forwarded_for off
> 
> Change that "off" to;
>    * "delete" for complete removal of the header), or
>    * "transparent" for Squid to not add the header.
> 
> 
>> ftp_user anonftpuser at ...
>> ftp_list_width 32
>> ftp_passive on
>> connect_timeout 30 seconds
>> peer_connect_timeout 20 seconds
>> read_timeout 2 minutes
>> request_timeout 2 minutes
>> persistent_request_timeout 30 seconds
>> cache_dir ufs /var/cache/squid/ufs/squid 16000 64 64
>> cache_replacement_policy heap LFUDA memory_replacement_policy lru
>> cache_mem 200 MB maximum_object_size 32 MB
>> maximum_object_size_in_memory 128 KB quick_abort_min 16 KB
>> quick_abort_max 1 MB quick_abort_pct 90 range_offset_limit 64 KB acl
>> no_cache_url url_regex -i "/etc/squid/no_cache_url"
>> cache deny no_cache_url
> 
> Modern Squid define a set of "refresh_pattern" to fixup messages cacheability inline with HTTP/1.1 caching requirements.
> 
> Please add these lines:
> 
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> 
> 
> 
>> acl blows_chunks dstdomain .blr.com
>> header_access Accept-Encoding deny blows_chunks
> 
> This is something to look into. Be aware of how exactly that server is broken when it receives "Accept-Encoding" headers.
> 
> The old Squid only supported HTTP/1.0. Your new Squid supports HTTP/1.1 which may work better with whatever that server was doing to be considered bad.
> 
> 
>> auth_param ntlm program /usr/bin/ntlm_auth
>> --helper-protocol=squid-2.5-ntlmssp
>> auth_param ntlm children 30
>> auth_param ntlm keep_alive on
>> auth_param basic program /usr/bin/ntlm_auth
>> --helper-protocol=squid-2.5-basic auth_param basic children 5
>> auth_param basic realm "..."
>> auth_param basic credentialsttl 2 hours acl authenticated proxy_auth
>> REQUIRED acl all src 0.0.0.0/0.0.0.0
> 
> Remove the above line. The "all" ACL is now built-in.
> 
> 
>> acl src_self src 127.0.0.0/255.0.0.0
>> acl src_self src 10.46.11.20
> 
> Modern Squid provide these as a built-in "localhost" ACL.
> 
> To add the machines global IP address as part of localhost, replace the above two lines with:
>     acl localhost src 10.46.11.20/32
> 
> Then replace all uses of "src_self" with "localhost".
> 
> 
>> acl dst_self dst 127.0.0.0/255.0.0.0
>> acl dst_self dst 10.46.11.20
> 
> 
> Modern Squid provide these as a built-in "to_localhost" ACL.
> 
> To add the machines global IP address as part of localhost, replace the above two lines with:
>     acl to_localhost dst 10.46.11.20/32
> 
> Then replace all uses of "dst_self" with "to_localhost".
> 
> 
>> acl from_arc src 10.0.0.0/255.255.0.0
>> acl from_arc src 10.46.0.0/255.254.0.0 acl local_dst_addr dst
>> 10.0.0.0/255.0.0.0
> 
> FYI; while the above is acceptible to Squid. Prefer writing those as CIDR masks instead of NetMask syntax.
> 
>    eg.  10.0.0.0/8
> 
> 
>> acl local_dst_addr dst bldg3.*.com.
>> acl local_dst_addr dst bldg5.*.com.
>> acl local_dst_dom dstdomain arcgate
> 
> The above is not a domain name, nor wildcard domain.
> 
> FYI; Squid will attempt to apply a domain search using the "domain" or "search" as configured in /etc/resolv.conf and resolve arcgate.* in DNS.
> 
> 
>> acl proto_FTP proto FTP
>> acl proto_HTTP proto HTTP
>> acl http_ports port 80
>> acl http_ports port 81
>> acl http_ports port 82
>> acl http_ports port 807
>> acl http_ports port 8000
>> acl http_ports port 8001
>> acl http_ports port 8080
>> acl http_ports port 8081
>> acl http_ports port 9000
>> acl ssl_ports port 443
>> acl ssl_ports port 818
>> acl ssl_ports port 4435
>> acl ssl_ports port 9571
>> acl ssl_ports port 9030
>> acl ssl_ports port 4502
>> acl ssl_ports port 8080
>> acl ssl_ports port 8081
>> acl ssh_ports port 22 1776 8217
>> acl ftp_ports port 21
>> acl method_CONNECT method CONNECT
> 
> The "CONNECT" ACL is provided as a built-in.
> 
> Replace all uses of "method_CONNECT" with just "CONNECT" and remove the above line.
> 
> 
>> acl methods_std method GET HEAD POST PUT DELETE acl methods_std method
>> TRACE OPTIONS acl purge method PURGE http_access allow purge src_self
>> http_access deny purge
> 
> This purge is something to consider carefully. You should not need to ever use it on a properly working cache that obeys HTTP standard.
> 
> If possible prefer to remove the http_access and acl lines relating to the curstom "PURGE" method. This allows modern Squid to improve performance by not tracking a lot of things.
> 
> 
>> acl cache_manager proto cache_object
> 
> The "manager" ACL is provided as built-in by modern Squids, and has a different definition for the latest access mechanism(s).
> 
> Replace all uses of "cache_manager" with "manager" and remove the above line.
> 
> 
>> cachemgr_passwd disabled shutdown offline_toggle cachemgr_passwd none
>> all
> 
>> http_access allow cache_manager src_self http_access deny
>> cache_manager
> 
> Per earlier change requests this should become:
> 
>    http_access allow manager localhost
>    http_access deny manager
> 
> 
>> http_access deny dst_self
>> http_access deny src_self
> 
> 
> Per earlier change requests this should become:
> 
>    http_access deny localhost
>    http_access deny to_localhost
> 
>> http_access deny !from_arc
> 
>> http_access       allow local_dst_dom
>> http_reply_access allow local_dst_dom
> 
>> http_access       allow local_dst_addr
>> http_reply_access allow local_dst_addr
> 
>> acl authless_src src "/etc/squid/authless_src"
>> http_access       allow authless_src
>> http_reply_access allow authless_src
> 
>> acl authless_dst dstdomain "/etc/squid/authless_dst"
>> http_access       allow authless_dst
>> http_reply_access allow authless_dst
> 
>> acl bad_domains_preauth dstdomain "/etc/squid/bad_domains_preauth"
>> http_access deny bad_domains_preauth
> 
>> http_access deny !authenticated
> 
>> acl block_user proxy_auth_regex -i "/etc/squid/block_user"
>> http_access deny block_user
> 
>> acl bad_exception_urls url_regex -i "/etc/squid/bad_exception_urls"
>> acl exec_files url_regex -i "/etc/squid/exec_files"
>> acl exec_users proxy_auth_regex -i "/etc/squid/exec_users"
>> http_access deny !bad_exception_urls !exec_users exec_files deny_info
>> ERR_BLOCK_TYPE exec_files
> 
>> acl mmedia_users proxy_auth_regex -i "/etc/squid/mmedia_users"
>> acl mmedia_sites dstdomain "/etc/squid/mmedia_sites"
>> http_access       allow methods_std    proto_HTTP http_ports mmedia_sites mmedia_users
>> http_reply_access allow methods_std    proto_HTTP http_ports mmedia_sites mmedia_users
> 
>> http_access       allow method_CONNECT            ssl_ports  mmedia_sites mmedia_users
>> http_reply_access allow method_CONNECT            ssl_ports  mmedia_sites mmedia_users
> 
>> acl bad_domains dstdomain "/etc/squid/bad_domains"
>> http_access deny !bad_exception_urls bad_domains
>> deny_info ERR_BLOCK_DST       bad_domains
> 
>> acl bad_domains_regex dstdom_regex -i "/etc/squid/bad_domains_regex"
>> http_access deny !bad_exception_urls bad_domains_regex
>> deny_info ERR_BLOCK_DST       bad_domains_regex
> 
>> acl bad_urls url_regex -i "/etc/squid/bad_urls"
>> http_access deny !bad_exception_urls bad_urls
>> deny_info ERR_BLOCK_DST       bad_urls
> 
>> acl bad_files urlpath_regex -i "/etc/squid/bad_files"
>> http_access deny !bad_exception_urls bad_files deny_info
>> ERR_BLOCK_TYPE bad_files
> 
>> acl bad_types rep_mime_type -i "/etc/squid/bad_types"
>> http_reply_access deny bad_types !bad_exception_urls deny_info
>> ERR_BLOCK_TYPE bad_types
> 
>> acl fsoguest_user proxy_auth_regex -i fsoguest acl fsoguest_dst
>> dstdomain .opm.gov acl fsoguest_dst dstdomain .google-analytics.com
>> acl fsoguest_dst dstdomain pki.google.com acl fsoguest_dst dstdomain
>> ajax.googleapis.com acl fsoguest_dst dstdomain fonts.googleapis.com
>> acl fsoguest_dst dstdomain html5shiv.googlecode.com acl fsoguest_dst
>> dstdomain fonts.gstatic.com acl fsoguest_dst dstdomain
>> clients1.google.com acl fsoguest_dst dstdomain ajax.microsoft.com acl
>> fsoguest_dst dstdomain ajax.aspnetcdn.com acl fsoguest_dst dstdomain
>> .geotrust.com acl fsoguest_dst dstdomain .akamaihd.net acl
>> fsoguest_dst dstdomain symcd.com http_access allow methods_std
>> proto_HTTP http_ports fsoguest_dst fsoguest_user
>> http_access allow method_CONNECT         ssl_ports  fsoguest_dst fsoguest_user
>> http_access deny fsoguest_user
> 
>> http_access allow http_ports proto_HTTP methods_std
> 
>> acl ssh_users proxy_auth -i PCADMIN
>> acl ssh_users proxy_auth -i BSCOTT
>> http_access allow method_CONNECT ssh_ports ssh_users
> 
>> acl ssh_dst dst vthm.com
>> http_access allow method_CONNECT ssh_ports ssh_dst
> 
>> acl ftp_dst dst
>> http://www.a/
>> rc-tech.com%2F&data=05%7C02%7Cjosh.piana%40hexcel.com%7C69861412949747
>> 94b68b08dc6deddb54%7C4248050df19546d5ac9c0c7c52b04cae%7C0%7C0%7C638506
>> 115567977267%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luM
>> zIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=Rj6hxBCYCNqITDlpJ
>> QiS%2B8TlfOX6z6DbmVNOfHeD7sU%3D&reserved=0
> 
> I hoep that above line is a typo. A full URL is not valid for a "dst"
> ACL type.
> 
> The "dst" ACL values can be;
>    * a raw-IP, or
>    * a CIDR range, or
>    * a NetMask range (eg A-B/mask), or
>    * a hostname which is resolvable in DNS at Squid startup/reconfigure time.
> 
> 
>> acl ftp_dst dst ftp.telemeter.de
>> acl ftp_dst dst ftp.lucasindustries.com acl ftp_dst dst
>> ftp-upload.trendmicro.com http_access allow method_CONNECT ftp_dst
>> http_access allow method_CONNECT ssl_ports http_access deny
>> method_CONNECT
> 
>> http_access allow ftp_ports proto_FTP
>> http_access deny all
>> http_reply_access allow all
>>
> 
> 
> After making the above adjustments with Squid installed you should be aboe to run the command "squid -k parse -f /etc/squid/squid.conf.old" to see what the new Squid thinks of the old configuration.
> 
> Any "ERROR" lines that are displayed by by that command will need fixing before you can use Squid.
> 
> Any "WARNING" or "NOTICE" or "UPGRADE" are things that should be looked into fixing. But not urgent enough to make Squid unusable.
> 
> 
> You may need to run "squid -z -f /etc/squid/squid.conf.old" to create the cache directory.
> 
> 
> When that is fine you can move the /etc/squid/squid.conf.old to replace the /etc/squid/squid.conf and use the OS method for starting Squid.
> 
> Which for RHEL 9 I believe should be:
>      service squid start
> 
> 
> ... then start testing that what Squid does actually meets your expectations.
> 
> 
> HTH
> Amos
> 
> 
> 
> 
>> --------------------------------------------------------------
>>
>> Current Box squid -v Output:
>>
>> Squid Cache: Version 2.6.STABLE21
>>
>> configure options:  '--build=i386-redhat-linux-gnu' '--host=i386-redhat-linux-gnu' '--target=i386-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--includedir=/usr/include' '--libdir=/usr/lib' '--libexecdir=/usr/libexec' '--sharedstatedir=/usr/com' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--exec_prefix=/usr' '--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid' '--localstatedir=/var' '--datadir=/usr/share' '--sysconfdir=/etc/squid' '--enable-arp-acl' '--enable-epoll' '--enable-snmp' '--enable-removal-policies=heap,lru' '--enable-storeio=aufs,coss,diskd,null,ufs' '--enable-ssl' '--with-openssl=/usr/kerberos' '--enable-delay-pools' '--enable-linux-netfilter' '--with-pthreads' '--enable-ntlm-auth-helpers=SMB,fakeauth' '--enable-external-acl-helpers=ip_user,ldap_group,unix_group,wbinfo_group' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-digest-auth-helpers=password' '--with-winbind-auth-challenge' '--enable-useragent-log' '--enable-referer-log' '--disable-dependency-tracking' '--enable-cachemgr-hostname=localhost' '--enable-underscores' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL' '--enable-cache-digests' '--enable-ident-lookups' '--with-large-files' '--enable-follow-x-forwarded-for' '--enable-wccpv2' '--enable-fd-config' '--with-maxfd=16384' 'build_alias=i386-redhat-linux-gnu' 'host_alias=i386-redhat-linux-gnu' 'target_alias=i386-redhat-linux-gnu' 'CFLAGS=-D_FORTIFY_SOURCE=2 -fPIE -Os -g -pipe -fsigned-char' 'LDFLAGS=-pie'
>>
>> --------------------------------------------------------------
>>
>> New Box squid -v Output:
>>
>> Squid Cache: Version 5.5
>> Service Name: squid
>>
>> This binary uses OpenSSL 3.0.7 1 Nov 2022. For legal restrictions on
>> distribution see
>> https://www/.
>> openssl.org%2Fsource%2Flicense.html&data=05%7C02%7Cjosh.piana%40hexcel
>> .com%7C6986141294974794b68b08dc6deddb54%7C4248050df19546d5ac9c0c7c52b0
>> 4cae%7C0%7C0%7C638506115567977267%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4w
>> LjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sd
>> ata=SYACR6XE7IVCwGsCWdigcKjas80B5luo%2BHi8F6s5SFo%3D&reserved=0
>>
>> configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--localstatedir=/var' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--libexecdir=/usr/lib64/squid' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/run/squid.pid' '--disable-dependency-tracking' '--enable-eui' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,PAM,POP3,RADIUS,SASL,SMB,SMB_LM' '--enable-auth-ntlm=SMB_LM,fake' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos' '--enable-external-acl-helpers=LDAP_group,time_quota,session,unix_group,wbinfo_group,kerberos_ldap_group' '--enable-storeid-rewrite-helpers=file' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-ssl-crtd' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-diskio' '--enable-wccpv2' '--enable-esi' '--enable-ecap' '--with-aio' '--with-default-user=squid' '--with-dl' '--with-openssl' '--with-pthreads' '--disable-arch-native' '--disable-security-cert-validators' '--disable-strict-error-checking' '--with-swapdir=/var/spool/squid' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CC=gcc' 'CFLAGS=-O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection' 'LDFLAGS=-Wl,-z,relro -Wl,--as-needed  -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 ' 'CXX=g++' 'CXXFLAGS=-O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' 'LT_SYS_LIBRARY_PATH=/usr/lib64:'
>>
>> --------------------------------------------------------------
>>
>> -----Original Message-----
>> From: squid-users <squid-users-bounces at lists.squid-cache.org> On
>> Behalf Of Amos Jeffries
>> Sent: Friday, May 3, 2024 4:21 PM
>> To: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] Linux Noob - Squid Config
>>
>> [You don't often get email from squid3 at treenet.co.nz. Learn why this
>> is important at https://aka.ms/LearnAboutSenderIdentification ]
>>
>> Caution: This email originated from outside of Hexcel. Do not click links or open attachments unless you recognize the sender and know the content is safe.
>>
>>
>> On 4/05/24 07:59, Piana, Josh wrote:
>>> Hey Everyone.
>>>
>>> I apologize in advance for any lack of formality normally shared on
>>> mailing lists such as these, it?s my first time seeking product
>>> support in this manner.
>>>
>>
>> NO need to apologize. Help and questions is most of what we do here
>> :-)
>>
>>
>>> I want to start by saying that I?m new to Linux, been using Windows
>>> environments my entire life. Such is the reason for me reaching out
>>> to you all.
>>>
>>> I have been tasked with modernizing a Squid box and feel very
>>> overwhelmed, to say the least.
>>>
>>> Current Setup:
>>>
>>> ?CentOS 5.0
>>>
>>> ?Squid 2.3
>>>
>>> ?Apache 2.0.46
>>>
>>> ?Samba 3.0.9
>>>
>>> Desired Setup:
>>>
>>> ?RHEL 9.2 OS
>>>
>>> ?Needs to qualify for NTLM authentication
>>>
>>
>> Hmm, does it *have* to be NTLM? that auth protocol was deprecated in 2006.
>>
>>
>>> ?Would like to remove legacy apps/services
>>>
>>> ?Continue to authenticate outgoing communication via AD
>>>
>>> My question is, how do I get all of these services/apps to work
>>> together? Do I just install the newest versions of each and migrate
>>> the existing config files?
>>>
>>> I was hoping for a better understanding on how all of these work
>>> together and exactly how to configure or edit these as needed. I?ve
>>> gotten as far as installing RHEL 9.2 on a fresh VM Server and trying
>>> as best as I can to learn the basics on Linux and just the general
>>> operation of a Linux ran environment. It feels like trying to ride a
>>> bike with box wheels.
>>>
>>
>>
>> The installation of a basic Squid service for RHEL is easy.
>> Just open a terminal and enter this command:
>>
>>       yum install squid
>>
>>
>> The next part is going over your old Squid configuration to see how much of it remains necessary or can be updated. It would be useful for the next steps to copy it to the RHEL machine as /etc/squid/squid.conf.old .
>>
>> You can likely find it on the CentOS machine at /etc/squid/squid.conf or /usr/share/squid/etc/squid.conf depending on how that Squid was built.
>>
>>
>> If you are able to paste the contents of that file (without the '#'
>> comment or empty lines) here, we can assist with getting the new Squid doing the same or equivalent actions.
>>
>>
>> Also please paste the output of "squid -v" run on both the old CentOS machine and on the new RHEL.
>>
>>
>> Cheers
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://list/
>> s.squid-cache.org%2Flistinfo%2Fsquid-users&data=05%7C02%7Cjosh.piana%4
>> 0hexcel.com%7C6986141294974794b68b08dc6deddb54%7C4248050df19546d5ac9c0
>> c7c52b04cae%7C0%7C0%7C638506115567977267%7CUnknown%7CTWFpbGZsb3d8eyJWI
>> joiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7
>> C%7C&sdata=tm3ZL54tYg9GI5l1LlqjR9vQN8o%2BRcjshffEoKxMH%2FA%3D&reserved
>> =0
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

From Albert.Shih at obspm.fr  Wed May  8 07:55:04 2024
From: Albert.Shih at obspm.fr (Albert Shih)
Date: Wed, 8 May 2024 09:55:04 +0200
Subject: [squid-users] Dynamic ACL with local auth
In-Reply-To: <000301da9f96$bcf19270$36d4b750$@gmail.com>
References: <ZjiZc8LLSYmXma5V@io.chezmoi.fr>
 <000301da9f96$bcf19270$36d4b750$@gmail.com>
Message-ID: <Zjsv2G5vV_epsTpS@io.chezmoi.fr>

Le 06/05/2024 ? 12:21:10+0300, ngtech1ltd at gmail.com a ?crit
Hi, 

> 
> The right way to do it is to use an external acl helper that will use some kind of database for the settings.

Ok. I will check that. 

> The other option is to use a reloadable ACLs file.

But those this reload need a restart of the service ? 

> But you need to clarify exactly the goal if you want more then a basic advise.

Well..pretty simple task I need to build a squid server to allow/deny
people access to some data (website) because those website don't support
authentication. 

But the rule of access ?allow/deny? are manage in other place through
another application. 

So the goal is to have some ?thing? who going to retrieve the ?permissions?
of the user and apply the ACL on squid. 

It's not ?ultra dynamic? the modification of the permissions will occur
time to time. So even a reload will do.....if the reload don't need a
shutdown of squid. 

Thanks. 

Regards

-- 
Albert SHIH ? ?
France
Heure locale/Local time:
mer. 08 mai 2024 09:51:00 CEST


From ngtech1ltd at gmail.com  Wed May  8 08:42:53 2024
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Wed, 8 May 2024 11:42:53 +0300
Subject: [squid-users] Dynamic ACL with local auth
In-Reply-To: <Zjsv2G5vV_epsTpS@io.chezmoi.fr>
References: <ZjiZc8LLSYmXma5V@io.chezmoi.fr>
 <000301da9f96$bcf19270$36d4b750$@gmail.com> <Zjsv2G5vV_epsTpS@io.chezmoi.fr>
Message-ID: <003701daa123$b8806340$298129c0$@gmail.com>

Hey Albert,

It's preferable to use an external ACL compared to reloading the squid conf in general.
It will probably require to use external acl helper with the authenticated username as a detail which is being sent to the helper.
Let's take an example.org squid.conf for the "project".
On what ports squid listens? 80 and 443?
It's a reverse proxy or a forward proxy which is defined in the client browser?

An "auto" reload of squid can be done using couple of systemd triggers.
If it's enough for you I can try to research how it can be done and we will go on from there.
If you wish to choose the "dark" path of external_acl helper development I will also be happy to try and
assist you in my spare time (which is not a lot these days).

Eliezer

-----Original Message-----
From: Albert Shih <Albert.Shih at obspm.fr> 
Sent: Wednesday, May 8, 2024 10:55 AM
To: ngtech1ltd at gmail.com
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Dynamic ACL with local auth

Le 06/05/2024 ? 12:21:10+0300, ngtech1ltd at gmail.com a ?crit
Hi, 

> 
> The right way to do it is to use an external acl helper that will use some kind of database for the settings.

Ok. I will check that. 

> The other option is to use a reloadable ACLs file.

But those this reload need a restart of the service ? 

> But you need to clarify exactly the goal if you want more then a basic advise.

Well..pretty simple task I need to build a squid server to allow/deny
people access to some data (website) because those website don't support
authentication. 

But the rule of access ?allow/deny? are manage in other place through
another application. 

So the goal is to have some ?thing? who going to retrieve the ?permissions?
of the user and apply the ACL on squid. 

It's not ?ultra dynamic? the modification of the permissions will occur
time to time. So even a reload will do.....if the reload don't need a
shutdown of squid. 

Thanks. 

Regards

-- 
Albert SHIH ? ?
France
Heure locale/Local time:
mer. 08 mai 2024 09:51:00 CEST



From squid3 at treenet.co.nz  Wed May  8 16:16:03 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 9 May 2024 04:16:03 +1200
Subject: [squid-users] Dynamic ACL with local auth
In-Reply-To: <Zjsv2G5vV_epsTpS@io.chezmoi.fr>
References: <ZjiZc8LLSYmXma5V@io.chezmoi.fr>
 <000301da9f96$bcf19270$36d4b750$@gmail.com> <Zjsv2G5vV_epsTpS@io.chezmoi.fr>
Message-ID: <a4f1cf47-4421-4919-be24-072152362647@treenet.co.nz>

On 8/05/24 19:55, Albert Shih wrote:
> Le 06/05/2024 ? 12:21:10+0300, ngtech1ltda ?crit
> Hi,
> 
>>
>> The right way to do it is to use an external acl helper that will use some kind of database for the settings.
> 
> Ok. I will check that.
> 
>> The other option is to use a reloadable ACLs file.
> 
> But those this reload need a restart of the service ?
> 
>> But you need to clarify exactly the goal if you want more then a basic advise.
> 
> Well..pretty simple task

Ah, this is about equivalent to "just create life" level of simplicity.


I expect that what you need is doable, but not in the way you are 
describing so far.


(p-PS. If you can mention how much experience you have working with 
Squid configuration it will help us know how much detail we can skip 
over when offering options.)



> I need to build a squid server to allow/deny
> people access to some data (website) because those website don't support
> authentication.
> 

So Squid needs to authenticate. Is that every request or on a 
per-resource (URL) basis?

  A) needs only simple auth setup
or
  B) needs auth setup, with ACL(s) defining when to authenticate


> But the rule of access ?allow/deny? are manage in other place through
> another application.
> 

What criteria/details is this other application checking?

Can any of its decision logic be codified as a sequence of Squid ACL 
types checked in some specific order?

How are you expecting Squid to communicate with it?


> So the goal is to have some ?thing? who going to retrieve the ?permissions?
> of the user and apply the ACL on squid.
> 

Please explain/clarify what **exactly** a "permission" is in your design?


Cheers
Amos


From jonathanlee571 at gmail.com  Wed May  8 17:02:31 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 8 May 2024 17:02:31 +0000
Subject: [squid-users] Dynamic ACL with local auth
In-Reply-To: <Zjsv2G5vV_epsTpS@io.chezmoi.fr>
References: <ZjiZc8LLSYmXma5V@io.chezmoi.fr>
 <000301da9f96$bcf19270$36d4b750$@gmail.com> <Zjsv2G5vV_epsTpS@io.chezmoi.fr>
Message-ID: <DS0PR19MB72704CC8150578CB48016509A7E52@DS0PR19MB7270.namprd19.prod.outlook.com>

for dynamic assignment you could could use domian based ACLs they are slow match however you could make a list to do this with
________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Albert Shih <Albert.Shih at obspm.fr>
Sent: Wednesday, May 8, 2024 00:55
To: ngtech1ltd at gmail.com <ngtech1ltd at gmail.com>
Cc: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Dynamic ACL with local auth

Le 06/05/2024 ? 12:21:10+0300, ngtech1ltd at gmail.com a ?crit
Hi,

>
> The right way to do it is to use an external acl helper that will use some kind of database for the settings.

Ok. I will check that.

> The other option is to use a reloadable ACLs file.

But those this reload need a restart of the service ?

> But you need to clarify exactly the goal if you want more then a basic advise.

Well..pretty simple task I need to build a squid server to allow/deny
people access to some data (website) because those website don't support
authentication.

But the rule of access ?allow/deny? are manage in other place through
another application.

So the goal is to have some ?thing? who going to retrieve the ?permissions?
of the user and apply the ACL on squid.

It's not ?ultra dynamic? the modification of the permissions will occur
time to time. So even a reload will do.....if the reload don't need a
shutdown of squid.

Thanks.

Regards

--
Albert SHIH ? ?
France
Heure locale/Local time:
mer. 08 mai 2024 09:51:00 CEST
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240508/26ecafab/attachment.htm>

From rousskov at measurement-factory.com  Wed May  8 18:31:52 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 8 May 2024 14:31:52 -0400
Subject: [squid-users] Error from icap during respmod
In-Reply-To: <1650153442.7740770.1715038797924@mail.yahoo.com>
References: <166088187.5074521.1714410400274.ref@mail.yahoo.com>
 <166088187.5074521.1714410400274@mail.yahoo.com>
 <6ad59ee8-714a-48d3-bfec-a8d239bade05@measurement-factory.com>
 <1650153442.7740770.1715038797924@mail.yahoo.com>
Message-ID: <b8c5127e-374f-4b17-bafe-85838f5dc8ec@measurement-factory.com>

On 2024-05-06 19:39, Arun Kumar wrote:
> Are you aware of any compatible 
> Python or Java based iCAP server implemenation?

I am not aware of any Python- or Java-based ICAP service that I can 
recommend. AFAIK, most folks looking for a free ICAP service (that 
resist the temptation to reinvent a rather complex wheel) use c-icap, 
but c-icap is written in C: https://c-icap.sourceforge.net/

Please note that if my triage is correct, then the issue here is not 
"compatibility" with Squid. It is a serious ICAP service bug or 
misconfiguration.


Good luck,

Alex.


> We want to implement 
> custom virus scanning of the response.
> I got the book /Squid: The Definitive Guide /and going over for more 
> understanding. Saw your name mentioned by the author. I am very proud to 
> work with great people like you.
> 
> 
> On Thursday, May 2, 2024 at 04:18:45 PM EDT, Alex Rousskov 
> <rousskov at measurement-factory.com> wrote:
> 
> 
> On 2024-04-29 13:06, Arun Kumar wrote:
>  > Configured python based icap server (pyicap) and getting 500 Internal
>  > Server error during respmod.
> 
> AFAICT, this ICAP RESPMOD service is buggy: It sends what looks like an
> HTTP response body chunk after sending an ICAP 100 Continue control
> message. Instead, it is supposed to send the final ICAP response headers
> and HTTP response headers _before_ sending that HTTP response body chunk.
> 
> 
>  ? ? 00:50:54.989 ... ReadNow: conn33 ... size 65535, retval 25
>  ? ? ICAP/1.0 100 Continue
> 
> 
>  ? ? 00:50:54.991 ReadNow: conn33 ... size 65535, retval 137
>  ? ? 83
>  ? ? {"activity":...}
> 
> 
> HTH,
> 
> Alex.
> 
> 
>  > 
> https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing <https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing> <https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing <https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing>>
>  >
>  > Squid configuration:
>  > icap_enable on
>  > icap_send_client_ip on
>  > icap_send_client_username on
>  > icap_client_username_encode off
>  > icap_client_username_header X-Authenticated-User
>  > icap_preview_enable on
>  > icap_preview_size 1024
>  >
>  > icap_service service_req reqmod_precache bypass=0
>  > icap://127.0.0.1:13440/example
>  > icap_service service_resp respmod_precache bypass=0
>  > icap://127.0.0.1:13441/example
> 
>  >
>  >
>  >
>  > _______________________________________________
>  > squid-users mailing list
>  > squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
>  > https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
> 
> 



From eracton at gmail.com  Sat May 11 21:59:31 2024
From: eracton at gmail.com (Vilmondes Queiroz)
Date: Sat, 11 May 2024 18:59:31 -0300
Subject: [squid-users] deny_info URL not working
Message-ID: <CAOef84=qcf17mLARitkihtA5pvNxbHE3wumn-yOXX-bzTdqp2A@mail.gmail.com>

Hello,

squid -v
Squid Cache: Version 6.6

What am I doing wrong here?

*squid.conf:*
external_acl_type ip_validator ttl=3600 negative_ttl=10 %SRC
/usr/bin/python3 /home/ubuntu/squid/authentication.py

acl authorized_ips external ip_validator

deny_info http://example.com !authorized_ips

http_access allow authorized_ips
http_access deny !authorized_ips
http_access deny all

I'm not getting redirected to the URL when squid refused the connection.

I can see in the access.log that the connection is getting rejected.

This is a fresh squid installation. The only changes I made to the conf
file are the above lines.

Appreciate your help!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240511/a270a1fc/attachment.htm>

From squid.org at bloms.de  Sun May 12 05:48:59 2024
From: squid.org at bloms.de (Dieter Bloms)
Date: Sun, 12 May 2024 07:48:59 +0200
Subject: [squid-users] deny_info URL not working
In-Reply-To: <CAOef84=qcf17mLARitkihtA5pvNxbHE3wumn-yOXX-bzTdqp2A@mail.gmail.com>
References: <CAOef84=qcf17mLARitkihtA5pvNxbHE3wumn-yOXX-bzTdqp2A@mail.gmail.com>
Message-ID: <20240512054859.qptg7vksvs3xbkny@bloms.de>

Hello,

On Sat, May 11, Vilmondes Queiroz wrote:

> deny_info http://example.com !authorized_ips

does it works, if you add the http status code like:

deny_info 307:http://example.com !authorized_ips


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From squid3 at treenet.co.nz  Sun May 12 11:44:34 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 12 May 2024 23:44:34 +1200
Subject: [squid-users] deny_info URL not working
In-Reply-To: <20240512054859.qptg7vksvs3xbkny@bloms.de>
References: <CAOef84=qcf17mLARitkihtA5pvNxbHE3wumn-yOXX-bzTdqp2A@mail.gmail.com>
 <20240512054859.qptg7vksvs3xbkny@bloms.de>
Message-ID: <0fd144e0-eb51-4686-a5c1-98124acead26@treenet.co.nz>

On 12/05/24 17:48, Dieter Bloms wrote:
> Hello,
> 
> On Sat, May 11, Vilmondes Queiroz wrote:
> 
>> deny_info http://example.com !authorized_ips
> 
> does it works, if you add the http status code like:
> 
> deny_info 307:http://example.com !authorized_ips
> 

Also the "!" is not valid here. The ACL on deny_info lines is the name 
of the one that is to be adjusted when it is used for a "deny" action 
by, for example, "http_access deny".


   acl authorized_ips src ...
   deny_info 307:http://example.com authorized_ips
   http_access deny !authorized_ips


HTH
Amos


From andre.bolinhas at articatech.com  Wed May 15 00:56:02 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Wed, 15 May 2024 01:56:02 +0100
Subject: [squid-users] Squid returns a lot of ABORTED in access log and user
 navigation speed slows
Message-ID: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>

Hi

Sometimes my users complains that the internet navigation thought Squid 
is very slow.

After checking the access.log, I can see a lot of ABORTED messages like this

1715537802.589????? 2 10.103.12.94 NONE_NONE_ABORTED/200 0 CONNECT 
api.telegram.org:443 - HIER_NONE/-:- - mac="00:00:00:00:00:00" 
accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT"

1715537183.180? 99993 172.16.31.205 TCP_MISS_ABORTED/000 0 POST 
http://pjcpd-dlpend01.hlbank.my/GECommunicationWS.asmx - HIER_NONE/-:- - 
mac="00:00:00:00:00:00" accessrule:%20global_whitelist%0D%0A 
exterr="ERR_CLIENT_GONE|WITH_CLIENT"

I have imported the access.log into my ELK machine and I can see that 
during the time that the users complained about the slowness there is a 
huge spike of NONE_ABORTED messages.

https://i.postimg.cc/6QR79GWk/6e727e86-de3d-4f3b-bd9e-04c04052ca2e.jpg

Now my question is:
1. What can cause this kind of issue? It's a squid server issue, network 
(firewall, switch, router, ?), or client?
2. Why the number of NONE_ABORTED requests is almost 4 time more than 
normal request?

Best regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240515/e2db5052/attachment.htm>

From jonathanlee571 at gmail.com  Wed May 15 17:15:56 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 15 May 2024 10:15:56 -0700
Subject: [squid-users] Squid returns a lot of ABORTED in access log and
 user navigation speed slows
In-Reply-To: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>
References: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>
Message-ID: <7B56260D-F777-4B85-AF0A-6607A21FA292@gmail.com>

Have you researched enabling pipeline_prefetch??

> On May 14, 2024, at 17:56, Andre Bolinhas <andre.bolinhas at articatech.com> wrote:
> 
> Hi
> 
> Sometimes my users complains that the internet navigation thought Squid is very slow.
> 
> After checking the access.log, I can see a lot of ABORTED messages like this
> 
> 1715537802.589      2 10.103.12.94 NONE_NONE_ABORTED/200 0 CONNECT api.telegram.org:443 - HIER_NONE/-:- - mac="00:00:00:00:00:00" accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT"
> 
> 1715537183.180  99993 172.16.31.205 TCP_MISS_ABORTED/000 0 POST http://pjcpd-dlpend01.hlbank.my/GECommunicationWS.asmx - HIER_NONE/-:- - mac="00:00:00:00:00:00" accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT"
> 
> I have imported the access.log into my ELK machine and I can see that during the time that the users complained about the slowness there is a huge spike of NONE_ABORTED messages.
> 
> https://i.postimg.cc/6QR79GWk/6e727e86-de3d-4f3b-bd9e-04c04052ca2e.jpg
> 
> Now my question is:
> 1. What can cause this kind of issue? It's a squid server issue, network (firewall, switch, router, ?), or client?
> 2. Why the number of NONE_ABORTED requests is almost 4 time more than normal request?
> 
> Best regards
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240515/fd650ef9/attachment.htm>

From andre.bolinhas at articatech.com  Wed May 15 18:08:25 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Wed, 15 May 2024 19:08:25 +0100
Subject: [squid-users] Squid returns a lot of ABORTED in access log and
 user navigation speed slows
In-Reply-To: <7B56260D-F777-4B85-AF0A-6607A21FA292@gmail.com>
References: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>
 <7B56260D-F777-4B85-AF0A-6607A21FA292@gmail.com>
Message-ID: <9eed0c7b-55d2-4e2b-95cc-594b0750f4b9@articatech.com>

Hi

Thanks for your response

I'm not using pipeline_prefetch, because pipeline_prefetch breaks the 
NTLM/Kerberos authentication.


On 15/05/2024 18:15, Jonathan Lee wrote:
> Have you researched enabling pipeline_prefetch??
>
>> On May 14, 2024, at 17:56, Andre Bolinhas 
>> <andre.bolinhas at articatech.com> wrote:
>>
>> Hi
>>
>> Sometimes my users complains that the internet navigation thought 
>> Squid is very slow.
>>
>> After checking the access.log, I can see a lot of ABORTED messages 
>> like this
>>
>> 1715537802.589????? 2 10.103.12.94 NONE_NONE_ABORTED/200 0 CONNECT 
>> api.telegram.org:443 - HIER_NONE/-:- - mac="00:00:00:00:00:00" 
>> accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>
>> 1715537183.180? 99993 172.16.31.205 TCP_MISS_ABORTED/000 0 POST 
>> http://pjcpd-dlpend01.hlbank.my/GECommunicationWS.asmx - 
>> HIER_NONE/-:- - mac="00:00:00:00:00:00" 
>> accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>
>> I have imported the access.log into my ELK machine and I can see that 
>> during the time that the users complained about the slowness there is 
>> a huge spike of NONE_ABORTED messages.
>>
>> https://i.postimg.cc/6QR79GWk/6e727e86-de3d-4f3b-bd9e-04c04052ca2e.jpg
>>
>> Now my question is:
>> 1. What can cause this kind of issue? It's a squid server issue, 
>> network (firewall, switch, router, ?), or client?
>> 2. Why the number of NONE_ABORTED requests is almost 4 time more than 
>> normal request?
>>
>> Best regards
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240515/3fba20be/attachment.htm>

From rousskov at measurement-factory.com  Wed May 15 18:24:50 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 15 May 2024 14:24:50 -0400
Subject: [squid-users] Squid returns a lot of ABORTED in access log and
 user navigation speed slows
In-Reply-To: <9eed0c7b-55d2-4e2b-95cc-594b0750f4b9@articatech.com>
References: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>
 <7B56260D-F777-4B85-AF0A-6607A21FA292@gmail.com>
 <9eed0c7b-55d2-4e2b-95cc-594b0750f4b9@articatech.com>
Message-ID: <25eb4d61-f618-4358-9f39-de6427d4d94d@measurement-factory.com>

On 2024-05-15 14:08, Andre Bolinhas wrote:

> I'm not using pipeline_prefetch, because pipeline_prefetch breaks the 
> NTLM/Kerberos authentication.


Enabling pipeline_prefetch introduces other problems as well. There 
might be some very special use cases that benefit from pipeline_prefetch 
today, but, in general, that directive should not be used (and the whole 
feature should be removed from Squid until it is properly implemented).

I cannot currently answer your primary questions on this thread. I hope 
somebody else will guide you through this triage.

Alex.


> On 15/05/2024 18:15, Jonathan Lee wrote:
>> Have you researched enabling pipeline_prefetch??
>>
>>> On May 14, 2024, at 17:56, Andre Bolinhas 
>>> <andre.bolinhas at articatech.com> wrote:
>>>
>>> Hi
>>>
>>> Sometimes my users complains that the internet navigation thought 
>>> Squid is very slow.
>>>
>>> After checking the access.log, I can see a lot of ABORTED messages 
>>> like this
>>>
>>> 1715537802.589????? 2 10.103.12.94 NONE_NONE_ABORTED/200 0 CONNECT 
>>> api.telegram.org:443 - HIER_NONE/-:- - mac="00:00:00:00:00:00" 
>>> accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>>
>>> 1715537183.180? 99993 172.16.31.205 TCP_MISS_ABORTED/000 0 POST 
>>> http://pjcpd-dlpend01.hlbank.my/GECommunicationWS.asmx - 
>>> HIER_NONE/-:- - mac="00:00:00:00:00:00" 
>>> accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>>
>>> I have imported the access.log into my ELK machine and I can see that 
>>> during the time that the users complained about the slowness there is 
>>> a huge spike of NONE_ABORTED messages.
>>>
>>> https://i.postimg.cc/6QR79GWk/6e727e86-de3d-4f3b-bd9e-04c04052ca2e.jpg
>>>
>>> Now my question is:
>>> 1. What can cause this kind of issue? It's a squid server issue, 
>>> network (firewall, switch, router, ?), or client?
>>> 2. Why the number of NONE_ABORTED requests is almost 4 time more than 
>>> normal request?
>>>
>>> Best regards
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>>
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From andre.bolinhas at articatech.com  Wed May 15 23:02:00 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Thu, 16 May 2024 00:02:00 +0100
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <000901d816b2$2d21cfd0$87656f70$@gmail.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD3FXIJWgsSQLJz3KxHKB5yAQAAAAA=@articatech.com>
 <CABA8h=QBGofnCPuXqd5F_yF_M=mV_G7FVucRtZ7mWJAx_WbiFg@mail.gmail.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACQee6iB+9UQbA7yyJVYK9FAQAAAAA=@articatech.com>
 <000901d816b2$2d21cfd0$87656f70$@gmail.com>
Message-ID: <01aa3f58-73a3-4f14-90fd-cba2234da3ed@articatech.com>

Hi

To handle this amount of traffic should I enable 
client_persistent_connections and server_persistent_connections or is it 
better to keep it disable?

Best regards

On 31/01/2022 14:52, Eliezer Croitoru wrote:
>
> Hey Andre,
>
> I *would not *recommend on 5.x yet since there are couple bugs which 
> are blocking it to be used as stable.
>
> I believe that your current setup is pretty good.
>
> The only thing which might affect the system is the authentication and 
> ACLs.
>
> As long these ACL rules are static it should not affect too much on 
> the operation, however,
> When adding external authentication and external helpers for other 
> things it?s possible to see some slowdown in specific scenarios.
>
> As long as the credentials and the ACLs will be fast enough it is 
> expected to work fast but only testing will prove how the real world usage
> will affect the service.
>
> I believe that 5 workers is enough and also take into account that the 
> external helpers would also require CPU so don?t rush into
> changing the workers amount just yet.
>
> All The Bests,
>
> Eliezer
>
> ----
>
> Eliezer Croitoru
>
> NgTech, Tech Support
>
> Mobile: +972-5-28704261
>
> Email: ngtech1ltd at gmail.com
>
> *From:* Andr? Bolinhas <andre.bolinhas at articatech.com>
> *Sent:* Monday, January 31, 2022 15:47
> *To:* 'NgTech LTD' <ngtech1ltd at gmail.com>
> *Cc:* 'Squid Users' <squid-users at lists.squid-cache.org>
> *Subject:* RE: [squid-users] Tune Squid proxy to handle 90k connection
>
> Hi
>
> I will not use cache in this project.
>
> Yes, I will need
>
>   * ACL (based on Domain, AD user, Headers, User Agent?)
>   * Authentication
>   * SSL bump just for one domain.
>   * DNS resolution (I will use Unbound DNS service for this)
>
> Also, I will divide the traffic between two Squid box instead just one.
>
> So each box will handle around 50k request.
>
> Each box have:
>
>   * CPU(s) 16
>   * Threads per code 2
>   * Cores per socket 8
>   * Sockets 1
>   * Inter Xeron Silver 4208? @ 2.10GHz
>   * 96GB Ram
>   * 1TB raid-0 SSD
>
> At this time I have 5 workers on each Squid box and the Squid version 
> is 4.17, do you recommend more workers or upgrade the squid version to 5?
>
> Best regards
>
> *De:*NgTech LTD <ngtech1ltd at gmail.com>
> *Enviada:* 31 de janeiro de 2022 04:59
> *Para:* Andr? Bolinhas <andre.bolinhas at articatech.com>
> *Cc:* Squid Users <squid-users at lists.squid-cache.org>
> *Assunto:* Re: [squid-users] Tune Squid proxy to handle 90k connection
>
> I would recommend you to start with 0 caching.
>
> However, for choosing the right solution you must give more details.
>
> For example there is an IBM reasearch that prooved that for about 90k 
> connections you can use vm's ontop of such hardware with apache web 
> server.
>
> If you do have the set of the other requirements from the proxy else 
> then the 90k requests it would be wise to mention them.
>
> Do you need any specific acls?
>
> Do you need authentication?
>
> etc..
>
> For a simple forward proxy I would suggest to use a simpler solution 
> and if possible to not log anything as a starter point.
>
> Any local disk i/o will slow down the machine.
>
> About the url categorization, I do not have experience with ufdbguard 
> on such scale but it would be pretty heavy for any software to handle 
> 90k rps...
>
> ?It's doable to implement such setup but will require testing.
>
> Will you use ssl bump in this setup?
>
> If I will have all the technical and specs/requirements details I 
> might be able to suggest better then now.
>
> Take into account that each squid worker can handle about 3k rps 
> tops(with my experience) and it's a juggling between two sides so... 
> 3k is really 3k+3k+external_acls+dns...
>
> I believe that in this case an example of configuration from the squid 
> developers might be usefull.
>
> Eliezer
>
> ?????? ??? ??, 25 ????? 2022, 18:42, ???Andr? Bolinhas 
> ?<andre.bolinhas at articatech.com>:
>
>     Any tip about my last comment?
>
>     -----Mensagem original-----
>     De: Andr? Bolinhas <andre.bolinhas at articatech.com>
>     Enviada: 21 de janeiro de 2022 16:36
>     Para: 'Amos Jeffries' <squid3 at treenet.co.nz>;
>     squid-users at lists.squid-cache.org
>     Assunto: RE: [squid-users] Tune Squid proxy to handle 90k connection
>
>     Thanks Amos
>     Yes, you are right, I will put a second box with HaProxy in front
>     to balance the traffic.
>     About the sockets I can't double it because is a physical machine,
>     do you think disable hyperthreading from bios will help, because
>     we have other services inside the box that works in
>     multi-threading, like unbound DNS?
>
>     Just more a few questions:
>     1? The server have 92Gb of Ram, do you think that is needed that
>     adding swap will help squid performance?
>     2? Right now we are using squid 4.17 did you recommend upgrade or
>     downgrade to any specific version?
>     3? We need categorization, for this we are using an external
>     helper to achieve it, do you recommend use this approach with ACL
>     or move to some kind of ufdbguard service?
>
>     Best regards
>     -----Mensagem original-----
>     De: squid-users <squid-users-bounces at lists.squid-cache.org> Em
>     Nome De Amos Jeffries
>     Enviada: 21 de janeiro de 2022 16:05
>     Para: squid-users at lists.squid-cache.org
>     Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection
>
>     Sorry for the slow reply. Responses inline.
>
>
>     On 14/01/22 05:44, Andr? Bolinhas wrote:
>     > Hi
>     > ~80k request per second? 10k users
>
>
>     Test this, but you may need a second machine to achieve the full
>     80k RPS.
>
>     Latest Squid do not have any details analysis, but older Squid-3.5
>     were only achieving >15k RPS under lab conditions, more likely
>     expect under 10k RPS/worker on real traffic.
>     ? That means (IME) this machine is quite likely to hit its
>     capacity somewhere under 70k RPS.
>
>
>     > CPU info:
>     > CPU(s) 16
>     > Threads per code 2
>     > Cores per socket 8
>
>     With this CPU you will be able to run 7 workers. Setup affinity of
>     one core per worker (the "kidN" processes of Squid). Leaving one
>     core to the OS and additional processing needs - this matters at
>     peak loading.
>
>     CPU "threads" tend not to be useful for Squid. Under high loads
>     Squid workers will consume all available cycles on their core, not
>     leaving any for the fancy "thread" core sharing features to
>     pretend there is another core available. YMMV. One of the tests to
>     try when tuning is to turn off the CPU hyperthreading and see what
>     effect it has (if any).
>
>
>     > Sockets 1
>     > Inter Xeron Silver 4208? @ 2.10GHz
>     >
>
>     Okay. Doable, but for best performance you want as high GHz rating
>     on the cores as your budget can afford. The amount of "lag" Squid
>     adds to traffic and RPS performance/parallelism directly
>     correlates with how fast the CPU core can run cycles.
>
>
>
>     HTH
>     Amos
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     http://lists.squid-cache.org/listinfo/squid-users
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240516/022391cd/attachment.htm>

From andre.bolinhas at articatech.com  Thu May 16 00:16:44 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Thu, 16 May 2024 01:16:44 +0100
Subject: [squid-users] Squid returns a lot of ABORTED in access log and
 user navigation speed slows
In-Reply-To: <25eb4d61-f618-4358-9f39-de6427d4d94d@measurement-factory.com>
References: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>
 <7B56260D-F777-4B85-AF0A-6607A21FA292@gmail.com>
 <9eed0c7b-55d2-4e2b-95cc-594b0750f4b9@articatech.com>
 <25eb4d61-f618-4358-9f39-de6427d4d94d@measurement-factory.com>
Message-ID: <1d343770-efba-4f29-87e8-d5dc173ec937@articatech.com>

Hi Alex
Thanks for your feedback, in this case enable 
client_persistent_connections and server_persistent_connections could 
help or is better to keep it disable?

Best regards

On 15/05/2024 19:24, Alex Rousskov wrote:
> On 2024-05-15 14:08, Andre Bolinhas wrote:
>
>> I'm not using pipeline_prefetch, because pipeline_prefetch breaks the 
>> NTLM/Kerberos authentication.
>
>
> Enabling pipeline_prefetch introduces other problems as well. There 
> might be some very special use cases that benefit from 
> pipeline_prefetch today, but, in general, that directive should not be 
> used (and the whole feature should be removed from Squid until it is 
> properly implemented).
>
> I cannot currently answer your primary questions on this thread. I 
> hope somebody else will guide you through this triage.
>
> Alex.
>
>
>> On 15/05/2024 18:15, Jonathan Lee wrote:
>>> Have you researched enabling pipeline_prefetch??
>>>
>>>> On May 14, 2024, at 17:56, Andre Bolinhas 
>>>> <andre.bolinhas at articatech.com> wrote:
>>>>
>>>> Hi
>>>>
>>>> Sometimes my users complains that the internet navigation thought 
>>>> Squid is very slow.
>>>>
>>>> After checking the access.log, I can see a lot of ABORTED messages 
>>>> like this
>>>>
>>>> 1715537802.589????? 2 10.103.12.94 NONE_NONE_ABORTED/200 0 CONNECT 
>>>> api.telegram.org:443 - HIER_NONE/-:- - mac="00:00:00:00:00:00" 
>>>> accessrule:%20global_whitelist%0D%0A 
>>>> exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>>>
>>>> 1715537183.180? 99993 172.16.31.205 TCP_MISS_ABORTED/000 0 POST 
>>>> http://pjcpd-dlpend01.hlbank.my/GECommunicationWS.asmx - 
>>>> HIER_NONE/-:- - mac="00:00:00:00:00:00" 
>>>> accessrule:%20global_whitelist%0D%0A 
>>>> exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>>>
>>>> I have imported the access.log into my ELK machine and I can see 
>>>> that during the time that the users complained about the slowness 
>>>> there is a huge spike of NONE_ABORTED messages.
>>>>
>>>> https://i.postimg.cc/6QR79GWk/6e727e86-de3d-4f3b-bd9e-04c04052ca2e.jpg
>>>>
>>>> Now my question is:
>>>> 1. What can cause this kind of issue? It's a squid server issue, 
>>>> network (firewall, switch, router, ?), or client?
>>>> 2. Why the number of NONE_ABORTED requests is almost 4 time more 
>>>> than normal request?
>>>>
>>>> Best regards
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240516/db2e4ddc/attachment.htm>

From jonathanlee571 at gmail.com  Thu May 16 05:46:43 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 15 May 2024 22:46:43 -0700
Subject: [squid-users] Squid returns a lot of ABORTED in access log and
 user navigation speed slows
In-Reply-To: <1d343770-efba-4f29-87e8-d5dc173ec937@articatech.com>
References: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>
 <7B56260D-F777-4B85-AF0A-6607A21FA292@gmail.com>
 <9eed0c7b-55d2-4e2b-95cc-594b0750f4b9@articatech.com>
 <25eb4d61-f618-4358-9f39-de6427d4d94d@measurement-factory.com>
 <1d343770-efba-4f29-87e8-d5dc173ec937@articatech.com>
Message-ID: <623F31F9-A022-4E91-BC46-D1AE1E550FD9@gmail.com>

I think they are default on if you look at references 


> On May 15, 2024, at 17:16, Andre Bolinhas <andre.bolinhas at articatech.com> wrote:
> 
> Hi Alex
> Thanks for your feedback, in this case enable client_persistent_connections and server_persistent_connections could help or is better to keep it disable?
> 
> Best regards
> 
> On 15/05/2024 19:24, Alex Rousskov wrote:
>> On 2024-05-15 14:08, Andre Bolinhas wrote: 
>> 
>>> I'm not using pipeline_prefetch, because pipeline_prefetch breaks the NTLM/Kerberos authentication.
>> 
>> 
>> Enabling pipeline_prefetch introduces other problems as well. There might be some very special use cases that benefit from pipeline_prefetch today, but, in general, that directive should not be used (and the whole feature should be removed from Squid until it is properly implemented). 
>> 
>> I cannot currently answer your primary questions on this thread. I hope somebody else will guide you through this triage. 
>> 
>> Alex. 
>> 
>> 
>>> On 15/05/2024 18:15, Jonathan Lee wrote:
>>>> Have you researched enabling pipeline_prefetch?? 
>>>> 
>>>>> On May 14, 2024, at 17:56, Andre Bolinhas <andre.bolinhas at articatech.com> <mailto:andre.bolinhas at articatech.com> wrote: 
>>>>> 
>>>>> Hi 
>>>>> 
>>>>> Sometimes my users complains that the internet navigation thought Squid is very slow. 
>>>>> 
>>>>> After checking the access.log, I can see a lot of ABORTED messages like this 
>>>>> 
>>>>> 1715537802.589      2 10.103.12.94 NONE_NONE_ABORTED/200 0 CONNECT api.telegram.org:443 - HIER_NONE/-:- - mac="00:00:00:00:00:00" accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT" 
>>>>> 
>>>>> 1715537183.180  99993 172.16.31.205 TCP_MISS_ABORTED/000 0 POST http://pjcpd-dlpend01.hlbank.my/GECommunicationWS.asmx - HIER_NONE/-:- - mac="00:00:00:00:00:00" accessrule:%20global_whitelist%0D%0A exterr="ERR_CLIENT_GONE|WITH_CLIENT" 
>>>>> 
>>>>> I have imported the access.log into my ELK machine and I can see that during the time that the users complained about the slowness there is a huge spike of NONE_ABORTED messages. 
>>>>> 
>>>>> https://i.postimg.cc/6QR79GWk/6e727e86-de3d-4f3b-bd9e-04c04052ca2e.jpg 
>>>>> 
>>>>> Now my question is: 
>>>>> 1. What can cause this kind of issue? It's a squid server issue, network (firewall, switch, router, ?), or client? 
>>>>> 2. Why the number of NONE_ABORTED requests is almost 4 time more than normal request? 
>>>>> 
>>>>> Best regards 
>>>>> 
>>>>> _______________________________________________ 
>>>>> squid-users mailing list 
>>>>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>> 
>>> 
>>> _______________________________________________ 
>>> squid-users mailing list 
>>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
>> _______________________________________________ 
>> squid-users mailing list 
>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
>> https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240515/b76460e1/attachment.htm>

From andre.bolinhas at articatech.com  Thu May 16 11:50:21 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Thu, 16 May 2024 12:50:21 +0100
Subject: [squid-users] Squid returns a lot of ABORTED in access log and
 user navigation speed slows
In-Reply-To: <623F31F9-A022-4E91-BC46-D1AE1E550FD9@gmail.com>
References: <d4159e69-80f6-41af-9f48-ac3a2abd0da4@articatech.com>
 <7B56260D-F777-4B85-AF0A-6607A21FA292@gmail.com>
 <9eed0c7b-55d2-4e2b-95cc-594b0750f4b9@articatech.com>
 <25eb4d61-f618-4358-9f39-de6427d4d94d@measurement-factory.com>
 <1d343770-efba-4f29-87e8-d5dc173ec937@articatech.com>
 <623F31F9-A022-4E91-BC46-D1AE1E550FD9@gmail.com>
Message-ID: <f1103461-6685-4dd3-bec0-dbab19c954a4@articatech.com>

Hi

I have disabled it, I just want to know if I re-enable it, it will help 
on to avoid this issue or increase performance.

Best regards

On 16/05/2024 06:46, Jonathan Lee wrote:
> I think they are default on if you look at references
>
>
>> On May 15, 2024, at 17:16, Andre Bolinhas 
>> <andre.bolinhas at articatech.com> wrote:
>>
>> Hi Alex
>> Thanks for your feedback, in this case enable 
>> client_persistent_connections and server_persistent_connections could 
>> help or is better to keep it disable?
>>
>> Best regards
>>
>> On 15/05/2024 19:24, Alex Rousskov wrote:
>>> On 2024-05-15 14:08, Andre Bolinhas wrote:
>>>
>>>> I'm not using pipeline_prefetch, because pipeline_prefetch breaks 
>>>> the NTLM/Kerberos authentication.
>>>
>>>
>>> Enabling pipeline_prefetch introduces other problems as well. There 
>>> might be some very special use cases that benefit from 
>>> pipeline_prefetch today, but, in general, that directive should not 
>>> be used (and the whole feature should be removed from Squid until it 
>>> is properly implemented).
>>>
>>> I cannot currently answer your primary questions on this thread. I 
>>> hope somebody else will guide you through this triage.
>>>
>>> Alex.
>>>
>>>
>>>> On 15/05/2024 18:15, Jonathan Lee wrote:
>>>>> Have you researched enabling pipeline_prefetch??
>>>>>
>>>>>> On May 14, 2024, at 17:56, Andre Bolinhas 
>>>>>> <andre.bolinhas at articatech.com> wrote:
>>>>>>
>>>>>> Hi
>>>>>>
>>>>>> Sometimes my users complains that the internet navigation thought 
>>>>>> Squid is very slow.
>>>>>>
>>>>>> After checking the access.log, I can see a lot of ABORTED 
>>>>>> messages like this
>>>>>>
>>>>>> 1715537802.589????? 2 10.103.12.94 NONE_NONE_ABORTED/200 0 
>>>>>> CONNECT api.telegram.org:443 - HIER_NONE/-:- - 
>>>>>> mac="00:00:00:00:00:00" accessrule:%20global_whitelist%0D%0A 
>>>>>> exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>>>>>
>>>>>> 1715537183.180? 99993 172.16.31.205 TCP_MISS_ABORTED/000 0 POST 
>>>>>> http://pjcpd-dlpend01.hlbank.my/GECommunicationWS.asmx - 
>>>>>> HIER_NONE/-:- - mac="00:00:00:00:00:00" 
>>>>>> accessrule:%20global_whitelist%0D%0A 
>>>>>> exterr="ERR_CLIENT_GONE|WITH_CLIENT"
>>>>>>
>>>>>> I have imported the access.log into my ELK machine and I can see 
>>>>>> that during the time that the users complained about the slowness 
>>>>>> there is a huge spike of NONE_ABORTED messages.
>>>>>>
>>>>>> https://i.postimg.cc/6QR79GWk/6e727e86-de3d-4f3b-bd9e-04c04052ca2e.jpg 
>>>>>>
>>>>>>
>>>>>> Now my question is:
>>>>>> 1. What can cause this kind of issue? It's a squid server issue, 
>>>>>> network (firewall, switch, router, ?), or client?
>>>>>> 2. Why the number of NONE_ABORTED requests is almost 4 time more 
>>>>>> than normal request?
>>>>>>
>>>>>> Best regards
>>>>>>
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240516/5ea5720c/attachment.htm>

From rousskov at measurement-factory.com  Thu May 16 13:08:17 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 16 May 2024 09:08:17 -0400
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <01aa3f58-73a3-4f14-90fd-cba2234da3ed@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD3FXIJWgsSQLJz3KxHKB5yAQAAAAA=@articatech.com>
 <CABA8h=QBGofnCPuXqd5F_yF_M=mV_G7FVucRtZ7mWJAx_WbiFg@mail.gmail.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACQee6iB+9UQbA7yyJVYK9FAQAAAAA=@articatech.com>
 <000901d816b2$2d21cfd0$87656f70$@gmail.com>
 <01aa3f58-73a3-4f14-90fd-cba2234da3ed@articatech.com>
Message-ID: <2ef8fee9-5d29-492b-a482-b85b3003801f@measurement-factory.com>

On 2024-05-15 19:02, Andre Bolinhas wrote:

> To handle this amount of traffic should I enable 
> client_persistent_connections and server_persistent_connections or is it 
> better to keep it disable?

As Jonathan has already mentioned, the question is misleading because 
these directives default to "on" -- persistent connections are enabled 
by default. Modern HTTP specs enable them by default as well.

Since you do not know whether persistent connections are harmful in your 
particular deployment environments, remove those two directives from 
your Squid configuration files (effectively enabling persistent 
connection use). There are always exceptions, but in the vast majority 
of cases, not specifying those directives is the best first step.

If you want to research whether persistent connections are harmful in 
your environments, you will need to define performance metrics and 
experiment with all four different combinations across the two boolean 
directives (at least -- there are more directives that affect connection 
persistency). Doing this kind of research right is difficult!


HTH,

Alex.


> Best regards
> 
> On 31/01/2022 14:52, Eliezer Croitoru wrote:
>>
>> Hey Andre,
>>
>> I *would not *recommend on 5.x yet since there are couple bugs which 
>> are blocking it to be used as stable.
>>
>> I believe that your current setup is pretty good.
>>
>> The only thing which might affect the system is the authentication and 
>> ACLs.
>>
>> As long these ACL rules are static it should not affect too much on 
>> the operation, however,
>> When adding external authentication and external helpers for other 
>> things it?s possible to see some slowdown in specific scenarios.
>>
>> As long as the credentials and the ACLs will be fast enough it is 
>> expected to work fast but only testing will prove how the real world usage
>> will affect the service.
>>
>> I believe that 5 workers is enough and also take into account that the 
>> external helpers would also require CPU so don?t rush into
>> changing the workers amount just yet.
>>
>> All The Bests,
>>
>> Eliezer
>>
>> ----
>>
>> Eliezer Croitoru
>>
>> NgTech, Tech Support
>>
>> Mobile: +972-5-28704261
>>
>> Email: ngtech1ltd at gmail.com
>>
>> *From:* Andr? Bolinhas <andre.bolinhas at articatech.com>
>> *Sent:* Monday, January 31, 2022 15:47
>> *To:* 'NgTech LTD' <ngtech1ltd at gmail.com>
>> *Cc:* 'Squid Users' <squid-users at lists.squid-cache.org>
>> *Subject:* RE: [squid-users] Tune Squid proxy to handle 90k connection
>>
>> Hi
>>
>> I will not use cache in this project.
>>
>> Yes, I will need
>>
>>   * ACL (based on Domain, AD user, Headers, User Agent?)
>>   * Authentication
>>   * SSL bump just for one domain.
>>   * DNS resolution (I will use Unbound DNS service for this)
>>
>> Also, I will divide the traffic between two Squid box instead just one.
>>
>> So each box will handle around 50k request.
>>
>> Each box have:
>>
>>   * CPU(s) 16
>>   * Threads per code 2
>>   * Cores per socket 8
>>   * Sockets 1
>>   * Inter Xeron Silver 4208? @ 2.10GHz
>>   * 96GB Ram
>>   * 1TB raid-0 SSD
>>
>> At this time I have 5 workers on each Squid box and the Squid version 
>> is 4.17, do you recommend more workers or upgrade the squid version to 5?
>>
>> Best regards
>>
>> *De:*NgTech LTD <ngtech1ltd at gmail.com>
>> *Enviada:* 31 de janeiro de 2022 04:59
>> *Para:* Andr? Bolinhas <andre.bolinhas at articatech.com>
>> *Cc:* Squid Users <squid-users at lists.squid-cache.org>
>> *Assunto:* Re: [squid-users] Tune Squid proxy to handle 90k connection
>>
>> I would recommend you to start with 0 caching.
>>
>> However, for choosing the right solution you must give more details.
>>
>> For example there is an IBM reasearch that prooved that for about 90k 
>> connections you can use vm's ontop of such hardware with apache web 
>> server.
>>
>> If you do have the set of the other requirements from the proxy else 
>> then the 90k requests it would be wise to mention them.
>>
>> Do you need any specific acls?
>>
>> Do you need authentication?
>>
>> etc..
>>
>> For a simple forward proxy I would suggest to use a simpler solution 
>> and if possible to not log anything as a starter point.
>>
>> Any local disk i/o will slow down the machine.
>>
>> About the url categorization, I do not have experience with ufdbguard 
>> on such scale but it would be pretty heavy for any software to handle 
>> 90k rps...
>>
>> ?It's doable to implement such setup but will require testing.
>>
>> Will you use ssl bump in this setup?
>>
>> If I will have all the technical and specs/requirements details I 
>> might be able to suggest better then now.
>>
>> Take into account that each squid worker can handle about 3k rps 
>> tops(with my experience) and it's a juggling between two sides so... 
>> 3k is really 3k+3k+external_acls+dns...
>>
>> I believe that in this case an example of configuration from the squid 
>> developers might be usefull.
>>
>> Eliezer
>>
>> ?????? ??? ??, 25 ????? 2022, 18:42, ???Andr? Bolinhas 
>> ?<andre.bolinhas at articatech.com>:
>>
>>     Any tip about my last comment?
>>
>>     -----Mensagem original-----
>>     De: Andr? Bolinhas <andre.bolinhas at articatech.com>
>>     Enviada: 21 de janeiro de 2022 16:36
>>     Para: 'Amos Jeffries' <squid3 at treenet.co.nz>;
>>     squid-users at lists.squid-cache.org
>>     Assunto: RE: [squid-users] Tune Squid proxy to handle 90k connection
>>
>>     Thanks Amos
>>     Yes, you are right, I will put a second box with HaProxy in front
>>     to balance the traffic.
>>     About the sockets I can't double it because is a physical machine,
>>     do you think disable hyperthreading from bios will help, because
>>     we have other services inside the box that works in
>>     multi-threading, like unbound DNS?
>>
>>     Just more a few questions:
>>     1? The server have 92Gb of Ram, do you think that is needed that
>>     adding swap will help squid performance?
>>     2? Right now we are using squid 4.17 did you recommend upgrade or
>>     downgrade to any specific version?
>>     3? We need categorization, for this we are using an external
>>     helper to achieve it, do you recommend use this approach with ACL
>>     or move to some kind of ufdbguard service?
>>
>>     Best regards
>>     -----Mensagem original-----
>>     De: squid-users <squid-users-bounces at lists.squid-cache.org> Em
>>     Nome De Amos Jeffries
>>     Enviada: 21 de janeiro de 2022 16:05
>>     Para: squid-users at lists.squid-cache.org
>>     Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection
>>
>>     Sorry for the slow reply. Responses inline.
>>
>>
>>     On 14/01/22 05:44, Andr? Bolinhas wrote:
>>     > Hi
>>     > ~80k request per second? 10k users
>>
>>
>>     Test this, but you may need a second machine to achieve the full
>>     80k RPS.
>>
>>     Latest Squid do not have any details analysis, but older Squid-3.5
>>     were only achieving >15k RPS under lab conditions, more likely
>>     expect under 10k RPS/worker on real traffic.
>>     ? That means (IME) this machine is quite likely to hit its
>>     capacity somewhere under 70k RPS.
>>
>>
>>     > CPU info:
>>     > CPU(s) 16
>>     > Threads per code 2
>>     > Cores per socket 8
>>
>>     With this CPU you will be able to run 7 workers. Setup affinity of
>>     one core per worker (the "kidN" processes of Squid). Leaving one
>>     core to the OS and additional processing needs - this matters at
>>     peak loading.
>>
>>     CPU "threads" tend not to be useful for Squid. Under high loads
>>     Squid workers will consume all available cycles on their core, not
>>     leaving any for the fancy "thread" core sharing features to
>>     pretend there is another core available. YMMV. One of the tests to
>>     try when tuning is to turn off the CPU hyperthreading and see what
>>     effect it has (if any).
>>
>>
>>     > Sockets 1
>>     > Inter Xeron Silver 4208? @ 2.10GHz
>>     >
>>
>>     Okay. Doable, but for best performance you want as high GHz rating
>>     on the cores as your budget can afford. The amount of "lag" Squid
>>     adds to traffic and RPS performance/parallelism directly
>>     correlates with how fast the CPU core can run cycles.
>>
>>
>>
>>     HTH
>>     Amos
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     http://lists.squid-cache.org/listinfo/squid-users
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     http://lists.squid-cache.org/listinfo/squid-users
>>
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From andre.bolinhas at articatech.com  Thu May 16 14:23:11 2024
From: andre.bolinhas at articatech.com (=?utf-8?Q?Bolinhas_Andr=C3=A9?=)
Date: Thu, 16 May 2024 16:23:11 +0200
Subject: [squid-users] Tune Squid proxy to handle 90k connection
Message-ID: <zarafa.664616cf.7ae1.3a8be0da5397216e@ns413437.ip-37-187-142.eu>

Hi Alex?
Has I explain, by default I set those directives to off to avoid high cpu consumption.?
My doubt is enabling persistent connection will help squid to process the request more efficiently and gain more performance or not.?

Best regards?

Sent from Nine

--------------------------------
De: Alex Rousskov <rousskov at measurement-factory.com>
Enviado: quinta-feira, 16 de maio de 2024 14:56
Para: squid-users at lists.squid-cache.org
Assunto Re: [squid-users] Tune Squid proxy to handle 90k connection



On 2024-05-15 19:02, Andre Bolinhas wrote:

> To handle this amount of traffic should I enable 
> client_persistent_connections and server_persistent_connections or is it 
> better to keep it disable?

As Jonathan has already mentioned, the question is misleading because 
these directives default to "on" -- persistent connections are enabled 
by default. Modern HTTP specs enable them by default as well.

Since you do not know whether persistent connections are harmful in your 
particular deployment environments, remove those two directives from 
your Squid configuration files (effectively enabling persistent 
connection use). There are always exceptions, but in the vast majority 
of cases, not specifying those directives is the best first step.

If you want to research whether persistent connections are harmful in 
your environments, you will need to define performance metrics and 
experiment with all four different combinations across the two boolean 
directives (at least -- there are more directives that affect connection 
persistency). Doing this kind of research right is difficult!


HTH,

Alex.


> Best regards
> 
> On 31/01/2022 14:52, Eliezer Croitoru wrote:
>>
>> Hey Andre,
>>
>> I *would not *recommend on 5.x yet since there are couple bugs which 
>> are blocking it to be used as stable.
>>
>> I believe that your current setup is pretty good.
>>
>> The only thing which might affect the system is the authentication and 
>> ACLs.
>>
>> As long these ACL rules are static it should not affect too much on 
>> the operation, however,
>> When adding external authentication and external helpers for other 
>> things it?s possible to see some slowdown in specific scenarios.
>>
>> As long as the credentials and the ACLs will be fast enough it is 
>> expected to work fast but only testing will prove how the real world usage
>> will affect the service.
>>
>> I believe that 5 workers is enough and also take into account that the 
>> external helpers would also require CPU so don?t rush into
>> changing the workers amount just yet.
>>
>> All The Bests,
>>
>> Eliezer
>>
>> ----
>>
>> Eliezer Croitoru
>>
>> NgTech, Tech Support
>>
>> Mobile: +972-5-28704261
>>
>> Email: ngtech1ltd at gmail.com
>>
>> *From:* Andr? Bolinhas <andre.bolinhas at articatech.com>
>> *Sent:* Monday, January 31, 2022 15:47
>> *To:* 'NgTech LTD' <ngtech1ltd at gmail.com>
>> *Cc:* 'Squid Users' <squid-users at lists.squid-cache.org>
>> *Subject:* RE: [squid-users] Tune Squid proxy to handle 90k connection
>>
>> Hi
>>
>> I will not use cache in this project.
>>
>> Yes, I will need
>>
>>?? * ACL (based on Domain, AD user, Headers, User Agent?)
>>?? * Authentication
>>?? * SSL bump just for one domain.
>>?? * DNS resolution (I will use Unbound DNS service for this)
>>
>> Also, I will divide the traffic between two Squid box instead just one.
>>
>> So each box will handle around 50k request.
>>
>> Each box have:
>>
>>?? * CPU(s) 16
>>?? * Threads per code 2
>>?? * Cores per socket 8
>>?? * Sockets 1
>>?? * Inter Xeron Silver 4208? @ 2.10GHz
>>?? * 96GB Ram
>>?? * 1TB raid-0 SSD
>>
>> At this time I have 5 workers on each Squid box and the Squid version 
>> is 4.17, do you recommend more workers or upgrade the squid version to 5?
>>
>> Best regards
>>
>> *De:*NgTech LTD <ngtech1ltd at gmail.com>
>> *Enviada:* 31 de janeiro de 2022 04:59
>> *Para:* Andr? Bolinhas <andre.bolinhas at articatech.com>
>> *Cc:* Squid Users <squid-users at lists.squid-cache.org>
>> *Assunto:* Re: [squid-users] Tune Squid proxy to handle 90k connection
>>
>> I would recommend you to start with 0 caching.
>>
>> However, for choosing the right solution you must give more details.
>>
>> For example there is an IBM reasearch that prooved that for about 90k 
>> connections you can use vm's ontop of such hardware with apache web 
>> server.
>>
>> If you do have the set of the other requirements from the proxy else 
>> then the 90k requests it would be wise to mention them.
>>
>> Do you need any specific acls?
>>
>> Do you need authentication?
>>
>> etc..
>>
>> For a simple forward proxy I would suggest to use a simpler solution 
>> and if possible to not log anything as a starter point.
>>
>> Any local disk i/o will slow down the machine.
>>
>> About the url categorization, I do not have experience with ufdbguard 
>> on such scale but it would be pretty heavy for any software to handle 
>> 90k rps...
>>
>> ?It's doable to implement such setup but will require testing.
>>
>> Will you use ssl bump in this setup?
>>
>> If I will have all the technical and specs/requirements details I 
>> might be able to suggest better then now.
>>
>> Take into account that each squid worker can handle about 3k rps 
>> tops(with my experience) and it's a juggling between two sides so... 
>> 3k is really 3k+3k+external_acls+dns...
>>
>> I believe that in this case an example of configuration from the squid 
>> developers might be usefull.
>>
>> Eliezer
>>
>> ?????? ??? ??, 25 ????? 2022, 18:42, ???Andr? Bolinhas 
>> ?<andre.bolinhas at articatech.com>:
>>
>>???? Any tip about my last comment?
>>
>>???? -----Mensagem original-----
>>???? De: Andr? Bolinhas <andre.bolinhas at articatech.com>
>>???? Enviada: 21 de janeiro de 2022 16:36
>>???? Para: 'Amos Jeffries' <squid3 at treenet.co.nz>;
>>???? squid-users at lists.squid-cache.org
>>???? Assunto: RE: [squid-users] Tune Squid proxy to handle 90k connection
>>
>>???? Thanks Amos
>>???? Yes, you are right, I will put a second box with HaProxy in front
>>???? to balance the traffic.
>>???? About the sockets I can't double it because is a physical machine,
>>???? do you think disable hyperthreading from bios will help, because
>>???? we have other services inside the box that works in
>>???? multi-threading, like unbound DNS?
>>
>>???? Just more a few questions:
>>???? 1? The server have 92Gb of Ram, do you think that is needed that
>>???? adding swap will help squid performance?
>>???? 2? Right now we are using squid 4.17 did you recommend upgrade or
>>???? downgrade to any specific version?
>>???? 3? We need categorization, for this we are using an external
>>???? helper to achieve it, do you recommend use this approach with ACL
>>???? or move to some kind of ufdbguard service?
>>
>>???? Best regards
>>???? -----Mensagem original-----
>>???? De: squid-users <squid-users-bounces at lists.squid-cache.org> Em
>>???? Nome De Amos Jeffries
>>???? Enviada: 21 de janeiro de 2022 16:05
>>???? Para: squid-users at lists.squid-cache.org
>>???? Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection
>>
>>???? Sorry for the slow reply. Responses inline.
>>
>>
>>???? On 14/01/22 05:44, Andr? Bolinhas wrote:
>>???? > Hi
>>???? > ~80k request per second? 10k users
>>
>>
>>???? Test this, but you may need a second machine to achieve the full
>>???? 80k RPS.
>>
>>???? Latest Squid do not have any details analysis, but older Squid-3.5
>>???? were only achieving >15k RPS under lab conditions, more likely
>>???? expect under 10k RPS/worker on real traffic.
>>???? ? That means (IME) this machine is quite likely to hit its
>>???? capacity somewhere under 70k RPS.
>>
>>
>>???? > CPU info:
>>???? > CPU(s) 16
>>???? > Threads per code 2
>>???? > Cores per socket 8
>>
>>???? With this CPU you will be able to run 7 workers. Setup affinity of
>>???? one core per worker (the "kidN" processes of Squid). Leaving one
>>???? core to the OS and additional processing needs - this matters at
>>???? peak loading.
>>
>>???? CPU "threads" tend not to be useful for Squid. Under high loads
>>???? Squid workers will consume all available cycles on their core, not
>>???? leaving any for the fancy "thread" core sharing features to
>>???? pretend there is another core available. YMMV. One of the tests to
>>???? try when tuning is to turn off the CPU hyperthreading and see what
>>???? effect it has (if any).
>>
>>
>>???? > Sockets 1
>>???? > Inter Xeron Silver 4208? @ 2.10GHz
>>???? >
>>
>>???? Okay. Doable, but for best performance you want as high GHz rating
>>???? on the cores as your budget can afford. The amount of "lag" Squid
>>???? adds to traffic and RPS performance/parallelism directly
>>???? correlates with how fast the CPU core can run cycles.
>>
>>
>>
>>???? HTH
>>???? Amos
>>???? _______________________________________________
>>???? squid-users mailing list
>>???? squid-users at lists.squid-cache.org
>>???? http://lists.squid-cache.org/listinfo/squid-users
>>
>>???? _______________________________________________
>>???? squid-users mailing list
>>???? squid-users at lists.squid-cache.org
>>???? http://lists.squid-cache.org/listinfo/squid-users
>>
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240516/1ad65980/attachment.htm>

From squid3 at treenet.co.nz  Thu May 16 19:53:18 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 17 May 2024 07:53:18 +1200
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <zarafa.664616cf.7ae1.3a8be0da5397216e@ns413437.ip-37-187-142.eu>
References: <zarafa.664616cf.7ae1.3a8be0da5397216e@ns413437.ip-37-187-142.eu>
Message-ID: <547dfffa-23bd-4f29-a595-446bbdfb711f@treenet.co.nz>

On 17/05/24 02:23, Bolinhas Andr? wrote:
> Hi Alex
> Has I explain, by default I set those directives to off to avoid high 
> cpu consumption.


Ah, actually with NTLM auth you are using *more* CPU per transaction 
with those turned off.

The thing is that auth takes a relatively long time to happen, so the 
transactions are slower. Hiding the fact that they are, in total, using 
more CPU and TCP networking resources.



> My doubt is enabling persistent connection will help squid to process 
> the request more efficiently and gain more performance or not.
> 

With persistent connections disabled, every client request must:

  1) wait for a TCP socket to become free for use
  2) perform a full SYN / SYN+ACK exchange to open it for use
  3) perform a NTLM challenge-response over HTTP
  4) wait for a second TCP socket to become free for use
  5) perform a full SYN / SYN+ACK exchange to open it for use
  6) perform the actual HTTP NTLM authenticated transaction.

Then
  7) locate a server that can be used
  8) wait for a TCP socket to become free for use
  9) perform a full SYN / SYN+ACK exchange to open it for use
  10) send the request on to the found server


That is a LOT of time, CPU, and networking.


With persistent connections enabled, only the first request looks like 
above. The second, third etc look like below:


  11) perform the HTTP NTLM authenticated transaction.

Then
  12) locate a server that can be used
  13) send the request on to the found server


  14) perform the HTTP NTLM authenticated transaction.

Then
  15) locate a server that can be used
  16) send the request on to the found server


That is MUCH better for performance.


HTH
Amos


From andre.bolinhas at articatech.com  Thu May 16 19:57:21 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Thu, 16 May 2024 20:57:21 +0100
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <547dfffa-23bd-4f29-a595-446bbdfb711f@treenet.co.nz>
References: <zarafa.664616cf.7ae1.3a8be0da5397216e@ns413437.ip-37-187-142.eu>
 <547dfffa-23bd-4f29-a595-446bbdfb711f@treenet.co.nz>
Message-ID: <7a094c4d-870f-441c-a210-5b2a0d40db92@articatech.com>

Ok, so in this case you recommended both enable 
client_persistent_connections and server_persistent_connections to gain 
more performance in tems of CPU and Networking, correct?

Thanks in advance for your help.
Best regards

On 16/05/2024 20:53, Amos Jeffries wrote:
> On 17/05/24 02:23, Bolinhas Andr? wrote:
>> Hi Alex
>> Has I explain, by default I set those directives to off to avoid high 
>> cpu consumption.
>
>
> Ah, actually with NTLM auth you are using *more* CPU per transaction 
> with those turned off.
>
> The thing is that auth takes a relatively long time to happen, so the 
> transactions are slower. Hiding the fact that they are, in total, 
> using more CPU and TCP networking resources.
>
>
>
>> My doubt is enabling persistent connection will help squid to process 
>> the request more efficiently and gain more performance or not.
>>
>
> With persistent connections disabled, every client request must:
>
> ?1) wait for a TCP socket to become free for use
> ?2) perform a full SYN / SYN+ACK exchange to open it for use
> ?3) perform a NTLM challenge-response over HTTP
> ?4) wait for a second TCP socket to become free for use
> ?5) perform a full SYN / SYN+ACK exchange to open it for use
> ?6) perform the actual HTTP NTLM authenticated transaction.
>
> Then
> ?7) locate a server that can be used
> ?8) wait for a TCP socket to become free for use
> ?9) perform a full SYN / SYN+ACK exchange to open it for use
> ?10) send the request on to the found server
>
>
> That is a LOT of time, CPU, and networking.
>
>
> With persistent connections enabled, only the first request looks like 
> above. The second, third etc look like below:
>
>
> ?11) perform the HTTP NTLM authenticated transaction.
>
> Then
> ?12) locate a server that can be used
> ?13) send the request on to the found server
>
>
> ?14) perform the HTTP NTLM authenticated transaction.
>
> Then
> ?15) locate a server that can be used
> ?16) send the request on to the found server
>
>
> That is MUCH better for performance.
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240516/ba988c14/attachment.htm>

From rousskov at measurement-factory.com  Thu May 16 20:34:49 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 16 May 2024 16:34:49 -0400
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <547dfffa-23bd-4f29-a595-446bbdfb711f@treenet.co.nz>
References: <zarafa.664616cf.7ae1.3a8be0da5397216e@ns413437.ip-37-187-142.eu>
 <547dfffa-23bd-4f29-a595-446bbdfb711f@treenet.co.nz>
Message-ID: <ac8818a2-10d7-41a6-abc4-6aa47ab66550@measurement-factory.com>

On 17/05/24 02:23, Bolinhas Andr? wrote:

> Has I explain, by default I set those directives to off to avoid high 
> cpu consumption.

Just FYI: In this context, when you say "default", folks will tend to 
think that you are talking about default Squid configuration setting 
(i.e. something hard-coded in Squid code) rather than the actual thing 
you are talking about (i.e. your custom Squid configuration).

I do not know whether disabling persistent connections reduces CPU 
consumption in your environment. There are too many variables. In most 
cases, including NTLM authentication cases detailed by Amos, disabling 
persistent connections hurts performance, but there are always 
exceptions (and bugs).

It is not clear (to me) whether you disable persistent connections 
because they hurt performance in your environment OR you disable 
persistent connections because _you assume_ (without evidence) that they 
hurt performance in your environment.

If you do not know that disabling persistent connections reduces CPU 
consumption in your environment, then you should not disable them until 
you discover strong evidence that they hurt performance. At that point, 
you can share that evidence and ask for configuration advice based on 
that evidence.


HTH,

Alex.



From andre.bolinhas at articatech.com  Thu May 16 22:10:01 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Thu, 16 May 2024 23:10:01 +0100
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <ac8818a2-10d7-41a6-abc4-6aa47ab66550@measurement-factory.com>
References: <zarafa.664616cf.7ae1.3a8be0da5397216e@ns413437.ip-37-187-142.eu>
 <547dfffa-23bd-4f29-a595-446bbdfb711f@treenet.co.nz>
 <ac8818a2-10d7-41a6-abc4-6aa47ab66550@measurement-factory.com>
Message-ID: <dd148d7a-845c-4d85-a021-9f42cd83bde8@articatech.com>

Hi
Well, the performance and NTLM issues that I had with persistent 
connections goes back to squid 3.5 ?, so I never re-enabled it again on 
new version, I'm using Squid 5.9 and 6.8 now.

If you tell me that now that persistent connections are more stable and 
inclusive is recommended to be enabled by default to gain performance 
and also speed up NTLM/Kerberos authentication, I will re-enable again 
on my production servers.

Best Regards

On 16/05/2024 21:34, Alex Rousskov wrote:
> On 17/05/24 02:23, Bolinhas Andr? wrote:
>
>> Has I explain, by default I set those directives to off to avoid high 
>> cpu consumption.
>
> Just FYI: In this context, when you say "default", folks will tend to 
> think that you are talking about default Squid configuration setting 
> (i.e. something hard-coded in Squid code) rather than the actual thing 
> you are talking about (i.e. your custom Squid configuration).
>
> I do not know whether disabling persistent connections reduces CPU 
> consumption in your environment. There are too many variables. In most 
> cases, including NTLM authentication cases detailed by Amos, disabling 
> persistent connections hurts performance, but there are always 
> exceptions (and bugs).
>
> It is not clear (to me) whether you disable persistent connections 
> because they hurt performance in your environment OR you disable 
> persistent connections because _you assume_ (without evidence) that 
> they hurt performance in your environment.
>
> If you do not know that disabling persistent connections reduces CPU 
> consumption in your environment, then you should not disable them 
> until you discover strong evidence that they hurt performance. At that 
> point, you can share that evidence and ask for configuration advice 
> based on that evidence.
>
>
> HTH,
>
> Alex.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240516/81f74c1e/attachment.htm>

From jonathanlee571 at gmail.com  Thu May 16 23:12:53 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 16 May 2024 16:12:53 -0700
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <dd148d7a-845c-4d85-a021-9f42cd83bde8@articatech.com>
References: <dd148d7a-845c-4d85-a021-9f42cd83bde8@articatech.com>
Message-ID: <4F4ED907-7ADD-4CAB-AE29-547737265570@gmail.com>

What about using COSS file system? 
Sent from my iPhone

> On May 16, 2024, at 15:10, Andre Bolinhas <andre.bolinhas at articatech.com> wrote:
> 
> ? Hi
> Well, the performance and NTLM issues that I had with persistent connections goes back to squid 3.5 ?, so I never re-enabled it again on new version, I'm using Squid 5.9 and 6.8 now.
> 
> If you tell me that now that persistent connections are more stable and inclusive is recommended to be enabled by default to gain performance and also speed up NTLM/Kerberos authentication, I will re-enable again on my production servers.
> Best Regards
> 
> On 16/05/2024 21:34, Alex Rousskov wrote:
>> On 17/05/24 02:23, Bolinhas Andr? wrote:
>> 
>>> Has I explain, by default I set those directives to off to avoid high cpu consumption.
>> 
>> Just FYI: In this context, when you say "default", folks will tend to think that you are talking about default Squid configuration setting (i.e. something hard-coded in Squid code) rather than the actual thing you are talking about (i.e. your custom Squid configuration).
>> 
>> I do not know whether disabling persistent connections reduces CPU consumption in your environment. There are too many variables. In most cases, including NTLM authentication cases detailed by Amos, disabling persistent connections hurts performance, but there are always exceptions (and bugs).
>> 
>> It is not clear (to me) whether you disable persistent connections because they hurt performance in your environment OR you disable persistent connections because _you assume_ (without evidence) that they hurt performance in your environment.
>> 
>> If you do not know that disabling persistent connections reduces CPU consumption in your environment, then you should not disable them until you discover strong evidence that they hurt performance. At that point, you can share that evidence and ask for configuration advice based on that evidence.
>> 
>> 
>> HTH,
>> 
>> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240516/8e3cec97/attachment.htm>

From rousskov at measurement-factory.com  Fri May 17 13:38:24 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 17 May 2024 09:38:24 -0400
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <4F4ED907-7ADD-4CAB-AE29-547737265570@gmail.com>
References: <dd148d7a-845c-4d85-a021-9f42cd83bde8@articatech.com>
 <4F4ED907-7ADD-4CAB-AE29-547737265570@gmail.com>
Message-ID: <03f8c85e-10a5-4409-b5dd-30b851600330@measurement-factory.com>

On May 16, 2024, at 15:10, Andre Bolinhas wrote:
> Well, the performance and NTLM issues that I had with persistent 
> connections goes back to squid 3.5 ?, so I never re-enabled it again 
> on new version, I'm using Squid 5.9 and 6.8 now.
>
> If you tell me that now that persistent connections are more stable 
> and inclusive is recommended to be enabled by default to gain 
> performance and also speed up NTLM/Kerberos authentication, I will 
> re-enable again on my production servers.

FWIW, I am not going to tell you any of that. I am also not going to 
tell you the opposite of those statements. In my previous emails, I did 
my best to document that I cannot correctly predict performance impact 
in your specific deployment environments (and suggested alternatives to 
asking unsubstantiated "Should I enable or disable persistent 
connections?" question on a mailing list). I obviously failed to get 
that message across since essentially the same question is still being 
asked.

Alex.



>> On 16/05/2024 21:34, Alex Rousskov wrote:
>>> On 17/05/24 02:23, Bolinhas Andr? wrote:
>>>
>>>> Has I explain, by default I set those directives to off to avoid 
>>>> high cpu consumption.
>>>
>>> Just FYI: In this context, when you say "default", folks will tend to 
>>> think that you are talking about default Squid configuration setting 
>>> (i.e. something hard-coded in Squid code) rather than the actual 
>>> thing you are talking about (i.e. your custom Squid configuration).
>>>
>>> I do not know whether disabling persistent connections reduces CPU 
>>> consumption in your environment. There are too many variables. In 
>>> most cases, including NTLM authentication cases detailed by Amos, 
>>> disabling persistent connections hurts performance, but there are 
>>> always exceptions (and bugs).
>>>
>>> It is not clear (to me) whether you disable persistent connections 
>>> because they hurt performance in your environment OR you disable 
>>> persistent connections because _you assume_ (without evidence) that 
>>> they hurt performance in your environment.
>>>
>>> If you do not know that disabling persistent connections reduces CPU 
>>> consumption in your environment, then you should not disable them 
>>> until you discover strong evidence that they hurt performance. At 
>>> that point, you can share that evidence and ask for configuration 
>>> advice based on that evidence.
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Fri May 17 13:42:44 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 17 May 2024 09:42:44 -0400
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <4F4ED907-7ADD-4CAB-AE29-547737265570@gmail.com>
References: <dd148d7a-845c-4d85-a021-9f42cd83bde8@articatech.com>
 <4F4ED907-7ADD-4CAB-AE29-547737265570@gmail.com>
Message-ID: <111c15a0-ef21-4c25-962b-593f9d1f0b0a@measurement-factory.com>

On 2024-05-16 19:12, Jonathan Lee wrote:
> What about using COSS file system?

Squid does not support COSS cache_dirs since v3.5. If Squid in question 
does disk caching, then rock cache_dirs may be the best bet.

Alex.


>> On May 16, 2024, at 15:10, Andre Bolinhas wrote:
>>
>> ? Hi
>> Well, the performance and NTLM issues that I had with persistent 
>> connections goes back to squid 3.5 ?, so I never re-enabled it again 
>> on new version, I'm using Squid 5.9 and 6.8 now.
>>
>> If you tell me that now that persistent connections are more stable 
>> and inclusive is recommended to be enabled by default to gain 
>> performance and also speed up NTLM/Kerberos authentication, I will 
>> re-enable again on my production servers.
>>
>> Best Regards
>>
>> On 16/05/2024 21:34, Alex Rousskov wrote:
>>> On 17/05/24 02:23, Bolinhas Andr? wrote:
>>>
>>>> Has I explain, by default I set those directives to off to avoid 
>>>> high cpu consumption.
>>>
>>> Just FYI: In this context, when you say "default", folks will tend to 
>>> think that you are talking about default Squid configuration setting 
>>> (i.e. something hard-coded in Squid code) rather than the actual 
>>> thing you are talking about (i.e. your custom Squid configuration).
>>>
>>> I do not know whether disabling persistent connections reduces CPU 
>>> consumption in your environment. There are too many variables. In 
>>> most cases, including NTLM authentication cases detailed by Amos, 
>>> disabling persistent connections hurts performance, but there are 
>>> always exceptions (and bugs).
>>>
>>> It is not clear (to me) whether you disable persistent connections 
>>> because they hurt performance in your environment OR you disable 
>>> persistent connections because _you assume_ (without evidence) that 
>>> they hurt performance in your environment.
>>>
>>> If you do not know that disabling persistent connections reduces CPU 
>>> consumption in your environment, then you should not disable them 
>>> until you discover strong evidence that they hurt performance. At 
>>> that point, you can share that evidence and ask for configuration 
>>> advice based on that evidence.
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users



From andre.bolinhas at articatech.com  Fri May 17 13:51:27 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Fri, 17 May 2024 14:51:27 +0100
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <111c15a0-ef21-4c25-962b-593f9d1f0b0a@measurement-factory.com>
References: <dd148d7a-845c-4d85-a021-9f42cd83bde8@articatech.com>
 <4F4ED907-7ADD-4CAB-AE29-547737265570@gmail.com>
 <111c15a0-ef21-4c25-962b-593f9d1f0b0a@measurement-factory.com>
Message-ID: <bdd43902-342b-4c96-ae21-7f660fdb4812@articatech.com>

Hi

No, no cache is used.

Alex can you reply this please

> ? Hi
> Well, the performance and NTLM issues that I had with persistent 
> connections goes back to squid 3.5 ?, so I never re-enabled it again 
> on new version, I'm using Squid 5.9 and 6.8 now.
>
> If you tell me that now that persistent connections are more stable 
> and inclusive is recommended to be enabled by default to gain 
> performance and also speed up NTLM/Kerberos authentication, I will 
> re-enable again on my production servers. 


On 17/05/2024 14:42, Alex Rousskov wrote:
> On 2024-05-16 19:12, Jonathan Lee wrote:
>> What about using COSS file system?
>
> Squid does not support COSS cache_dirs since v3.5. If Squid in 
> question does disk caching, then rock cache_dirs may be the best bet.
>
> Alex.
>
>
>>> On May 16, 2024, at 15:10, Andre Bolinhas wrote:
>>>
>>> ? Hi
>>> Well, the performance and NTLM issues that I had with persistent 
>>> connections goes back to squid 3.5 ?, so I never re-enabled it 
>>> again on new version, I'm using Squid 5.9 and 6.8 now.
>>>
>>> If you tell me that now that persistent connections are more stable 
>>> and inclusive is recommended to be enabled by default to gain 
>>> performance and also speed up NTLM/Kerberos authentication, I will 
>>> re-enable again on my production servers.
>>>
>>> Best Regards
>>>
>>> On 16/05/2024 21:34, Alex Rousskov wrote:
>>>> On 17/05/24 02:23, Bolinhas Andr? wrote:
>>>>
>>>>> Has I explain, by default I set those directives to off to avoid 
>>>>> high cpu consumption.
>>>>
>>>> Just FYI: In this context, when you say "default", folks will tend 
>>>> to think that you are talking about default Squid configuration 
>>>> setting (i.e. something hard-coded in Squid code) rather than the 
>>>> actual thing you are talking about (i.e. your custom Squid 
>>>> configuration).
>>>>
>>>> I do not know whether disabling persistent connections reduces CPU 
>>>> consumption in your environment. There are too many variables. In 
>>>> most cases, including NTLM authentication cases detailed by Amos, 
>>>> disabling persistent connections hurts performance, but there are 
>>>> always exceptions (and bugs).
>>>>
>>>> It is not clear (to me) whether you disable persistent connections 
>>>> because they hurt performance in your environment OR you disable 
>>>> persistent connections because _you assume_ (without evidence) that 
>>>> they hurt performance in your environment.
>>>>
>>>> If you do not know that disabling persistent connections reduces 
>>>> CPU consumption in your environment, then you should not disable 
>>>> them until you discover strong evidence that they hurt performance. 
>>>> At that point, you can share that evidence and ask for 
>>>> configuration advice based on that evidence.
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240517/0fc4479b/attachment.htm>

From lizhijian at fujitsu.com  Mon May 20 07:35:04 2024
From: lizhijian at fujitsu.com (Zhijian Li (Fujitsu))
Date: Mon, 20 May 2024 07:35:04 +0000
Subject: [squid-users] Question: cache_mem share among multiple squid
 instances with the same service_name in SMP mode
Message-ID: <70ad1ff1-a3d9-43c9-957a-6c451fa55fa5@fujitsu.com>

Hi All,

In SMP mode, is it possible that cache_mem can be share among multiple squid instances with the same service_name?

Per SmpScale[1], "memory object cache (in most environments)" can be share among workers
Per smp-enabled-squid[2], "Each set of SMP-aware processes will interact only with other processes using the same service name"

So if i have multiple (SMP mode + same service_name) squid instances, would they share the cache_mem objects.

[1] https://wiki.squid-cache.org/Features/SmpScale#what-can-workers-share
[2] https://wiki.squid-cache.org/KnowledgeBase/MultipleInstances#smp-enabled-squid


Thanks
Zhijian

From rousskov at measurement-factory.com  Mon May 20 14:09:18 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 20 May 2024 10:09:18 -0400
Subject: [squid-users] Question: cache_mem share among multiple squid
 instances with the same service_name in SMP mode
In-Reply-To: <70ad1ff1-a3d9-43c9-957a-6c451fa55fa5@fujitsu.com>
References: <70ad1ff1-a3d9-43c9-957a-6c451fa55fa5@fujitsu.com>
Message-ID: <ad957a71-a788-4d26-bef3-a5dda67c72d1@measurement-factory.com>

On 2024-05-20 03:35, Zhijian Li (Fujitsu) wrote:

> In SMP mode, is it possible that cache_mem can be share among
> multiple squid instances with the same service_name?

Short answer: "Do not run multiple SMP Squid instances with the same 
service_name".

SMP Squid cache[1] is not supposed to be shared across Squid instances. 
Any configurations or actions that result in such sharing are 
unsupported and may lead to undefined behavior. Squid may not emit 
warnings or other diagnostics in such unsupported cases -- no Squid code 
has been written specifically to detect and warn about unsupported 
memory sharing.

For example, running multiple identically-built Squid instances on the 
same "box"[2] with the _same_ service name is unsupported and may lead 
to undefined behavior, especially if SMP Squid cache[1] is enabled.

Running multiple identically-built Squid instances on the same "box"[2] 
with _different_ service names is supported on some OSes because it does 
not lead to unsupported sharing. In other environments, it may lead to 
undefined behavior. This limitation is a Squid bug or a missing feature. 
Developers wishing to remove this limitation should look at 
shm_portable_segment_name_is_path() description and use case.

[1]: Here, "SMP Squid cache" applies to both cache_dir storage (on disk 
and in shared memory) and cache_mem storage (in shared memory). Very 
similar reasoning applies to non-caching SMP Squid instances as well, 
but the question was about caching, so I will not detail these other cases.

[2]: Here, the term "box" is used to mean "isolation environment": "Same 
box" means the same OS instance, the same container instance (if 
containerized), and the same filesystem (i.e. no chroot, jails, or 
similar isolation tricks for each Squid instance). Various OSes isolate 
shared memory segments differently, but many use file systems for some 
shared memory artifacts. If artifacts from different Squid instances 
clash, Squid behavior is undefined.


HTH,

Alex.

> 
> Per SmpScale[1], "memory object cache (in most environments)" can be share among workers
> Per smp-enabled-squid[2], "Each set of SMP-aware processes will interact only with other processes using the same service name"
> 
> So if i have multiple (SMP mode + same service_name) squid instances, would they share the cache_mem objects.
> 
> [1] https://wiki.squid-cache.org/Features/SmpScale#what-can-workers-share
> [2] https://wiki.squid-cache.org/KnowledgeBase/MultipleInstances#smp-enabled-squid
> 
> 
> Thanks
> Zhijian
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Mon May 20 19:30:48 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 20 May 2024 15:30:48 -0400
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <bdd43902-342b-4c96-ae21-7f660fdb4812@articatech.com>
References: <dd148d7a-845c-4d85-a021-9f42cd83bde8@articatech.com>
 <4F4ED907-7ADD-4CAB-AE29-547737265570@gmail.com>
 <111c15a0-ef21-4c25-962b-593f9d1f0b0a@measurement-factory.com>
 <bdd43902-342b-4c96-ae21-7f660fdb4812@articatech.com>
Message-ID: <7dac94ee-56d6-4c31-af8a-d5b60be4ca68@measurement-factory.com>

On 2024-05-17 09:51, Andre Bolinhas wrote:

> Alex can you reply this please

Already did. Please see
https://lists.squid-cache.org/pipermail/squid-users/2024-May/026677.html

Alex.


>> ? Hi
>> Well, the performance and NTLM issues that I had with persistent 
>> connections goes back to squid 3.5 ?, so I never re-enabled it again 
>> on new version, I'm using Squid 5.9 and 6.8 now.
>>
>> If you tell me that now that persistent connections are more stable 
>> and inclusive is recommended to be enabled by default to gain 
>> performance and also speed up NTLM/Kerberos authentication, I will 
>> re-enable again on my production servers. 
> 
> 
> On 17/05/2024 14:42, Alex Rousskov wrote:
>> On 2024-05-16 19:12, Jonathan Lee wrote:
>>> What about using COSS file system?
>>
>> Squid does not support COSS cache_dirs since v3.5. If Squid in 
>> question does disk caching, then rock cache_dirs may be the best bet.
>>
>> Alex.
>>
>>
>>>> On May 16, 2024, at 15:10, Andre Bolinhas wrote:
>>>>
>>>> ? Hi
>>>> Well, the performance and NTLM issues that I had with persistent 
>>>> connections goes back to squid 3.5 ?, so I never re-enabled it 
>>>> again on new version, I'm using Squid 5.9 and 6.8 now.
>>>>
>>>> If you tell me that now that persistent connections are more stable 
>>>> and inclusive is recommended to be enabled by default to gain 
>>>> performance and also speed up NTLM/Kerberos authentication, I will 
>>>> re-enable again on my production servers.
>>>>
>>>> Best Regards
>>>>
>>>> On 16/05/2024 21:34, Alex Rousskov wrote:
>>>>> On 17/05/24 02:23, Bolinhas Andr? wrote:
>>>>>
>>>>>> Has I explain, by default I set those directives to off to avoid 
>>>>>> high cpu consumption.
>>>>>
>>>>> Just FYI: In this context, when you say "default", folks will tend 
>>>>> to think that you are talking about default Squid configuration 
>>>>> setting (i.e. something hard-coded in Squid code) rather than the 
>>>>> actual thing you are talking about (i.e. your custom Squid 
>>>>> configuration).
>>>>>
>>>>> I do not know whether disabling persistent connections reduces CPU 
>>>>> consumption in your environment. There are too many variables. In 
>>>>> most cases, including NTLM authentication cases detailed by Amos, 
>>>>> disabling persistent connections hurts performance, but there are 
>>>>> always exceptions (and bugs).
>>>>>
>>>>> It is not clear (to me) whether you disable persistent connections 
>>>>> because they hurt performance in your environment OR you disable 
>>>>> persistent connections because _you assume_ (without evidence) that 
>>>>> they hurt performance in your environment.
>>>>>
>>>>> If you do not know that disabling persistent connections reduces 
>>>>> CPU consumption in your environment, then you should not disable 
>>>>> them until you discover strong evidence that they hurt performance. 
>>>>> At that point, you can share that evidence and ask for 
>>>>> configuration advice based on that evidence.
>>>>>
>>>>>
>>>>> HTH,
>>>>>
>>>>> Alex.
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users



From lizhijian at fujitsu.com  Tue May 21 01:35:03 2024
From: lizhijian at fujitsu.com (Zhijian Li (Fujitsu))
Date: Tue, 21 May 2024 01:35:03 +0000
Subject: [squid-users] Question: cache_mem share among multiple squid
 instances with the same service_name in SMP mode
In-Reply-To: <ad957a71-a788-4d26-bef3-a5dda67c72d1@measurement-factory.com>
References: <70ad1ff1-a3d9-43c9-957a-6c451fa55fa5@fujitsu.com>
 <ad957a71-a788-4d26-bef3-a5dda67c72d1@measurement-factory.com>
Message-ID: <86bc0358-886c-4471-b5b0-df9f9dd2de80@fujitsu.com>

Alex,


On 20/05/2024 22:09, Alex Rousskov wrote:
> On 2024-05-20 03:35, Zhijian Li (Fujitsu) wrote:
> 
>> In SMP mode, is it possible that cache_mem can be share among
>> multiple squid instances with the same service_name?
> 
> Short answer: "Do not run multiple SMP Squid instances with the same service_name".
> 
> SMP Squid cache[1] is not supposed to be shared across Squid instances. Any configurations or actions that result in such sharing are unsupported and may lead to undefined behavior. Squid may not emit warnings or other diagnostics in such unsupported cases -- no Squid code has been written specifically to detect and warn about unsupported memory sharing.
> 
> For example, running multiple identically-built Squid instances on the same "box"[2] with the _same_ service name is unsupported and may lead to undefined behavior, especially if SMP Squid cache[1] is enabled.
> 
> Running multiple identically-built Squid instances on the same "box"[2] with _different_ service names is supported on some OSes because it does not lead to unsupported sharing. In other environments, it may lead to undefined behavior. This limitation is a Squid bug or a missing feature. Developers wishing to remove this limitation should look at shm_portable_segment_name_is_path() description and use case.
> 

Understood, many thanks for your detailed explanation.


Thanks
Zhijian

> [1]: Here, "SMP Squid cache" applies to both cache_dir storage (on disk and in shared memory) and cache_mem storage (in shared memory). Very similar reasoning applies to non-caching SMP Squid instances as well, but the question was about caching, so I will not detail these other cases.
> 
> [2]: Here, the term "box" is used to mean "isolation environment": "Same box" means the same OS instance, the same container instance (if containerized), and the same filesystem (i.e. no chroot, jails, or similar isolation tricks for each Squid instance). Various OSes isolate shared memory segments differently, but many use file systems for some shared memory artifacts. If artifacts from different Squid instances clash, Squid behavior is undefined.
> 
> 
> HTH,
> 
> Alex.
> 
>>
>> Per SmpScale[1], "memory object cache (in most environments)" can be share among workers
>> Per smp-enabled-squid[2], "Each set of SMP-aware processes will interact only with other processes using the same service name"
>>
>> So if i have multiple (SMP mode + same service_name) squid instances, would they share the cache_mem objects.
>>
>> [1] https://wiki.squid-cache.org/Features/SmpScale#what-can-workers-share
>> [2] https://wiki.squid-cache.org/KnowledgeBase/MultipleInstances#smp-enabled-squid
>>
>>
>> Thanks
>> Zhijian
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

From bmatznick at pbandt.bank  Tue May 21 17:50:49 2024
From: bmatznick at pbandt.bank (Bobby Matznick)
Date: Tue, 21 May 2024 17:50:49 +0000
Subject: [squid-users] log_referrer question
In-Reply-To: <mailman.3.1713873601.940268.squid-users@lists.squid-cache.org>
References: <mailman.3.1713873601.940268.squid-users@lists.squid-cache.org>
Message-ID: <MW5PR14MB52897188C2ED83596B406151B0EA2@MW5PR14MB5289.namprd14.prod.outlook.com>

I have been trying to use a combined log format for squid. The below line in the squid config is my current attempt.

logformat combined %>a %[ui %[un [%tl "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh

It is working, as far as logging the normal stuff I would see before having tried to implement referrer. I noticed somewhere that you need to build squid with -enable-referrer-log, it was an older version, looked like 3.1 and lower, I am using 4.13. So, checked with squid -v and do not see "-enable-referrer_log" as one of the configure options used during install. Would I need to reinstall, or is that no longer necessary in version 4.13? Thanks!!

Bobby

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of squid-users-request at lists.squid-cache.org
Sent: Tuesday, April 23, 2024 6:00 AM
To: squid-users at lists.squid-cache.org
Subject: [External] squid-users Digest, Vol 116, Issue 31

Caution: This is an external email and has a suspicious subject or content. Please take care when clicking links or opening attachments. When in doubt, contact your IT Department
Send squid-users mailing list submissions to
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>
or, via email, send a message with subject or body 'help' to
squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org>

You can reach the person managing the list at
squid-users-owner at lists.squid-cache.org<mailto:squid-users-owner at lists.squid-cache.org>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

1. Re: Warm cold times (Amos Jeffries)
2. Re: Container Based Issues Lock Down Password and Terminate
SSL (Amos Jeffries)


----------------------------------------------------------------------

Message: 1
Date: Tue, 23 Apr 2024 19:41:37 +1200
From: Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Warm cold times
Message-ID: <9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz<mailto:9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz>>
Content-Type: text/plain; charset=UTF-8; format=flowed

On 22/04/24 17:42, Jonathan Lee wrote:
> Has anyone else taken up the fun challenge of doing windows update caching. It is amazing when it works right. It is a complex configuration, but it is worth it to see a warm download come down that originally took 30 mins instantly to a second client. I didn?t know how much of the updates are the same across different vendor laptops.
>

There have been several people over the years.
The collected information is being gathered at
<https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates<https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates>>

If you would like to check and update the information for the current
Windows 11 and Squid 6, etc. that would be useful.

Wiki updates are now made using github PRs against the repository at
<https://github.com/squid-cache/squid-cache.github.io<https://github.com/squid-cache/squid-cache.github.io>>.




> Amazing stuff Squid team.
> I wish I could get some of the Roblox Xbox stuff to cache but it?s a night to get running with squid in the first place, I had to splice a bunch of stuff and also wpad the Xbox system.

FWIW, what I have seen from routing perspective is that Roblox likes to
use custom ports and P2P connections for a lot of things. So no high
expectations there, but anything cacheable is great news.



>> On Apr 18, 2024, at 23:55, Jonathan Lee wrote:
>>
>> ?Does anyone know the current warm cold download times for dynamic cache of windows updates?
>>
>> I can say my experience was a massive increase in the warm download it was delivered in under a couple mins versus 30 or so to download it cold. The warm download was almost instant on the second device. Very green energy efficient.
>>
>>
>> Does squid 5.8 or 6 work better on warm delivery?

There is no significant differences AFAIK. They both come down to what
you have configured. That said, the ongoing improvements may make v6
some amount of "better" - even if only trivial.



>> Is there a way to make 100 percent sure a docker container can?t get inside the cache?

For Windows I would expect the only "100% sure" way is to completely
forbid access to the disk where the cache is stored.


The rest of your questions are about container management and Windows
configuration. Which are kind of off-topic.


Cheers
Amos


------------------------------

Message: 2
Date: Tue, 23 Apr 2024 20:03:42 +1200
From: Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Container Based Issues Lock Down Password
and Terminate SSL
Message-ID: <58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz<mailto:58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz>>
Content-Type: text/plain; charset=UTF-8; format=flowed

On 23/04/24 11:52, Jonathan Lee wrote:
> Hello fellow Squid Accelerator/Dynamic Cache/Web Cache Users/PfSense users
>
> I think this might resolve any container based issues/fears if they
> happened to get into the cache. Ie a Docker Proxy got installed and
> tried to data marshal the network card inside of a freeBSD jail or
> something like that. Biggest fear with my cache it is a big cache now
>
> Please yet me know what you think or if it is wrong.
>
> Here is my configuration. I wanted to share it as it might help to
> secure some of this.

FTR, this config was auto-generated by pfsense. A number of things which
that tool forces into the config could be done much better in the latest
Squid, but the tool does not do due to needing to support older Squid
version.


>
> Keep in mine I use cachemgr.cgi within Squidlight so I had to set the
> password and I have to also adapt the php status file to include the
> password and also the sqlight php file.
>
> After that the status and gui pages work still with the new password.
> Only issues area that it shows up in clear text when it goes over the
> proxy I can see my password clear as day again that was an issue listed
> inside the Squid O?REILLY book also.


Please ensure you are using the latest Squid v6 release. That release
has both a number of security fixes, and working https:// URL access to
the manager reports.

The cachemgr.cgi tool is deprecated fro a number of issues including
that style of embedding passwords in the URLs.

Francesco and I have created a tool that can be found at
<https://github.com/yadij/cachemgr.js/blob/master/README.md<https://github.com/yadij/cachemgr.js/blob/master/README.md>> for basic
access to the reports directly from Browser.
That tool uses HTTP authentication configured via the well-documented
proxy_auth ACLs and http_access for more secure access than the old URL
based mechanism (which still exists, just deprecated).



Cheers
Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>


------------------------------

End of squid-users Digest, Vol 116, Issue 31
********************************************
CONFIDENTIALITY NOTICE: The information contained in and attached to this email is intended only for the confidential use of the person or entity to which the email is addressed. This email and any attachments may contain privileged and confidential information. If you are not the intended recipient, you are notified that you received this email in error and that any reading, retention, use or distribution of this email and attachments is strictly prohibited. If you received this email in error, you are requested to immediately notify us by calling 888-728-3550 or by return email and immediately and permanently delete the email and any attachments. Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240521/c5379930/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0.jpg
Type: image/jpeg
Size: 6398 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240521/c5379930/attachment.jpg>

From bmatznick at pbandt.bank  Tue May 21 18:47:34 2024
From: bmatznick at pbandt.bank (Bobby Matznick)
Date: Tue, 21 May 2024 18:47:34 +0000
Subject: [squid-users] log_referrer question
In-Reply-To: <mailman.2618.1716313869.1200.squid-users@lists.squid-cache.org>
References: <mailman.2618.1716313869.1200.squid-users@lists.squid-cache.org>
Message-ID: <MW5PR14MB52893A5021F3B930A083A2E7B0EA2@MW5PR14MB5289.namprd14.prod.outlook.com>

To add and maybe clarify what my confusion is, the log entries below (hidden internal/external IP's, domain and username) don't seem to show what I expected, a line marked "referrer". Am I misunderstanding how that should show up in the log? Thanks

1716316179.294      0 ***.***.***.*** TCP_DENIED/407 4048 CONNECT cc-api-data.adobe.io:443 - HIER_NONE/- text/html
1716316179.297      0 ***.***.***.***TCP_DENIED/407 4048 CONNECT cc-api-data.adobe.io:443 - HIER_NONE/- text/html
1716316179.310      0 ***.***.***.***TCP_DENIED/407 4048 CONNECT cc-api-data.adobe.io:443 - HIER_NONE/- text/html
1716316179.313      0 ***.***.***.***TCP_DENIED/407 4112 CONNECT ib.adnxs.com:443 - HIER_NONE/- text/html
1716316179.316      0 ***.***.***.***TCP_DENIED/407 4144 CONNECT htlb.casalemedia.com:443 - HIER_NONE/- text/html
1716316179.316      0 ***.***.***.***TCP_DENIED/407 4048 CONNECT cc-api-data.adobe.io:443 - HIER_NONE/- text/html
1716316179.318      0 ***.***.***.***TCP_DENIED/407 4172 CONNECT fastlane.rubiconproject.com:443 - HIER_NONE/- text/html
1716316179.320      0 ***.***.***.***TCP_DENIED/407 4152 CONNECT hbopenbid.pubmatic.com:443 - HIER_NONE/- text/html
1716316179.322  20103 ***.***.***.***TCP_TUNNEL/200 3363 CONNECT th.bing.com:443 ***\\Username HIER_DIRECT/***.***.***.***-
1716316179.324      0 ***.***.***.***TCP_DENIED/407 4132 CONNECT bidder.criteo.com:443 - HIER_NONE/- text/html
1716316179.328      0 ***.***.***.***TCP_DENIED/407 4048 CONNECT cc-api-data.adobe.io:443 - HIER_NONE/- text/html
1716316179.331      0 ***.***.***.***TCP_DENIED/407 4048 CONNECT cc-api-data.adobe.io:443 - HIER_NONE/- text/html

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of squid-users-request at lists.squid-cache.org
Sent: Tuesday, May 21, 2024 11:51 AM
To: squid-users at lists.squid-cache.org
Subject: [External] squid-users Digest, Vol 117, Issue 23

Send squid-users mailing list submissions to
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>
or, via email, send a message with subject or body 'help' to
squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org>

You can reach the person managing the list at
squid-users-owner at lists.squid-cache.org<mailto:squid-users-owner at lists.squid-cache.org>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

1. log_referrer question (Bobby Matznick)


----------------------------------------------------------------------

Message: 1
Date: Tue, 21 May 2024 17:50:49 +0000
From: Bobby Matznick <bmatznick at pbandt.bank<mailto:bmatznick at pbandt.bank>>
To: "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>"
<squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
Subject: [squid-users] log_referrer question
Message-ID:
<MW5PR14MB52897188C2ED83596B406151B0EA2 at MW5PR14MB5289.namprd14.prod.outlook.com<mailto:MW5PR14MB52897188C2ED83596B406151B0EA2 at MW5PR14MB5289.namprd14.prod.outlook.com>>

Content-Type: text/plain; charset="utf-8"

I have been trying to use a combined log format for squid. The below line in the squid config is my current attempt.

logformat combined %>a %[ui %[un [%tl "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh

It is working, as far as logging the normal stuff I would see before having tried to implement referrer. I noticed somewhere that you need to build squid with -enable-referrer-log, it was an older version, looked like 3.1 and lower, I am using 4.13. So, checked with squid -v and do not see "-enable-referrer_log" as one of the configure options used during install. Would I need to reinstall, or is that no longer necessary in version 4.13? Thanks!!

Bobby

From: squid-users <squid-users-bounces at lists.squid-cache.org<mailto:squid-users-bounces at lists.squid-cache.org>> On Behalf Of squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org>
Sent: Tuesday, April 23, 2024 6:00 AM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: [External] squid-users Digest, Vol 116, Issue 31

Caution: This is an external email and has a suspicious subject or content. Please take care when clicking links or opening attachments. When in doubt, contact your IT Department
Send squid-users mailing list submissions to
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org%3cmailto:squid-users at lists.squid-cache.org>>

To subscribe or unsubscribe via the World Wide Web, visit
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users><https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>>
or, via email, send a message with subject or body 'help' to
squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org%3cmailto:squid-users-request at lists.squid-cache.org>>

You can reach the person managing the list at
squid-users-owner at lists.squid-cache.org<mailto:squid-users-owner at lists.squid-cache.org<mailto:squid-users-owner at lists.squid-cache.org%3cmailto:squid-users-owner at lists.squid-cache.org>>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

1. Re: Warm cold times (Amos Jeffries)
2. Re: Container Based Issues Lock Down Password and Terminate
SSL (Amos Jeffries)


----------------------------------------------------------------------

Message: 1
Date: Tue, 23 Apr 2024 19:41:37 +1200
From: Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz%3cmailto:squid3 at treenet.co.nz>>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org%3cmailto:squid-users at lists.squid-cache.org>>
Subject: Re: [squid-users] Warm cold times
Message-ID: <9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz<mailto:9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz<mailto:9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz%3cmailto:9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz>>>
Content-Type: text/plain; charset=UTF-8; format=flowed

On 22/04/24 17:42, Jonathan Lee wrote:
> Has anyone else taken up the fun challenge of doing windows update caching. It is amazing when it works right. It is a complex configuration, but it is worth it to see a warm download come down that originally took 30 mins instantly to a second client. I didn?t know how much of the updates are the same across different vendor laptops.
>

There have been several people over the years.
The collected information is being gathered at
<https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates<https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates><https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates<https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates>>>

If you would like to check and update the information for the current
Windows 11 and Squid 6, etc. that would be useful.

Wiki updates are now made using github PRs against the repository at
<https://github.com/squid-cache/squid-cache.github.io<https://github.com/squid-cache/squid-cache.github.io><https://github.com/squid-cache/squid-cache.github.io<https://github.com/squid-cache/squid-cache.github.io>>>.




> Amazing stuff Squid team.
> I wish I could get some of the Roblox Xbox stuff to cache but it?s a night to get running with squid in the first place, I had to splice a bunch of stuff and also wpad the Xbox system.

FWIW, what I have seen from routing perspective is that Roblox likes to
use custom ports and P2P connections for a lot of things. So no high
expectations there, but anything cacheable is great news.



>> On Apr 18, 2024, at 23:55, Jonathan Lee wrote:
>>
>> ?Does anyone know the current warm cold download times for dynamic cache of windows updates?
>>
>> I can say my experience was a massive increase in the warm download it was delivered in under a couple mins versus 30 or so to download it cold. The warm download was almost instant on the second device. Very green energy efficient.
>>
>>
>> Does squid 5.8 or 6 work better on warm delivery?

There is no significant differences AFAIK. They both come down to what
you have configured. That said, the ongoing improvements may make v6
some amount of "better" - even if only trivial.



>> Is there a way to make 100 percent sure a docker container can?t get inside the cache?

For Windows I would expect the only "100% sure" way is to completely
forbid access to the disk where the cache is stored.


The rest of your questions are about container management and Windows
configuration. Which are kind of off-topic.


Cheers
Amos


------------------------------

Message: 2
Date: Tue, 23 Apr 2024 20:03:42 +1200
From: Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz%3cmailto:squid3 at treenet.co.nz>>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org%3cmailto:squid-users at lists.squid-cache.org>>
Subject: Re: [squid-users] Container Based Issues Lock Down Password
and Terminate SSL
Message-ID: <58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz<mailto:58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz<mailto:58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz%3cmailto:58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz>>>
Content-Type: text/plain; charset=UTF-8; format=flowed

On 23/04/24 11:52, Jonathan Lee wrote:
> Hello fellow Squid Accelerator/Dynamic Cache/Web Cache Users/PfSense users
>
> I think this might resolve any container based issues/fears if they
> happened to get into the cache. Ie a Docker Proxy got installed and
> tried to data marshal the network card inside of a freeBSD jail or
> something like that. Biggest fear with my cache it is a big cache now
>
> Please yet me know what you think or if it is wrong.
>
> Here is my configuration. I wanted to share it as it might help to
> secure some of this.

FTR, this config was auto-generated by pfsense. A number of things which
that tool forces into the config could be done much better in the latest
Squid, but the tool does not do due to needing to support older Squid
version.


>
> Keep in mine I use cachemgr.cgi within Squidlight so I had to set the
> password and I have to also adapt the php status file to include the
> password and also the sqlight php file.
>
> After that the status and gui pages work still with the new password.
> Only issues area that it shows up in clear text when it goes over the
> proxy I can see my password clear as day again that was an issue listed
> inside the Squid O?REILLY book also.


Please ensure you are using the latest Squid v6 release. That release
has both a number of security fixes, and working https:// URL access to
the manager reports.

The cachemgr.cgi tool is deprecated fro a number of issues including
that style of embedding passwords in the URLs.

Francesco and I have created a tool that can be found at
<https://github.com/yadij/cachemgr.js/blob/master/README.md<https://github.com/yadij/cachemgr.js/blob/master/README.md><https://github.com/yadij/cachemgr.js/blob/master/README.md<https://github.com/yadij/cachemgr.js/blob/master/README.md>>> for basic
access to the reports directly from Browser.
That tool uses HTTP authentication configured via the well-documented
proxy_auth ACLs and http_access for more secure access than the old URL
based mechanism (which still exists, just deprecated).



Cheers
Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org%3cmailto:squid-users at lists.squid-cache.org>>
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users><https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>>


------------------------------

End of squid-users Digest, Vol 116, Issue 31
********************************************
CONFIDENTIALITY NOTICE: The information contained in and attached to this email is intended only for the confidential use of the person or entity to which the email is addressed. This email and any attachments may contain privileged and confidential information. If you are not the intended recipient, you are notified that you received this email in error and that any reading, retention, use or distribution of this email and attachments is strictly prohibited. If you received this email in error, you are requested to immediately notify us by calling 888-728-3550 or by return email and immediately and permanently delete the email and any attachments. Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240521/c5379930/attachment.htm<http://lists.squid-cache.org/pipermail/squid-users/attachments/20240521/c5379930/attachment.htm>>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0.jpg
Type: image/jpeg
Size: 6398 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240521/c5379930/attachment.jpg<http://lists.squid-cache.org/pipermail/squid-users/attachments/20240521/c5379930/attachment.jpg>>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>


------------------------------

End of squid-users Digest, Vol 117, Issue 23
********************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240521/b7a4ba7d/attachment.htm>

From rousskov at measurement-factory.com  Tue May 21 19:51:55 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 21 May 2024 15:51:55 -0400
Subject: [squid-users] log_referrer question
In-Reply-To: <MW5PR14MB52897188C2ED83596B406151B0EA2@MW5PR14MB5289.namprd14.prod.outlook.com>
References: <mailman.3.1713873601.940268.squid-users@lists.squid-cache.org>
 <MW5PR14MB52897188C2ED83596B406151B0EA2@MW5PR14MB5289.namprd14.prod.outlook.com>
Message-ID: <c03ff027-d266-40ed-973c-d228047e8c1b@measurement-factory.com>

On 2024-05-21 13:50, Bobby Matznick wrote:
> I have been trying to use a combined log format for squid. The below 
> line in the squid config is my current attempt.
> 
> logformat combined %>a %[ui %[un [%tl "%rm %ru HTTP/%rv" %>Hs %<st 
> "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh

Please do not redefine built-in logformat configurations like "squid" 
and "combined". Name and define your own instead.


> It is working, as far as logging the normal stuff I would see before 
> having tried to implement referrer. I noticed somewhere that you need to 
> build squid with ?enable-referrer-log, it was an older version, looked 
> like 3.1 and lower, I am using 4.13.

Please upgrade to v6. Squid v4 is not supported by the Squid Project.


> So, checked with squid -v and do 
> not see ??enable-referrer_log? as one of the configure options used 
> during install. Would I need to reinstall, or is that no longer 
> necessary in version 4.13?

referer_log and the corresponding ./configure options have been removed 
long time ago, probably before v4.13 was released.

HTH,

Alex.


> *From:*squid-users <squid-users-bounces at lists.squid-cache.org> *On 
> Behalf Of *squid-users-request at lists.squid-cache.org
> *Sent:* Tuesday, April 23, 2024 6:00 AM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [External] squid-users Digest, Vol 116, Issue 31
> 
> 	
> 
> *Caution:*This is an external email and has a suspicious subject or 
> content. Please take care when clicking links or opening attachments. 
> When in doubt, contact your IT Department
> 
> Send squid-users mailing list submissions to
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
> or, via email, send a message with subject or body 'help' to
> squid-users-request at lists.squid-cache.org 
> <mailto:squid-users-request at lists.squid-cache.org>
> 
> You can reach the person managing the list at
> squid-users-owner at lists.squid-cache.org 
> <mailto:squid-users-owner at lists.squid-cache.org>
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
> 
> 
> Today's Topics:
> 
> 1. Re: Warm cold times (Amos Jeffries)
> 2. Re: Container Based Issues Lock Down Password and Terminate
> SSL (Amos Jeffries)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Tue, 23 Apr 2024 19:41:37 +1200
> From: Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
> To: squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Warm cold times
> Message-ID: <9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz 
> <mailto:9d8f4de6-c797-4e70-aaf5-c073f45c3390 at treenet.co.nz>>
> Content-Type: text/plain; charset=UTF-8; format=flowed
> 
> On 22/04/24 17:42, Jonathan Lee wrote:
>  > Has anyone else taken up the fun challenge of doing windows update 
> caching. It is amazing when it works right. It is a complex 
> configuration, but it is worth it to see a warm download come down that 
> originally took 30 mins instantly to a second client. I didn?t know how 
> much of the updates are the same across different vendor laptops.
>  >
> 
> There have been several people over the years.
> The collected information is being gathered at
> <https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates 
> <https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates>>
> 
> If you would like to check and update the information for the current
> Windows 11 and Squid 6, etc. that would be useful.
> 
> Wiki updates are now made using github PRs against the repository at
> <https://github.com/squid-cache/squid-cache.github.io 
> <https://github.com/squid-cache/squid-cache.github.io>>.
> 
> 
> 
> 
>  > Amazing stuff Squid team.
>  > I wish I could get some of the Roblox Xbox stuff to cache but it?s a 
> night to get running with squid in the first place, I had to splice a 
> bunch of stuff and also wpad the Xbox system.
> 
> FWIW, what I have seen from routing perspective is that Roblox likes to
> use custom ports and P2P connections for a lot of things. So no high
> expectations there, but anything cacheable is great news.
> 
> 
> 
>  >> On Apr 18, 2024, at 23:55, Jonathan Lee wrote:
>  >>
>  >> ?Does anyone know the current warm cold download times for dynamic 
> cache of windows updates?
>  >>
>  >> I can say my experience was a massive increase in the warm download 
> it was delivered in under a couple mins versus 30 or so to download it 
> cold. The warm download was almost instant on the second device. Very 
> green energy efficient.
>  >>
>  >>
>  >> Does squid 5.8 or 6 work better on warm delivery?
> 
> There is no significant differences AFAIK. They both come down to what
> you have configured. That said, the ongoing improvements may make v6
> some amount of "better" - even if only trivial.
> 
> 
> 
>  >> Is there a way to make 100 percent sure a docker container can?t get 
> inside the cache?
> 
> For Windows I would expect the only "100% sure" way is to completely
> forbid access to the disk where the cache is stored.
> 
> 
> The rest of your questions are about container management and Windows
> configuration. Which are kind of off-topic.
> 
> 
> Cheers
> Amos
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Tue, 23 Apr 2024 20:03:42 +1200
> From: Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
> To: squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Container Based Issues Lock Down Password
> and Terminate SSL
> Message-ID: <58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz 
> <mailto:58c41ee7-b88c-4d5a-bd12-220d44465067 at treenet.co.nz>>
> Content-Type: text/plain; charset=UTF-8; format=flowed
> 
> On 23/04/24 11:52, Jonathan Lee wrote:
>  > Hello fellow Squid Accelerator/Dynamic Cache/Web Cache Users/PfSense 
> users
>  >
>  > I think this might resolve any container based issues/fears if they
>  > happened to get into the cache. Ie a Docker Proxy got installed and
>  > tried to data marshal the network card inside of a freeBSD jail or
>  > something like that. Biggest fear with my cache it is a big cache now
>  >
>  > Please yet me know what you think or if it is wrong.
>  >
>  > Here is my configuration. I wanted to share it as it might help to
>  > secure some of this.
> 
> FTR, this config was auto-generated by pfsense. A number of things which
> that tool forces into the config could be done much better in the latest
> Squid, but the tool does not do due to needing to support older Squid
> version.
> 
> 
>  >
>  > Keep in mine I use cachemgr.cgi within Squidlight so I had to set the
>  > password and I have to also adapt the php status file to include the
>  > password and also the sqlight php file.
>  >
>  > After that the status and gui pages work still with the new password.
>  > Only issues area that it shows up in clear text when it goes over the
>  > proxy I can see my password clear as day again that was an issue listed
>  > inside the Squid O?REILLY book also.
> 
> 
> Please ensure you are using the latest Squid v6 release. That release
> has both a number of security fixes, and working https:// URL access to
> the manager reports.
> 
> The cachemgr.cgi tool is deprecated fro a number of issues including
> that style of embedding passwords in the URLs.
> 
> Francesco and I have created a tool that can be found at
> <https://github.com/yadij/cachemgr.js/blob/master/README.md 
> <https://github.com/yadij/cachemgr.js/blob/master/README.md>> for basic
> access to the reports directly from Browser.
> That tool uses HTTP authentication configured via the well-documented
> proxy_auth ACLs and http_access for more secure access than the old URL
> based mechanism (which still exists, just deprecated).
> 
> 
> 
> Cheers
> Amos
> 
> 
> ------------------------------
> 
> Subject: Digest Footer
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
> 
> 
> ------------------------------
> 
> End of squid-users Digest, Vol 116, Issue 31
> ********************************************
> 
> 
> *//*
> 
> */
> <http://www.pbandt.bank>
> 
> CONFIDENTIALITY NOTICE: The information contained in and attached to 
> this email is intended only for the confidential use of the person or 
> entity to which the email is addressed. This email and any attachments 
> may contain privileged and confidential information. If you are not the 
> intended recipient, you are notified that you received this email in 
> error and that any reading, retention, use or distribution of this email 
> and attachments is strictly prohibited. If you received this email in 
> error, you are requested to immediately notify us by calling 
> 888-728-3550 or by return email and immediately and permanently delete 
> the email and any attachments. Thank you. /*//
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Tue May 21 19:57:59 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 21 May 2024 15:57:59 -0400
Subject: [squid-users] log_referrer question
In-Reply-To: <MW5PR14MB52893A5021F3B930A083A2E7B0EA2@MW5PR14MB5289.namprd14.prod.outlook.com>
References: <mailman.2618.1716313869.1200.squid-users@lists.squid-cache.org>
 <MW5PR14MB52893A5021F3B930A083A2E7B0EA2@MW5PR14MB5289.namprd14.prod.outlook.com>
Message-ID: <79954c57-40a3-4e99-b5d3-b75d0bd6b92f@measurement-factory.com>

On 2024-05-21 14:47, Bobby Matznick wrote:
> To add and maybe clarify what my confusion is, the log entries below 
> (hidden internal/external IP?s, domain and username) don?t seem to show 
> what I expected, a line marked ?referrer?. Am I misunderstanding how 
> that should show up in the log?

Kind of: HTTP CONNECT requests normally do not have Referer headers. 
These requests establish a TCP tunnel to an origin server through Squid. 
The "real" requests to origin server are inside that tunnel.

In some cases, it is possible to configure the client and Squid in such 
a way that Squid can look inside that tunnel and find "real" requests, 
but doing so well requires a lot of effort, including becoming a 
Certificate Authority and configuring client to trust certificates 
produced by that Certificate Authority. You can search for SslBump to 
get more information, but the area is full of insurmountable 
difficulties and misleading advice. Avoid it if at all possible.


HTH,

Alex.


> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Tue, 21 May 2024 17:50:49 +0000
> From: Bobby Matznick <bmatznick at pbandt.bank <mailto:bmatznick at pbandt.bank>>
> To: "squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>"
> <squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
> Subject: [squid-users] log_referrer question
> Message-ID:
> <MW5PR14MB52897188C2ED83596B406151B0EA2 at MW5PR14MB5289.namprd14.prod.outlook.com <mailto:MW5PR14MB52897188C2ED83596B406151B0EA2 at MW5PR14MB5289.namprd14.prod.outlook.com>>
> 
> Content-Type: text/plain; charset="utf-8"
> 
> I have been trying to use a combined log format for squid. The below 
> line in the squid config is my current attempt.
> 
> logformat combined %>a %[ui %[un [%tl "%rm %ru HTTP/%rv" %>Hs %<st 
> "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
> 
> It is working, as far as logging the normal stuff I would see before 
> having tried to implement referrer. I noticed somewhere that you need to 
> build squid with -enable-referrer-log, it was an older version, looked 
> like 3.1 and lower, I am using 4.13. So, checked with squid -v and do 
> not see "-enable-referrer_log" as one of the configure options used 
> during install. Would I need to reinstall, or is that no longer 
> necessary in version 4.13? Thanks!!
> 
> Bobby



From squid at digi.ninja  Wed May 22 07:49:10 2024
From: squid at digi.ninja (Robin Wood)
Date: Wed, 22 May 2024 08:49:10 +0100
Subject: [squid-users] Adding an extra header to TLS connection
Message-ID: <CALmccy6b86QKWKDwkvN2VR69hZF4uvMzCnt-f+9z1810HKZtaw@mail.gmail.com>

Hi
I'm trying to work out how to add an extra header to a TLS connection.

I've found information on how to do it on what I think is the pre-3.5
release, but I can't find any useful information on doing it on the current
version.

Could someone give me an example or point me at some documentation on how
to do it.

Thanks

Robin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240522/84958517/attachment.htm>

From squid3 at treenet.co.nz  Wed May 22 13:04:21 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 May 2024 01:04:21 +1200
Subject: [squid-users] log_referrer question
In-Reply-To: <c03ff027-d266-40ed-973c-d228047e8c1b@measurement-factory.com>
References: <mailman.3.1713873601.940268.squid-users@lists.squid-cache.org>
 <MW5PR14MB52897188C2ED83596B406151B0EA2@MW5PR14MB5289.namprd14.prod.outlook.com>
 <c03ff027-d266-40ed-973c-d228047e8c1b@measurement-factory.com>
Message-ID: <7048f5f6-c3e2-4389-8fbb-b44ba5fd6c41@treenet.co.nz>

On 22/05/24 07:51, Alex Rousskov wrote:
> On 2024-05-21 13:50, Bobby Matznick wrote:
>> I have been trying to use a combined log format for squid. The below 
>> line in the squid config is my current attempt.
>>
>> logformat combined %>a %[ui %[un [%tl "%rm %ru HTTP/%rv" %>Hs %<st 
>> "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
> 
> Please do not redefine built-in logformat configurations like "squid" 
> and "combined". Name and define your own instead.
> 

For built-in formats do not use logformat directive at all. Just 
configure the log output:

  access_log daemon:/var/log/squid/access.log combined


As Alex said, please do not try to re-define the built-in formats. If 
you must define *a* format with the same/similar details, use a custom 
name for yours.

> 
>> So, checked with squid -v and do not see ??enable-referrer_log? as one 
>> of the configure options used during install. Would I need to 
>> reinstall, or is that no longer necessary in version 4.13?
> 
> referer_log and the corresponding ./configure options have been removed 
> long time ago, probably before v4.13 was released.
> 

Since Squid v3.2 that log has been a built-in logformat. Just configure 
a log like this:

  access_log daemon:/var/log/squid/access.log referrer


HTH
Amos


From rousskov at measurement-factory.com  Thu May 23 15:49:10 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 23 May 2024 11:49:10 -0400
Subject: [squid-users] Adding an extra header to TLS connection
In-Reply-To: <CALmccy6b86QKWKDwkvN2VR69hZF4uvMzCnt-f+9z1810HKZtaw@mail.gmail.com>
References: <CALmccy6b86QKWKDwkvN2VR69hZF4uvMzCnt-f+9z1810HKZtaw@mail.gmail.com>
Message-ID: <fac1780c-4cfe-43e1-862a-8e8beb6e13c0@measurement-factory.com>

On 2024-05-22 03:49, Robin Wood wrote:

> I'm trying to work out how to add an extra header to a TLS connection.

I assume that you want to add a header field to an HTTP request or 
response that is being transmitted inside a TLS connection between a TLS 
client (e.g., a user browser) and an HTTPS origin server.

Do you control the client that originates that TLS connection (or its 
OS/environment) or the origin server? If you do not, then what you want 
is impossible -- TLS encryption exists, in part, to prevent such traffic 
modifications.

If you control the client that originates that TLS connection (or its 
OS/environment), then you may be able to, in _some_ cases, add that 
header by configuring the client (or its OS/environment) to trust you as 
a Certificate Authority, minting your own X509 certificates, and 
configuring Squid to perform a "man in the middle" attack on 
client-server traffic, using your minted certificates. You can search 
for Squid SslBump to get more information about this feature, but the 
area is full of insurmountable difficulties and misleading advice. Avoid 
it if at all possible!


HTH,

Alex.


> I've found information on how to do it on what I think is the pre-3.5 
> release, but I can't find any useful information on doing it on the 
> current version.
> 
> Could someone give me an example or point me at some documentation on 
> how to do it.
> 
> Thanks
> 
> Robin
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Thu May 23 16:59:25 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 23 May 2024 09:59:25 -0700
Subject: [squid-users] Adding an extra header to TLS connection
In-Reply-To: <fac1780c-4cfe-43e1-862a-8e8beb6e13c0@measurement-factory.com>
References: <fac1780c-4cfe-43e1-862a-8e8beb6e13c0@measurement-factory.com>
Message-ID: <75EBE016-0A78-4593-99B2-2EF9B5EBB10F@gmail.com>

I do use ssl bump again it requires certificates installed on the devices, and or some and a splice for the others. You must also add a url list for items that must never be intercepted like banks etc. I agree it is not an easy task, it took me years to get it to work correctly for what I needed. When it does work it works beautifully, you can cache updates and reuse them, you can use clam AV on https traffic. It?s not for everyone it will make you a wizard level 1000 if you can get it going.
Sent from my iPhone

> On May 23, 2024, at 08:49, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 2024-05-22 03:49, Robin Wood wrote:
> 
>> I'm trying to work out how to add an extra header to a TLS connection.
> 
> I assume that you want to add a header field to an HTTP request or response that is being transmitted inside a TLS connection between a TLS client (e.g., a user browser) and an HTTPS origin server.
> 
> Do you control the client that originates that TLS connection (or its OS/environment) or the origin server? If you do not, then what you want is impossible -- TLS encryption exists, in part, to prevent such traffic modifications.
> 
> If you control the client that originates that TLS connection (or its OS/environment), then you may be able to, in _some_ cases, add that header by configuring the client (or its OS/environment) to trust you as a Certificate Authority, minting your own X509 certificates, and configuring Squid to perform a "man in the middle" attack on client-server traffic, using your minted certificates. You can search for Squid SslBump to get more information about this feature, but the area is full of insurmountable difficulties and misleading advice. Avoid it if at all possible!
> 
> 
> HTH,
> 
> Alex.
> 
> 
>> I've found information on how to do it on what I think is the pre-3.5 release, but I can't find any useful information on doing it on the current version.
>> Could someone give me an example or point me at some documentation on how to do it.
>> Thanks
>> Robin
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From squid at digi.ninja  Thu May 23 17:06:01 2024
From: squid at digi.ninja (Robin Wood)
Date: Thu, 23 May 2024 18:06:01 +0100
Subject: [squid-users] Adding an extra header to TLS connection
In-Reply-To: <75EBE016-0A78-4593-99B2-2EF9B5EBB10F@gmail.com>
References: <fac1780c-4cfe-43e1-862a-8e8beb6e13c0@measurement-factory.com>
 <75EBE016-0A78-4593-99B2-2EF9B5EBB10F@gmail.com>
Message-ID: <CALmccy4dboZq61cRF0gv8VUgs-JRaYJdsn-cFpW7tHqYYGr1VA@mail.gmail.com>

On Thu, 23 May 2024 at 18:00, Jonathan Lee <jonathanlee571 at gmail.com> wrote:

> I do use ssl bump again it requires certificates installed on the devices,
> and or some and a splice for the others. You must also add a url list for
> items that must never be intercepted like banks etc. I agree it is not an
> easy task, it took me years to get it to work correctly for what I needed.
> When it does work it works beautifully, you can cache updates and reuse
> them, you can use clam AV on https traffic. It?s not for everyone it will
> make you a wizard level 1000 if you can get it going.
>

Jonathan, can you give me an example of it working?

Oddly, you are replying to a message from Alex that I never received.

Alex, in answer to your questions...

I'm doing some testing against a client's site, they require a custom
header to allow my connections through their WAF. I could try to do this
manually with all my tools, but it would be easier to just have Squid do it
for me and then have the tools use Squid as their proxy. I can tell them to
not do cert checking or I can use my own CA and import it into the system
store, that is not a problem.

I've tried searching for Squid and sslbump and not found anything useful
that works with the current version, that is why I'm asking here, I was
hoping someone could point me at an example that would definitely work with
the current version of Squid.

Robin


> Sent from my iPhone
>
> > On May 23, 2024, at 08:49, Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
> >
> > ?On 2024-05-22 03:49, Robin Wood wrote:
> >
> >> I'm trying to work out how to add an extra header to a TLS connection.
> >
> > I assume that you want to add a header field to an HTTP request or
> response that is being transmitted inside a TLS connection between a TLS
> client (e.g., a user browser) and an HTTPS origin server.
> >
> > Do you control the client that originates that TLS connection (or its
> OS/environment) or the origin server? If you do not, then what you want is
> impossible -- TLS encryption exists, in part, to prevent such traffic
> modifications.
> >
> > If you control the client that originates that TLS connection (or its
> OS/environment), then you may be able to, in _some_ cases, add that header
> by configuring the client (or its OS/environment) to trust you as a
> Certificate Authority, minting your own X509 certificates, and configuring
> Squid to perform a "man in the middle" attack on client-server traffic,
> using your minted certificates. You can search for Squid SslBump to get
> more information about this feature, but the area is full of insurmountable
> difficulties and misleading advice. Avoid it if at all possible!
> >
> >
> > HTH,
> >
> > Alex.
> >
> >
> >> I've found information on how to do it on what I think is the pre-3.5
> release, but I can't find any useful information on doing it on the current
> version.
> >> Could someone give me an example or point me at some documentation on
> how to do it.
> >> Thanks
> >> Robin
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> https://lists.squid-cache.org/listinfo/squid-users
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240523/b1c26534/attachment.htm>

From rousskov at measurement-factory.com  Thu May 23 18:53:15 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 23 May 2024 14:53:15 -0400
Subject: [squid-users] Adding an extra header to TLS connection
In-Reply-To: <CALmccy4dboZq61cRF0gv8VUgs-JRaYJdsn-cFpW7tHqYYGr1VA@mail.gmail.com>
References: <fac1780c-4cfe-43e1-862a-8e8beb6e13c0@measurement-factory.com>
 <75EBE016-0A78-4593-99B2-2EF9B5EBB10F@gmail.com>
 <CALmccy4dboZq61cRF0gv8VUgs-JRaYJdsn-cFpW7tHqYYGr1VA@mail.gmail.com>
Message-ID: <4e8f87d8-7bd9-4220-be28-c15fc7dad263@measurement-factory.com>

On 2024-05-23 13:06, Robin Wood wrote:
> I've tried searching for Squid and sslbump and not found anything useful 
> that works with the current version, that is why I'm asking here, I was 
> hoping someone could point me at an example that would definitely work 
> with the current version of Squid.

FWIW, most of the basics are covered at
https://wiki.squid-cache.org/Features/SslPeekAndSplice

That page was written for a feature introduced in v3.5, but it is not 
specific to that Squid version.


HTH,

Alex.


>      > On May 23, 2024, at 08:49, Alex Rousskov wrote:
>      >
>      > ?On 2024-05-22 03:49, Robin Wood wrote:
>      >
>      >> I'm trying to work out how to add an extra header to a TLS
>     connection.
>      >
>      > I assume that you want to add a header field to an HTTP request
>     or response that is being transmitted inside a TLS connection
>     between a TLS client (e.g., a user browser) and an HTTPS origin server.
>      >
>      > Do you control the client that originates that TLS connection (or
>     its OS/environment) or the origin server? If you do not, then what
>     you want is impossible -- TLS encryption exists, in part, to prevent
>     such traffic modifications.
>      >
>      > If you control the client that originates that TLS connection (or
>     its OS/environment), then you may be able to, in _some_ cases, add
>     that header by configuring the client (or its OS/environment) to
>     trust you as a Certificate Authority, minting your own X509
>     certificates, and configuring Squid to perform a "man in the middle"
>     attack on client-server traffic, using your minted certificates. You
>     can search for Squid SslBump to get more information about this
>     feature, but the area is full of insurmountable difficulties and
>     misleading advice. Avoid it if at all possible!
>      >
>      >
>      > HTH,
>      >
>      > Alex.
>      >
>      >
>      >> I've found information on how to do it on what I think is the
>     pre-3.5 release, but I can't find any useful information on doing it
>     on the current version.
>      >> Could someone give me an example or point me at some
>     documentation on how to do it.
>      >> Thanks
>      >> Robin
>      >> _______________________________________________
>      >> squid-users mailing list
>      >> squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >> https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >
>      > _______________________________________________
>      > squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      > https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
> 



From pheriko.support at gmail.com  Fri May 24 05:43:25 2024
From: pheriko.support at gmail.com (Periko Support)
Date: Thu, 23 May 2024 22:43:25 -0700
Subject: [squid-users] Simulate connections for tuning squid?
Message-ID: <CAK2yrTbTD6t0WHmMvfBKUWYzapFoXjt2EQshqSyFh-CVQiw+Tg@mail.gmail.com>

Hello guys.

I would like to know if there exists a tool that helps us simulate
connections to squid and helps us tune squid for different scenarios
like small, medium or large networks?

Any info I would appreciate, thanks!!!


From rousskov at measurement-factory.com  Fri May 24 14:01:02 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 24 May 2024 10:01:02 -0400
Subject: [squid-users] Simulate connections for tuning squid?
In-Reply-To: <CAK2yrTbTD6t0WHmMvfBKUWYzapFoXjt2EQshqSyFh-CVQiw+Tg@mail.gmail.com>
References: <CAK2yrTbTD6t0WHmMvfBKUWYzapFoXjt2EQshqSyFh-CVQiw+Tg@mail.gmail.com>
Message-ID: <39e268df-fcad-4460-a951-1654acb2f822@measurement-factory.com>

On 2024-05-24 01:43, Periko Support wrote:

> I would like to know if there exists a tool that helps us simulate
> connections to squid and helps us tune squid for different scenarios
> like small, medium or large networks?

Yes, there are many tools, offering various tradeoffs, including:

* Apache "ab": Not designed for testing proxies but well-known and 
fairly simple.

* Web Polygraph: Designed for testing proxies but has a steep learning 
curve and lacks fresh releases.

* curl/wget/netcat: Not designed for testing performance but well-known 
and very simple.

Alex.



From squid at kretz.net  Fri May 24 19:28:02 2024
From: squid at kretz.net (Kevin)
Date: Fri, 24 May 2024 19:28:02 +0000 (UTC)
Subject: [squid-users] can't explain 403 denied for authenticated user
Message-ID: <1201410059.1716631.1716578882350.JavaMail.zimbra@kretz.net>

Hi, 

We have 2 external ACLs that take a request's data (IP, authenticated username, URL, user-agent, etc) and uses that information to determine whether a user or host should be permitted to access that URL. It almost always works well, but we have a recurring occasional issue that I can't figure out. 

When it occurs, it's always around 4AM. This particular request occurs often - averages about once a second throughout the day. 

What we see is a "403 forbidden" for a (should be) permitted site from an authenticated user from the same IP/user and to the same site that gets a "202 connection established" every other time. 

The difference I see in the logs: though all the digest auth info looks okay, the %un field in the log for the usual (successful) request is the authenticated username, while in the failed request, it's "-". So though there hasn't been an authentication error or "authentication required" in the log - and the username is in the authentication details in the log entry - it seems like squid isn't recognizing that username as %un. 

My squid.conf first tests a request to see if an unauthenticated request from a particular host is permitted. That external ACL doesn't take a username as an argument. If that external ACL passes, the request is allowed. 

The next line in squid.conf is 

acl auth_users proxy_auth REQUIRED 

... and after that, the external ACL that takes the username as well as the other info. 

The filter has its own log. For most authenticated requests, we see four entries in that log for each of this particular request: 

HostBasedRequest 
HostBasedResponse 
UserBasedRequest 
UserBasedResponse 

When the issue occurs, we see a blip in the pattern when looking at only this particular request, like: 


HostBasedRequest 
HostBasedRespons 
HostBasedRequest 
HostBasedResponse 
UserBasedRequest 
UserBasedResponse 

so it looks like the requests that experience the issue don't get past that "acl auth_users proxy_auth REQUIRED" directive. 

One more clue: The last morning the issue occurred, we saw 8 instances of "403 forbidden" responses (out of roughly 5800 that hour). When I looked at the log entry for one of them (included below) and looked for other instances of the cnonce in the digest auth info, I saw that cnonce in five of the eight log entries showing the issue. 

Any ideas or suggestions? Here are two logs: one illustrating the issue and the other showing how a typical successful request is logged. 



thanks! 

12.34.56.78 - - [20/May/2024:04:00:00 -0400] "CONNECT abc.defg.net:443 HTTP/1.1" 403 4276 "-" "Java/21.0.1" TCP_DENIED:HIER_NONE [User-Agent: Java/21.0.1\r\nAccept: */*\r\nProxy-Connection: keep-alive\r\nProxy-Authorization: Digest username="service_uname", realm="squid", nonce="eca7c1c8831a2fc2b0afb3ee95862950", nc=00000035, uri="abc.defg.net:443", response="88f2110f926ba56c3b1a84a1321a051c", algorithm=MD5, cnonce="BHGEEDNBMEPIIMIDLABNJHJNAIEHLKPGGEDFCLHG", qop=auth\r\nHost: abc.defg.net:443\r\n] [HTTP/1.1 403 Forbidden\r\nServer: squid/5.7\r\nMime-Version: 1.0\r\nDate: Mon, 20 May 2024 08:00:00 GMT\r\nContent-Type: text/html;charset=utf-8\r\nContent-Length: 3884\r\nX-Squid-Error: ERR_ACCESS_DENIED 0\r\nVary: Accept-Language\r\nContent-Language: en\r\nX-Cache: MISS from proxy.acme.com\r\nX-Cache-Lookup: NONE from proxy.acme.com:3128\r\nVia: 1.1 proxy.acme.com (squid/5.7)\r\nConnection: keep-alive\r\n\r\n] 



12.34.56.78 - service_uname [20/May/2024:10:50:10 -0400] "CONNECT abc.defg.net:443 HTTP/1.1" 200 2939 "-" "Java/21.0.1" TCP_TUNNEL:HIER_DIRECT [User-Agent: Java/21.0.1\r\nAccept: */*\r\nProxy-Connection: keep-alive\r\nProxy-Authorization: Digest username="service_uname", realm="squid", nonce="3e30376ba9c74cb016b3d8cfe1bf8a81", nc=0000002f, uri="abc.defg.net:443", response="f8f720d4e2bb9324e1a90bcfafecd1c5", algorithm=MD5, cnonce="KDJPEGFBCHFLMCJMAPEBMEGJNKOHOBEDOAEINPKL", qop=auth\r\nHost: abc.defg.net:443\r\n] [HTTP/1.1 200 Connection established\r\n\r\n] 



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240524/8ddedf79/attachment.htm>

From anton.kornexl at miex.cc  Tue May 28 14:23:45 2024
From: anton.kornexl at miex.cc (Anton Kornexl)
Date: Tue, 28 May 2024 16:23:45 +0200
Subject: [squid-users] urlfilterdb.com
Message-ID: <4e8daa19-9264-403e-acad-c1584b0eb62e@miex.cc>

Hello,

since two days the domain urlfilterdb.com is not resolved to an IP.? We 
get no updates to the urlfiter-DB and the homepage can?t be opned.

Does someone know the reason?

Kind regards

Anton




From support at unveiltech.com  Tue May 28 17:11:39 2024
From: support at unveiltech.com (UnveilTech - Support)
Date: Tue, 28 May 2024 17:11:39 +0000
Subject: [squid-users] urlfilterdb.com
In-Reply-To: <4e8daa19-9264-403e-acad-c1584b0eb62e@miex.cc>
References: <4e8daa19-9264-403e-acad-c1584b0eb62e@miex.cc>
Message-ID: <60d181a0460c4d8cbd2ff792d2bf3350@unveiltech.com>

Hello Anton,

We don't use this domain anymore.

Best regards,
UnveilTech Support Team
www.unveiltech.com
Skype: unveiltechsupportteam

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Anton Kornexl
Envoy??: mardi 28 mai 2024 16:24
??: squid-users at lists.squid-cache.org
Objet?: [squid-users] urlfilterdb.com

Hello,

since two days the domain urlfilterdb.com is not resolved to an IP.? We get no updates to the urlfiter-DB and the homepage can?t be opned.

Does someone know the reason?

Kind regards

Anton


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users

From support at unveiltech.com  Tue May 28 17:12:45 2024
From: support at unveiltech.com (UnveilTech - Support)
Date: Tue, 28 May 2024 17:12:45 +0000
Subject: [squid-users] urlfilterdb.com
In-Reply-To: <60d181a0460c4d8cbd2ff792d2bf3350@unveiltech.com>
References: <4e8daa19-9264-403e-acad-c1584b0eb62e@miex.cc>
 <60d181a0460c4d8cbd2ff792d2bf3350@unveiltech.com>
Message-ID: <b9fa00d71bc94f8b970858ac28fc325e@unveiltech.com>

Hello,

Forget our answer, wrong reply...

Best regards,
UnveilTech Support Team
www.unveiltech.com
Skype: unveiltechsupportteam

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de UnveilTech - Support
Envoy??: mardi 28 mai 2024 19:12
??: Anton Kornexl <anton.kornexl at miex.cc>; squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] urlfilterdb.com

Hello Anton,

We don't use this domain anymore.

Best regards,
UnveilTech Support Team
www.unveiltech.com
Skype: unveiltechsupportteam

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Anton Kornexl Envoy??: mardi 28 mai 2024 16:24 ??: squid-users at lists.squid-cache.org Objet?: [squid-users] urlfilterdb.com

Hello,

since two days the domain urlfilterdb.com is not resolved to an IP.? We get no updates to the urlfiter-DB and the homepage can?t be opned.

Does someone know the reason?

Kind regards

Anton


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users

From Rik.Theys at esat.kuleuven.be  Wed May 29 09:01:31 2024
From: Rik.Theys at esat.kuleuven.be (Rik Theys)
Date: Wed, 29 May 2024 11:01:31 +0200
Subject: [squid-users] Validation of IP address for SSL spliced connections
Message-ID: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>

Hi,

I'm configuring squid as a transparent proxy where local outbound 
traffic is redirect to a local squid process using tproxy.

I would like to limit the domains the host can contact by having an 
allow list. I have the following config file:

------

acl allowed_clients src "/etc/squid/allowed_clients"

acl allowed_domains dstdomain "/etc/squid/allowed_domains"

acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 443
acl CONNECT method CONNECT

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

# Additional access control lists
acl https_domains ssl::server_name "/etc/squid/allowed_domains"

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
http_access allow allowed_clients allowed_domains
http_access allow allowed_clients CONNECT

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128
http_port 3129 tproxy
https_port 3130 tproxy ssl-bump cert=/etc/squid/cert/local_ca.pem

# SSL bump configuration
ssl_bump peek step1
ssl_bump peek step2 https_domains
ssl_bump splice step3 https_domains
ssl_bump terminate all

------

When the Host header in an intercepted request matches a domain on the 
allowed_domains list, the request is allowed. Otherwise it's denied as 
expected.

But squid doesn't seem to validate that the IP address we're connecting 
to is valid for the specified name in the SNI header?

For example, if I add "wordpress.org" to my allowed_domains list, the 
following request is allowed:

curl -v https://wordpress.org --connect-to wordpress.org:443:8.8.8.8:443

8.8.8.8 is not a valid IP address for wordpress.org. This could be used 
to bypass the restrictions.

Is there an option in squid to make it perform a forward DNS lookup for 
the domain from the SNI information from step1 to validate that the IP 
address we're trying to connect to is actually valid for that host? In 
the example above, a DNS lookup for wordpress.org would return 
198.143.164.252 as the IP address. This is not the IP address we're 
trying to connect to, so squid should block the request.

Similar question for the server certificate: I've configured the 
'ssl_bump peek step2 https_domains' line so squid can peek at the server 
certificate. Is there a way to configure squid to validate that the 
server certificate is valid for the host specified in the SNI header?


Regards,

Rik
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240529/b843ca1b/attachment.htm>

From rousskov at measurement-factory.com  Wed May 29 15:29:18 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 29 May 2024 11:29:18 -0400
Subject: [squid-users] Validation of IP address for SSL spliced
 connections
In-Reply-To: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>
References: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>
Message-ID: <eead6ccc-96e9-4441-9200-35bcf37fee73@measurement-factory.com>

On 2024-05-29 05:01, Rik Theys wrote:
> acl allowed_clients src "/etc/squid/allowed_clients"
> acl allowed_domains dstdomain "/etc/squid/allowed_domains"

> http_access allow allowed_clients allowed_domains
> http_access allow allowed_clients CONNECT
> http_access deny all

Please note that the second http_access rule in the above configuration 
allows CONNECT tunnels to prohibited domains (i.e. domains that do not 
match allowed_domains). Consider restricting your "allow...CONNECT" rule 
to step1. For example:

     http_access allow allowed_clients step1 CONNECT


> squid doesn't seem to validate that the IP address we're connecting 
> to is valid for the specified name in the SNI header?

That observation matches my reading of Squid Host header forgery 
detection code which says "we do not yet handle CONNECT tunnels well, so 
ignore for them". To validate that theory, use "debug_options ALL,3" and 
look for "SECURITY ALERT: Host header forgery detected" messages in 
cache.log.

Please note that in many environments forgery detection does not work 
well (for cases where it is performed) due to clients and Squid seeing 
different sets of IP addresses for the same host name. There are 
numerous complains about that in squid-users archives.


> For example, if I add "wordpress.org" to my allowed_domains list, the 
> following request is allowed:
> 
> curl -v https://wordpress.org --connect-to wordpress.org:443:8.8.8.8:443
> 
> 8.8.8.8 is not a valid IP address for wordpress.org. This could be used 
> to bypass the restrictions.

Agreed.


> Is there an option in squid to make it perform a forward DNS lookup for 
> the domain from the SNI information from step1

FYI: SNI comes from step2. step1 looks at TCP/IP client info.


> to validate that the IP 
> address we're trying to connect to is actually valid for that host? In 
> the example above, a DNS lookup for wordpress.org would return 
> 198.143.164.252 as the IP address. This is not the IP address we're 
> trying to connect to, so squid should block the request.

AFAICT, there is no built-in support for that in current Squid code. One 
could enhance Squid or write an external ACL to perform that kind of 
validation. See above for details/caveats.


> Similar question for the server certificate: I've configured the 
> 'ssl_bump peek step2 https_domains' line so squid can peek at the server 
> certificate.

Peeking at the server certificates happens at step3. In many modern use 
cases, server certificates are encrypted, so a _peeking_ Squid cannot 
see them. To validate, Squid has to bump the tunnel (supported today but 
problematic for other reasons) or be enhanced to use out-of-band 
validation tricks (that come with their own set of problems).


> Is there a way to configure squid to validate that the 
> server certificate is valid for the host specified in the SNI header?

IIRC, that validation happens automatically in modern Squid versions 
when Squid receives an (unencrypted) server certificate.


HTH,

Alex.



From Rik.Theys at esat.kuleuven.be  Wed May 29 21:06:08 2024
From: Rik.Theys at esat.kuleuven.be (Rik Theys)
Date: Wed, 29 May 2024 23:06:08 +0200
Subject: [squid-users] Validation of IP address for SSL spliced
 connections
In-Reply-To: <eead6ccc-96e9-4441-9200-35bcf37fee73@measurement-factory.com>
References: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>
 <eead6ccc-96e9-4441-9200-35bcf37fee73@measurement-factory.com>
Message-ID: <54178fff-365f-4fa5-b2ec-0b13b829a0ca@esat.kuleuven.be>

Hi,

On 5/29/24 5:29 PM, Alex Rousskov wrote:
> On 2024-05-29 05:01, Rik Theys wrote:
>> acl allowed_clients src "/etc/squid/allowed_clients"
>> acl allowed_domains dstdomain "/etc/squid/allowed_domains"
>
>> http_access allow allowed_clients allowed_domains
>> http_access allow allowed_clients CONNECT
>> http_access deny all
>
> Please note that the second http_access rule in the above 
> configuration allows CONNECT tunnels to prohibited domains (i.e. 
> domains that do not match allowed_domains). Consider restricting your 
> "allow...CONNECT" rule to step1. For example:
>
> ??? http_access allow allowed_clients step1 CONNECT
Thanks, I've updated my configuration.
>
>
>> squid doesn't seem to validate that the IP address we're connecting 
>> to is valid for the specified name in the SNI header?
>
> That observation matches my reading of Squid Host header forgery 
> detection code which says "we do not yet handle CONNECT tunnels well, 
> so ignore for them". To validate that theory, use "debug_options 
> ALL,3" and look for "SECURITY ALERT: Host header forgery detected" 
> messages in cache.log.
>
I've enabled this debug option, but I never see the security alert in 
the logs. Maybe it was introduced in more recent versions? I'm currently 
using Squid 5.5 that comes with Rocky Linux 9.4.

Looking at the logs, I'm also having problems determining where each 
ssl-bump step is started.

> Please note that in many environments forgery detection does not work 
> well (for cases where it is performed) due to clients and Squid seeing 
> different sets of IP addresses for the same host name. There are 
> numerous complains about that in squid-users archives.
>
>
>> For example, if I add "wordpress.org" to my allowed_domains list, the 
>> following request is allowed:
>>
>> curl -v https://wordpress.org --connect-to wordpress.org:443:8.8.8.8:443
>>
>> 8.8.8.8 is not a valid IP address for wordpress.org. This could be 
>> used to bypass the restrictions.
>
> Agreed.
>
>
>> Is there an option in squid to make it perform a forward DNS lookup 
>> for the domain from the SNI information from step1
>
> FYI: SNI comes from step2. step1 looks at TCP/IP client info.
>
>
>> to validate that the IP address we're trying to connect to is 
>> actually valid for that host? In the example above, a DNS lookup for 
>> wordpress.org would return 198.143.164.252 as the IP address. This is 
>> not the IP address we're trying to connect to, so squid should block 
>> the request.
>
> AFAICT, there is no built-in support for that in current Squid code. 
> One could enhance Squid or write an external ACL to perform that kind 
> of validation. See above for details/caveats.
>
>
>> Similar question for the server certificate: I've configured the 
>> 'ssl_bump peek step2 https_domains' line so squid can peek at the 
>> server certificate.
>
> Peeking at the server certificates happens at step3. In many modern 
> use cases, server certificates are encrypted, so a _peeking_ Squid 
> cannot see them. To validate, Squid has to bump the tunnel (supported 
> today but problematic for other reasons) or be enhanced to use 
> out-of-band validation tricks (that come with their own set of problems).

I guess that explains why if I add "%ssl::<cert_subject" to my logformat 
for the access log, the field is always "-"?

>
>
>> Is there a way to configure squid to validate that the server 
>> certificate is valid for the host specified in the SNI header?
>
> IIRC, that validation happens automatically in modern Squid versions 
> when Squid receives an (unencrypted) server certificate.
>
Do you happen to known which version of Squid introduced that check?

Regards,

Rik




From rousskov at measurement-factory.com  Wed May 29 21:31:59 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 29 May 2024 17:31:59 -0400
Subject: [squid-users] Validation of IP address for SSL spliced
 connections
In-Reply-To: <54178fff-365f-4fa5-b2ec-0b13b829a0ca@esat.kuleuven.be>
References: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>
 <eead6ccc-96e9-4441-9200-35bcf37fee73@measurement-factory.com>
 <54178fff-365f-4fa5-b2ec-0b13b829a0ca@esat.kuleuven.be>
Message-ID: <5aca3feb-490c-4a17-a423-6fb2d4ae6b9e@measurement-factory.com>

On 2024-05-29 17:06, Rik Theys wrote:
> On 5/29/24 5:29 PM, Alex Rousskov wrote:
>> On 2024-05-29 05:01, Rik Theys wrote:
>>> acl allowed_clients src "/etc/squid/allowed_clients"
>>> acl allowed_domains dstdomain "/etc/squid/allowed_domains"
>>
>>> http_access allow allowed_clients allowed_domains
>>> http_access allow allowed_clients CONNECT
>>> http_access deny all
>>
>> Please note that the second http_access rule in the above 
>> configuration allows CONNECT tunnels to prohibited domains (i.e. 
>> domains that do not match allowed_domains). Consider restricting your 
>> "allow...CONNECT" rule to step1. For example:
>>
>> ??? http_access allow allowed_clients step1 CONNECT
> Thanks, I've updated my configuration.


Please do test any suggested changes. There are too many variables here 
for me to guarantee that a particular set of http_access and ssl_bump 
rules works as expected.


>>> squid doesn't seem to validate that the IP address we're connecting 
>>> to is valid for the specified name in the SNI header?
>>
>> That observation matches my reading of Squid Host header forgery 
>> detection code which says "we do not yet handle CONNECT tunnels well, 
>> so ignore for them". To validate that theory, use "debug_options 
>> ALL,3" and look for "SECURITY ALERT: Host header forgery detected" 
>> messages in cache.log.

> I've enabled this debug option, but I never see the security alert in 
> the logs. Maybe it was introduced in more recent versions? I'm currently 
> using Squid 5.5 that comes with Rocky Linux 9.4.

The code logging "SECURITY ALERT: Host header forgery detected" messages 
is present in v5.5, but perhaps it is not triggered in that version (or 
even in modern/supported Squids) when I expect it to be triggered. 
Unfortunately, there are too many variables for me to predict what 
exactly went wrong in your particular test case without doing a lot more 
work (and I cannot volunteer to do that work right now).


> Looking at the logs, I'm also having problems determining where each 
> ssl-bump step is started.

Yes, it is a known problem (even for developers). There are also bugs 
related to step boundaries.


>> Peeking at the server certificates happens at step3. In many modern 
>> use cases, server certificates are encrypted, so a _peeking_ Squid 
>> cannot see them. To validate, Squid has to bump the tunnel (supported 
>> today but problematic for other reasons) or be enhanced to use 
>> out-of-band validation tricks (that come with their own set of problems).

> I guess that explains why if I add "%ssl::<cert_subject" to my logformat 
> for the access log, the field is always "-"?

It may explain that, but other problems may lead to the same "no 
certificate" result as well, of course. You can kind of check by using 
stare/bump instead of peek/splice -- if you see certificate details 
logged in that bumping test, then it is more likely that Squid just does 
not get a plain text certificate in peeking configurations.


>>> Is there a way to configure squid to validate that the server 
>>> certificate is valid for the host specified in the SNI header?
>>
>> IIRC, that validation happens automatically in modern Squid versions 
>> when Squid receives an (unencrypted) server certificate.
>>
> Do you happen to known which version of Squid introduced that check?

IIRC, Squid v5.5 has that code.


HTH,

Alex.



From Rik.Theys at esat.kuleuven.be  Thu May 30 06:30:27 2024
From: Rik.Theys at esat.kuleuven.be (Rik Theys)
Date: Thu, 30 May 2024 08:30:27 +0200
Subject: [squid-users] Validation of IP address for SSL spliced
 connections
In-Reply-To: <5aca3feb-490c-4a17-a423-6fb2d4ae6b9e@measurement-factory.com>
References: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>
 <eead6ccc-96e9-4441-9200-35bcf37fee73@measurement-factory.com>
 <54178fff-365f-4fa5-b2ec-0b13b829a0ca@esat.kuleuven.be>
 <5aca3feb-490c-4a17-a423-6fb2d4ae6b9e@measurement-factory.com>
Message-ID: <a4b55d47-6122-43f6-aed0-0aa1741dcd28@esat.kuleuven.be>

Hi,

On 5/29/24 11:31 PM, Alex Rousskov wrote:
> On 2024-05-29 17:06, Rik Theys wrote:
>> On 5/29/24 5:29 PM, Alex Rousskov wrote:
>>> On 2024-05-29 05:01, Rik Theys wrote:
>
>
>>>> squid doesn't seem to validate that the IP address we're connecting 
>>>> to is valid for the specified name in the SNI header?
>>>
>>> That observation matches my reading of Squid Host header forgery 
>>> detection code which says "we do not yet handle CONNECT tunnels 
>>> well, so ignore for them". To validate that theory, use 
>>> "debug_options ALL,3" and look for "SECURITY ALERT: Host header 
>>> forgery detected" messages in cache.log.
>
>> I've enabled this debug option, but I never see the security alert in 
>> the logs. Maybe it was introduced in more recent versions? I'm 
>> currently using Squid 5.5 that comes with Rocky Linux 9.4.
>
> The code logging "SECURITY ALERT: Host header forgery detected" 
> messages is present in v5.5, but perhaps it is not triggered in that 
> version (or even in modern/supported Squids) when I expect it to be 
> triggered. Unfortunately, there are too many variables for me to 
> predict what exactly went wrong in your particular test case without 
> doing a lot more work (and I cannot volunteer to do that work right now).

Looking at https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery, 
it always seems to mention the Host header. It has no mention of 
performing the same checks for the SNI value. Since we're peeking at the 
request, we can't see the actual Host header being sent.

And indeed: if I perform the same test for HTTP traffic, I do see the 
error message:

curl http://wordpress.org --connect-to wordpress.org:80:8.8.8.8:80


I believe that for my use-case (only splice certain domains and prevent 
connecting to a wrong IP address), there's currently no solution then. 
Squid would also have to perform a similar check as the Host check for 
the SNI information. Maybe I can perform the same function with an 
external acl as you've mentioned. I will look into that later. Thanks 
for your time.

>
>
>> Looking at the logs, I'm also having problems determining where each 
>> ssl-bump step is started.
>
> Yes, it is a known problem (even for developers). There are also bugs 
> related to step boundaries.
>
>
>>> Peeking at the server certificates happens at step3. In many modern 
>>> use cases, server certificates are encrypted, so a _peeking_ Squid 
>>> cannot see them. To validate, Squid has to bump the tunnel 
>>> (supported today but problematic for other reasons) or be enhanced 
>>> to use out-of-band validation tricks (that come with their own set 
>>> of problems).
>
>> I guess that explains why if I add "%ssl::<cert_subject" to my 
>> logformat for the access log, the field is always "-"?
>
> It may explain that, but other problems may lead to the same "no 
> certificate" result as well, of course. You can kind of check by using 
> stare/bump instead of peek/splice -- if you see certificate details 
> logged in that bumping test, then it is more likely that Squid just 
> does not get a plain text certificate in peeking configurations.

I've updated the configuration to use stare/bump instead. The field is 
then indeed added to the log file. A curl request that forces the 
connection to a different IP address then also fails because the 
certificate isn't valid for the name. There's no mention of the Host 
header not matching the IP address, but I assume that check comes after 
the certificate check then.

Regards,

Rik




From marcus.kool at urlfilterdb.com  Thu May 30 08:38:15 2024
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 30 May 2024 09:38:15 +0100
Subject: [squid-users] urlfilterdb.com
In-Reply-To: <4e8daa19-9264-403e-acad-c1584b0eb62e@miex.cc>
References: <4e8daa19-9264-403e-acad-c1584b0eb62e@miex.cc>
Message-ID: <31a5d08a-6bf0-4ba8-b749-4efbeb1826e1@urlfilterdb.com>

Not sure if this message was meant for the Squid mailing list but for those who are interested, the DNS provider had an issue with DNSSEC resigning and all is well now.

Marcus


On 28/05/2024 15:23, Anton Kornexl wrote:
> Hello,
>
> since two days the domain urlfilterdb.com is not resolved to an IP.? We get no updates to the urlfiter-DB and the homepage can?t be opned.
>
> Does someone know the reason?
>
> Kind regards
>
> Anton
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Thu May 30 09:42:59 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 30 May 2024 21:42:59 +1200
Subject: [squid-users] Validation of IP address for SSL spliced
 connections
In-Reply-To: <a4b55d47-6122-43f6-aed0-0aa1741dcd28@esat.kuleuven.be>
References: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>
 <eead6ccc-96e9-4441-9200-35bcf37fee73@measurement-factory.com>
 <54178fff-365f-4fa5-b2ec-0b13b829a0ca@esat.kuleuven.be>
 <5aca3feb-490c-4a17-a423-6fb2d4ae6b9e@measurement-factory.com>
 <a4b55d47-6122-43f6-aed0-0aa1741dcd28@esat.kuleuven.be>
Message-ID: <335d2394-1862-457b-9b28-133a39db1a03@treenet.co.nz>

On 30/05/24 18:30, Rik Theys wrote:
> Hi,
> 
> On 5/29/24 11:31 PM, Alex Rousskov wrote:
>> On 2024-05-29 17:06, Rik Theys wrote:
>>> On 5/29/24 5:29 PM, Alex Rousskov wrote:
>>>> On 2024-05-29 05:01, Rik Theys wrote:
>>
>>
>>>>> squid doesn't seem to validate that the IP address we're connecting 
>>>>> to is valid for the specified name in the SNI header?
>>>>
>>>> That observation matches my reading of Squid Host header forgery 
>>>> detection code which says "we do not yet handle CONNECT tunnels 
>>>> well, so ignore for them". To validate that theory, use 
>>>> "debug_options ALL,3" and look for "SECURITY ALERT: Host header 
>>>> forgery detected" messages in cache.log.
>>
>>> I've enabled this debug option, but I never see the security alert in 
>>> the logs. Maybe it was introduced in more recent versions? I'm 
>>> currently using Squid 5.5 that comes with Rocky Linux 9.4.
>>
>> The code logging "SECURITY ALERT: Host header forgery detected" 
>> messages is present in v5.5, but perhaps it is not triggered in that 
>> version (or even in modern/supported Squids) when I expect it to be 
>> triggered. Unfortunately, there are too many variables for me to 
>> predict what exactly went wrong in your particular test case without 
>> doing a lot more work (and I cannot volunteer to do that work right now).
> 
> Looking at https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery, 
> it always seems to mention the Host header. It has no mention of 
> performing the same checks for the SNI value. Since we're peeking at the 
> request, we can't see the actual Host header being sent.
> 

FYI, The SSL-Bump feature uses a CONNECT tunnel at the HTTP layer to 
transfer the HTTPS (or encrypted non-HTTPS) content through Squid. The 
SNI value, cert altSubjectName, or raw-IP (whichever most-trusted is 
available) received from peek/bump gets used as the Host header on that 
internal CONNECT tunnel.

The Host header forgery check at HTTP layer is performed on that 
HTTP-level CONNECT request regardless of whether a specific SNI-vs-IP 
check was done by the TLS logic. Ideally both layers would do it, but 
SSL-Bump permutations/complexity makes that hard.



> And indeed: if I perform the same test for HTTP traffic, I do see the 
> error message:
> 
> curl http://wordpress.org --connect-to wordpress.org:80:8.8.8.8:80
> 
> 
> I believe that for my use-case (only splice certain domains and prevent 
> connecting to a wrong IP address), there's currently no solution then. 
> Squid would also have to perform a similar check as the Host check for 
> the SNI information. Maybe I can perform the same function with an 
> external acl as you've mentioned. I will look into that later. Thanks 
> for your time.


IIRC there is at least one SSL-Bump permutation which does server name 
vs IP validation (in a way, not explicitly). But that particular code 
path is not always taken and the SSL-Bump logic does not go out of its 
way to lookup missing details. So likely you are just not encountering 
the rare case that SNI gets verified.



HTH
Amos


From squid3 at treenet.co.nz  Thu May 30 10:15:27 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 30 May 2024 22:15:27 +1200
Subject: [squid-users] can't explain 403 denied for authenticated user
In-Reply-To: <1201410059.1716631.1716578882350.JavaMail.zimbra@kretz.net>
References: <1201410059.1716631.1716578882350.JavaMail.zimbra@kretz.net>
Message-ID: <96746157-da51-47db-8d52-d65239f2717e@treenet.co.nz>

On 25/05/24 07:28, Kevin wrote:
> Hi,
> 
> We have 2 external ACLs that take a request's data (IP, authenticated 
> username, URL, user-agent, etc) and uses that information to determine 
> whether a user or host should be permitted to access that URL.?? It 
> almost always works well, but we have a recurring occasional issue that 
> I can't figure out.
> 
> When it occurs, it's always around 4AM.?? This particular request occurs 
> often - averages about once a second throughout the day.
> 
> What we see is a "403 forbidden" for a (should be) permitted site from 
> an authenticated user from the same IP/user and to the same site that 
> gets a "202 connection established" every other time.

Is maybe 4am the time when your auth system refreshes all nonce?
  - thus making any currently in-use by the clients invalid until they 
re-auth. You might see a mix of 403/401/407 in a bunch at such times.


Or maybe in a similar style one/some of the clients is broken and fails 
to update its nonce before it expires at 4am?
  - looking at which client agent and IP were getting the 403 and/or the 
nonce which received 403 will give you hints about this possibility.


Or your network router(s) do garbage collection and terminate 
long-running connections to free up TCP resources?
  - thus forcing a lot of client re-connects at 4am, which may:
  a) overload the auth system/helper, or
  b) break a transaction that included nonce update for clients - 
resulting in their next request being invalid nonce.


Or maybe you have log processing software that does "squid -k restart" 
instead of the proper "squid -k rotate" to get access to the log files?

Or maybe your auth system has a limit on how large nonce-count can become?
  - I notice that the working request has 0x2F uses and the forbidden 
has 0x35 (suspiciously close to 50 in decimal)




> 
> The difference I see in the logs:? though all the digest auth info looks 
> okay, the %un field in the log for the usual (successful) request is the 
> authenticated username, while in the failed request, it's "-".?? So 
> though there hasn't been an authentication error or "authentication 
> required" in the log - and the username is in the authentication details 
> in the log entry -? it seems like squid isn't recognizing that username 
> as %un.


Be aware that a properly behaving client will *not* send credentials 
until they are requested, after which it should *always* send 
credentials on that same connection (even if they are not requested 
explicitly).

That means some requests on a multiplex/pipeline/keep-alive connection 
MAY arrive with credentials and be accepted(2xx)/denied(403) without 
authentication having occured. Entirely due to your *_access directives 
sequence. In these cases the log will show auth headers but no value for 
%un and/or %ul.


> 
> My squid.conf first tests a request to see if an unauthenticated request 
> from a particular host is permitted.? That external ACL doesn't take a 
> username as an argument.?? If that external ACL passes, the request is 
> allowed.
> 

Please *show* the config lines rather than describing what you *think* 
they do. Their exact ordering matters *a lot*.

  Obfuscation of sensitive details is okay/expected so long as you makes 
it easy for us to tell that value A and value B are different.


FWIW; if your config file is *actually* containing only what you 
described it is missing a number of things necessary to have a safe and 
secure proxy. A look at your full config (without comments or empty 
lines) will help us point out any unnoticed issues for you to consider 
fixing.


> The next line in squid.conf is
> 
> acl auth_users proxy_auth REQUIRED
> 

FYI the above just means that Squid is using authentication. It says 
nothing about when the authentication will be (or not be) performed.


> ... and after that, the external ACL that takes the username as well as 
> the other info.
> 


HTH
Amos


From rousskov at measurement-factory.com  Thu May 30 15:55:08 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 30 May 2024 11:55:08 -0400
Subject: [squid-users] Validation of IP address for SSL spliced
 connections
In-Reply-To: <a4b55d47-6122-43f6-aed0-0aa1741dcd28@esat.kuleuven.be>
References: <c4cb371a-9aa4-4046-8b81-05a8824b48ea@esat.kuleuven.be>
 <eead6ccc-96e9-4441-9200-35bcf37fee73@measurement-factory.com>
 <54178fff-365f-4fa5-b2ec-0b13b829a0ca@esat.kuleuven.be>
 <5aca3feb-490c-4a17-a423-6fb2d4ae6b9e@measurement-factory.com>
 <a4b55d47-6122-43f6-aed0-0aa1741dcd28@esat.kuleuven.be>
Message-ID: <7bae885f-e7d1-46f0-b5a2-9bed2e410943@measurement-factory.com>

On 2024-05-30 02:30, Rik Theys wrote:
> On 5/29/24 11:31 PM, Alex Rousskov wrote:
>> On 2024-05-29 17:06, Rik Theys wrote:
>>> On 5/29/24 5:29 PM, Alex Rousskov wrote:
>>>> On 2024-05-29 05:01, Rik Theys wrote:
>>>>> squid doesn't seem to validate that the IP address we're connecting 
>>>>> to is valid for the specified name in the SNI header?
>>>>
>>>> That observation matches my reading of Squid Host header forgery 
>>>> detection code which says "we do not yet handle CONNECT tunnels 
>>>> well, so ignore for them". To validate that theory, use 
>>>> "debug_options ALL,3" and look for "SECURITY ALERT: Host header 
>>>> forgery detected" messages in cache.log.
>>
>>> I've enabled this debug option, but I never see the security alert in 
>>> the logs. Maybe it was introduced in more recent versions? I'm 
>>> currently using Squid 5.5 that comes with Rocky Linux 9.4.
>>
>> The code logging "SECURITY ALERT: Host header forgery detected" 
>> messages is present in v5.5, but perhaps it is not triggered in that 
>> version (or even in modern/supported Squids) when I expect it to be 
>> triggered. Unfortunately, there are too many variables for me to 
>> predict what exactly went wrong in your particular test case without 
>> doing a lot more work (and I cannot volunteer to do that work right now).
> 
> Looking at https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery, 
> it always seems to mention the Host header. It has no mention of 
> performing the same checks for the SNI value. Since we're peeking at the 
> request, we can't see the actual Host header being sent.

As Amos has explained, SslBump at step2 is supposed to relay TLS Client 
Hello information via fake CONNECT request headers. SNI should go into 
CONNECT Host header and CONNECT target pseudo-header. That fake CONNECT 
request should then be checked for forgery.

Whether all of the above actually happens is an open question. I bet a 
short answer is "no". I am not just being extra cautious here based on 
overall poor SslBump code quality! I believe there are "real bugs" on 
that code path because we have fixed some of them (and I hope to find 
the time to post a polished version of those fixes for the official 
review in the foreseeable future). For an example that fuels my 
concerns, see the following unofficial commit message:
https://github.com/measurement-factory/squid/commit/462aedcc


> I believe that for my use-case (only splice certain domains and prevent 
> connecting to a wrong IP address), there's currently no solution then.

I suspect that there is currently no solution that does not involve 
writing complex external ACL helpers or complex Squid code fixes.


>>> I guess that explains why if I add "%ssl::<cert_subject" to my 
>>> logformat for the access log, the field is always "-"?
>>
>> It may explain that, but other problems may lead to the same "no 
>> certificate" result as well, of course. You can kind of check by using 
>> stare/bump instead of peek/splice -- if you see certificate details 
>> logged in that bumping test, then it is more likely that Squid just 
>> does not get a plain text certificate in peeking configurations.
> 
> I've updated the configuration to use stare/bump instead. The field is 
> then indeed added to the log file. A curl request that forces the 
> connection to a different IP address then also fails because the 
> certificate isn't valid for the name. There's no mention of the Host 
> header not matching the IP address, but I assume that check comes after 
> the certificate check then.

In most cases, the forgery check should happen before the certificate 
check. I suspect that it does not happen at all in your test case.


HTH,

Alex.



