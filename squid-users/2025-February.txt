From ngtech1ltd at gmail.com  Sat Feb  1 18:43:11 2025
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Sat, 1 Feb 2025 20:43:11 +0200
Subject: [squid-users] 2FA with Google Authenticator and squid login
Message-ID: <01ba01db74d9$25cae220$7160a660$@gmail.com>

Hey,

 

I was wondering if anyone have implemented any 2FA with squid.

IE a simple forward proxy that implements an external ACL helper that allows
a specific user to access from a specific src ip address for a specific
period of time.

For example 1 Hour since login.

The thing is that it can be done using some login portal and 2FA.

 

I wanted to implement this solution and I know it's possible to do with a
Radius server.

There are two options I have seen which I am interested in:

With Google authenticator and it requires a login page.

With some kind of push notification, maybe via email.

 

Any recommendations are welcome.


Thanks,

Eliezer

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250201/0636ca91/attachment.htm>

From uhlar at fantomas.sk  Sat Feb  1 19:31:34 2025
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sat, 1 Feb 2025 20:31:34 +0100
Subject: [squid-users] squid_icap to icap to system_2
In-Reply-To: <322641737455939@mail.yandex.ru>
References: <322641737455939@mail.yandex.ru>
Message-ID: <Z552lia_5eg_OAk2@fantomas.sk>

On 21.01.25 13:41, ???? ??????? wrote:
>   I have a squid proxy, it sends data to the system via icap. I need to
>   install another squid between the proxy and the system so that it receives
>   icap from the proxy, filters the icap by the ip of the external sender
>   (original IP) + packet size (no more than 200 bytes) and also sends
>   already filtered traffic to the system via icap. Please tell me if this is
>   possible, and if so, how to do it.
>   Current version of squid is 6.6
>   ?
>   P.S.
>   It is not possible to filter icap traffic directly on the main proxy due
>   to some restrictions.

the ICAP server does not need to reside on machine squid proxy runs on.
http://www.squid-cache.org/Doc/config/icap_service/

I don't understand your request more deeply so it's quite hard to give more 
thorough answer.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Chernobyl was an Windows 95 beta test site.

From squid3 at treenet.co.nz  Sat Feb  1 23:35:34 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 2 Feb 2025 12:35:34 +1300
Subject: [squid-users] 2FA with Google Authenticator and squid login
In-Reply-To: <01ba01db74d9$25cae220$7160a660$@gmail.com>
References: <01ba01db74d9$25cae220$7160a660$@gmail.com>
Message-ID: <4e7c28b4-c6ec-4ef1-8b1e-5d9227c42e62@treenet.co.nz>

On 2/02/25 07:43, ngtech1ltd wrote:
> Hey,
> 
> I was wondering if anyone have implemented any 2FA with squid.
> 
> IE a simple forward proxy that implements an external ACL helper that 

Ah, that would not be "authentication".


2FA is done through Squid auth_param and authentication helpers same as 
"normal" (1FA) authentication. It is just a slightly different bunch of 
steps the auth system performs in the background outside of Squid.


Cheers
Amos


From ngtech1ltd at gmail.com  Sun Feb  2 11:43:59 2025
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Sun, 2 Feb 2025 13:43:59 +0200
Subject: [squid-users] 2FA with Google Authenticator and squid login
In-Reply-To: <4e7c28b4-c6ec-4ef1-8b1e-5d9227c42e62@treenet.co.nz>
References: <01ba01db74d9$25cae220$7160a660$@gmail.com>
 <4e7c28b4-c6ec-4ef1-8b1e-5d9227c42e62@treenet.co.nz>
Message-ID: <CABA8h=QwGo4ex5H=+UpR-P-EgEQYzo9Kd+hYQ0H33aCWxFPgVA@mail.gmail.com>

What would make  a 2fa in squid case?

Thanks,
Eliezer

?????? ??? ??, 2 ????? 2025, 13:22, ??? Amos Jeffries ?<squid3 at treenet.co.nz
>:

> On 2/02/25 07:43, ngtech1ltd wrote:
> > Hey,
> >
> > I was wondering if anyone have implemented any 2FA with squid.
> >
> > IE a simple forward proxy that implements an external ACL helper that
>
> Ah, that would not be "authentication".
>
>
> 2FA is done through Squid auth_param and authentication helpers same as
> "normal" (1FA) authentication. It is just a slightly different bunch of
> steps the auth system performs in the background outside of Squid.
>
>
> Cheers
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250202/5b202ba0/attachment.htm>

From squid3 at treenet.co.nz  Mon Feb  3 05:10:02 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 3 Feb 2025 18:10:02 +1300
Subject: [squid-users] 2FA with Google Authenticator and squid login
In-Reply-To: <CABA8h=QwGo4ex5H=+UpR-P-EgEQYzo9Kd+hYQ0H33aCWxFPgVA@mail.gmail.com>
References: <01ba01db74d9$25cae220$7160a660$@gmail.com>
 <4e7c28b4-c6ec-4ef1-8b1e-5d9227c42e62@treenet.co.nz>
 <CABA8h=QwGo4ex5H=+UpR-P-EgEQYzo9Kd+hYQ0H33aCWxFPgVA@mail.gmail.com>
Message-ID: <1dc77d00-c20d-46bd-a588-ad472cba32e5@treenet.co.nz>

On 3/02/25 00:43, NgTech LTD wrote:
> What would make? a 2fa in squid case?
> 


When receiving a new login attempt the authentication (auth_param) 
helper should initiate whatever side-channel token delivery is needed. 
Then return "ERR" to Squid as usual.


Replace the login challenge error message with a login page to receive 
that token and deliver it to a server that marks the client as logged 
in. (Both ERR_ACCESS_DENIED and ERR_CACHE_ACCESS_DENIED. Either new 
templates or a deny_info 401/407 - I'm not sure which will work best)


Somewhat like how the SQL_session helper works in "active mode" session, 
but through the auth_param helpers instead of external ACL sessions.


HTH
Amos


> Thanks,
> Eliezer
> 
> ?????? ??? ??, 2 ????? 2025, 13:22, ??? Amos Jeffries 
> ?<squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>:
> 
>     On 2/02/25 07:43, ngtech1ltd wrote:
>      > Hey,
>      >
>      > I was wondering if anyone have implemented any 2FA with squid.
>      >
>      > IE a simple forward proxy that implements an external ACL helper
>     that
> 
>     Ah, that would not be "authentication".
> 
> 
>     2FA is done through Squid auth_param and authentication helpers same as
>     "normal" (1FA) authentication. It is just a slightly different bunch of
>     steps the auth system performs in the background outside of Squid.
> 
> 
>     Cheers
>     Amos
> 
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-
>     cache.org>
>     https://lists.squid-cache.org/listinfo/squid-users <https://
>     lists.squid-cache.org/listinfo/squid-users>
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From ngtech1ltd at gmail.com  Mon Feb  3 05:25:35 2025
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Mon, 3 Feb 2025 07:25:35 +0200
Subject: [squid-users] 2FA with Google Authenticator and squid login
In-Reply-To: <1dc77d00-c20d-46bd-a588-ad472cba32e5@treenet.co.nz>
References: <01ba01db74d9$25cae220$7160a660$@gmail.com>
 <4e7c28b4-c6ec-4ef1-8b1e-5d9227c42e62@treenet.co.nz>
 <CABA8h=QwGo4ex5H=+UpR-P-EgEQYzo9Kd+hYQ0H33aCWxFPgVA@mail.gmail.com>
 <1dc77d00-c20d-46bd-a588-ad472cba32e5@treenet.co.nz>
Message-ID: <CABA8h=S1cHjHzPrt47uHzmYHu86Ynb9ipKYUwccPkXgeE3OcKQ@mail.gmail.com>

What i was talking about is using both the auth helper and the external ack
helper.
The password is static but the authorization itself is done via some push
or another totp method that will authorize the login for a specific amount
of time.
And indeed it will kind of degrade the connection to 1fa for a period of
time, but, it will protect against couple specific attacks.
So, if the proxy connection is encrypted inside a tunnel then it's ok.

As for a directly accessible proxy over plain http, it will be vulnerable
to many auth attacks..

Thanks,
Eliezer

?????? ??? ??, 3 ????? 2025, 7:10, ??? Amos Jeffries ?<squid3 at treenet.co.nz
>:

> On 3/02/25 00:43, NgTech LTD wrote:
> > What would make  a 2fa in squid case?
> >
>
>
> When receiving a new login attempt the authentication (auth_param)
> helper should initiate whatever side-channel token delivery is needed.
> Then return "ERR" to Squid as usual.
>
>
> Replace the login challenge error message with a login page to receive
> that token and deliver it to a server that marks the client as logged
> in. (Both ERR_ACCESS_DENIED and ERR_CACHE_ACCESS_DENIED. Either new
> templates or a deny_info 401/407 - I'm not sure which will work best)
>
>
> Somewhat like how the SQL_session helper works in "active mode" session,
> but through the auth_param helpers instead of external ACL sessions.
>
>
> HTH
> Amos
>
>
> > Thanks,
> > Eliezer
> >
> > ?????? ??? ??, 2 ????? 2025, 13:22, ??? Amos Jeffries
> > ?<squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>:
> >
> >     On 2/02/25 07:43, ngtech1ltd wrote:
> >      > Hey,
> >      >
> >      > I was wondering if anyone have implemented any 2FA with squid.
> >      >
> >      > IE a simple forward proxy that implements an external ACL helper
> >     that
> >
> >     Ah, that would not be "authentication".
> >
> >
> >     2FA is done through Squid auth_param and authentication helpers same
> as
> >     "normal" (1FA) authentication. It is just a slightly different bunch
> of
> >     steps the auth system performs in the background outside of Squid.
> >
> >
> >     Cheers
> >     Amos
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-
> >     cache.org>
> >     https://lists.squid-cache.org/listinfo/squid-users <https://
> >     lists.squid-cache.org/listinfo/squid-users>
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > https://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250203/a4095808/attachment.htm>

From squid3 at treenet.co.nz  Mon Feb  3 07:58:14 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 3 Feb 2025 20:58:14 +1300
Subject: [squid-users] 2FA with Google Authenticator and squid login
In-Reply-To: <CABA8h=S1cHjHzPrt47uHzmYHu86Ynb9ipKYUwccPkXgeE3OcKQ@mail.gmail.com>
References: <01ba01db74d9$25cae220$7160a660$@gmail.com>
 <4e7c28b4-c6ec-4ef1-8b1e-5d9227c42e62@treenet.co.nz>
 <CABA8h=QwGo4ex5H=+UpR-P-EgEQYzo9Kd+hYQ0H33aCWxFPgVA@mail.gmail.com>
 <1dc77d00-c20d-46bd-a588-ad472cba32e5@treenet.co.nz>
 <CABA8h=S1cHjHzPrt47uHzmYHu86Ynb9ipKYUwccPkXgeE3OcKQ@mail.gmail.com>
Message-ID: <0c72c673-15d6-42d3-8d34-7bd1cfa12ebc@treenet.co.nz>

On 3/02/25 18:25, NgTech LTD wrote:
> What i was talking about is using both the auth helper and the external 
> ack helper.


Using an ACL helper is just extra complication that is not needed and 
the "Keep It Simple" (KIS) principle of design is very important for 
security systems.


For "global" access you can authorize OR authenticate. Doing "validate + 
authorize + authorize" is pointless for this use-case.

You only need to add authorization on top of authentication (eg user 
login + group access) if you have some non-global resources/area needing 
special authorization that is not granted by just the login.



At the lowest-level of operations:
  * the auth_param helper performs security action "Validate". The 
http_access rules you use to call it perform security action "Authorize".

  * the external ACL helper performs "nothing"[0] as far as Squid is 
concerned. The http_access rules you use to call it perform security 
action "Authorize".

[0] It could actually be doing anything, but Squid cannot know what. In 
particular it does **not** trigger Squid to apply any HTTP 
authentication-related security requirements on the HTTP request/reply 
handling (where the HTTP headers used by auth_param does trigger those) 
- which can potentially be **extremely** dangerous.



> The password is static but the authorization itself is done via some 
> push or another totp method that will authorize the login for a specific 
> amount of time.


Sure. But you do not need an external ACL for that.

In my earlier suggested design the altered ERR_* page has a HTML form 
for POST'ing the 2FA token somewhere directly from the clients Browser 
to a server. That other service is what grants the "Valid" status to 
complete the 2FA login.


**IF** that POST goes through Squid it should use an unrelated TCP 
connection and/or HTTPS security - so there is no way for Squid or any 
other service than your auth server to know which previous client login 
it applies to.



> And indeed it will kind of degrade the connection to 1fa for a period of 
> time, but, it will protect against couple specific attacks.
> So, if the proxy connection is encrypted inside a tunnel then it's ok.


To be 2FA by definition the entire process has to happen over two 
distinct channels, each being used to pass a different token (a.k.a. 
"factor").

case 1: client does not send any user+pass at all:

  channel 1: client -> Squid : (no login)
	  : Squid->client   : 401 login required

  channel 2: auth server -> email : token

  channel 1: client -> Squid : POST username + pass + token
	  : Squid->client   : 200 login confirmed,



case 2: client sends login details, but no 2FA yet:

  channel 1: client -> Squid : HTTP username + pass
	  : Squid->client   : 401 login required

  channel 2: auth server -> email : token

  channel 1: client -> Squid : POST username + pass + token
	  : Squid->client   : 200 login confirmed,


NB: in both cases you could do a 307 redirect back to the original 
requested URL if it is known at that late stage.



> 
> As for a directly accessible proxy over plain http, it will be 
> vulnerable to many auth attacks..

This is not relevant. Any login system faces the same risks of attack 
floods.And the "plain HTTP" is not required. It is only part of this 
discussion because Squid is an HTTP proxy. Thus messages are interpreted 
by Squid as HTTP regardless if they were received as "plain" or HTTPS.


HTH
Amos


From tpal at numen.mg  Mon Feb  3 14:07:46 2025
From: tpal at numen.mg (Thomas PALFRAY)
Date: Mon, 3 Feb 2025 14:07:46 +0000
Subject: [squid-users] Squid 6 with ssl-bump doesn't cache binary content
 over 100 kb
Message-ID: <69d416c9ca9e4355b97e3856cd41ad15@numen.mg>

Hello everyone,



My team and I are working on setting up a squid with ssl-bump to cache binary content (jpeg, png, pdf and json) on a remote site over HTTPS.

The size of the binary content can vary from a few dozen KB to several hundred MB.



We had a working HTTP configuration under squid 3.14, but for security reasons, all our links must now go through HTTPS.



We've tried configuring Squid 5 and Squid 6, but the behavior described below is the same for both versions of the tool.



In fact, we're seeing 200/TCP_MISS_ABORTED codes for content larger than around 100kb.

When content sizes are smaller, the expected behaviour occurs and data is returned from the cache.



On the client side, for content larger than 100kb :

  *   squid 5 returns x-cache = "MISS" and x-cache-lookup = "HIT".
  *   squid 6 returns cache-status = "url;detail=match", which is equivalent if my understanding is correct.



We first thought it might be linked to the following bug: https://bugs.squid-cache.org/show_bug.cgi?id=5214, which encouraged us to try version 6, but without success.



  *   Is it a configuration problem that we missed?
  *   Can you help us ?



HTTP client-side headers returned by squid 6 :



[2025-01-14T08:46:49.875] [TRACE] default - [0/1] getContentStream (user) header: {

  "date": "Tue, 14 Jan 2025 05:47:30 GMT",

  "server": "Apache-Chemistry-OpenCMIS/1.2.0_1859862-XXXXX-1",

  "strict-transport-security": "max-age=15768000",

  "x-xss-protection": "1; mode=block",

  "x-frame-options": "SAMEORIGIN",

  "x-content-type-options": "nosniff",

  "access-control-allow-origin": "*",

  "access-control-expose-headers": "Content-Disposition",

  "cache-control": "public, s-maxage=3600, must-revalidate",

  "etag": "\"08bd240128b475722db82d36c7ae7f164c37cab4ad2480abae052875fe7bc3bfdfef9996197d40110a13208d39a3db3a789879bc31803c82f25211eeba505455\"",

  "content-disposition": "inline; filename=FILENAME.jpg",

  "content-type": "image/jpeg",

  "content-length": "2069587",

  "content-security-policy": "default-src 'none'; connect-src 'self'; font-src 'self' fonts.gstatic.com; img-src blob: 'self'; script-src 'self' 'unsafe-eval' 'unsafe-inline'; style-src 'self' 'unsafe-inline' fonts.googleapis.com",

  "cache-status": "sv-infra-pxy4;detail=match",

  "via": "1.1 sv-infra-pxy4 (squid/6.10)",

  "connection": "close"

}

[2025-01-14T08:46:49.875] [INFO] default - [0/1][2] getCS oId:'369926' sId:'80669' name:' filename= FILENAME.jpg' type:'image/jpeg' size:'2021.08ko' res:[via:true hit:false length:true]





squid 6 acces.log extract:



[cid:image001.png at 01DB765E.24C1B6C0]



full server configuration file :



acl localnet src 0.0.0.1-0.255.255.255        # RFC 1122 "this" network (LAN)

acl localnet src 10.0.0.0/8                   # RFC 1918 local private network (LAN)

acl localnet src 100.64.0.0/10                           # RFC 6598 shared address space (CGN)

acl localnet src 169.254.0.0/16        # RFC 3927 link-local (directly plugged) machines

acl localnet src 172.16.0.0/12                           # RFC 1918 local private network (LAN)

acl localnet src 192.168.0.0/16                        # RFC 1918 local private network (LAN)

acl localnet src fc00::/7         # RFC 4193 local private network range

acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines



acl SSL_ports port 443

acl Safe_ports port 80                              # http

acl Safe_ports port 21                              # ftp

acl Safe_ports port 443                           # https

acl Safe_ports port 70                              # gopher

acl Safe_ports port 210                           # wais

acl Safe_ports port 1025-65535       # unregistered ports

acl Safe_ports port 280                           # http-mgmt

acl Safe_ports port 488                           # gss-http

acl Safe_ports port 591                           # filemaker

acl Safe_ports port 777                           # multiling http



#ACL pour SmartGED

acl smartged-mime req_mime_type -i ^image/jpeg$

acl smartged-mime req_mime_type -i ^image/png$

acl smartged-mime req_mime_type -i ^application/pdf$

acl smartged-mime req_mime_type -i ^application/json$



acl intermediate_fetching transaction_initiator certificate-fetching



http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports



# Only allow cachemgr access from localhost

http_access allow localhost manager

http_access deny manager

http_access allow localnet

http_access deny all



logformat toto %{%d/%b/%Y:%H:%M:%S}tl.%tu %>a %rm %03Hs/%Ss %6tr %ru %mt



access_log /var/log/squid/access.log toto



http_port 3128  ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB tls-cert=/etc/squid/ssl_cert/xxxx_.pem tls-key=/etc/squid/ssl_cert/xxxx_.key tls-dh=/etc/squid/ssl_cert/dhparam.pem

tls_outgoing_options cipher=ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384

sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/spool/squid/ssl_db -M 20MB

sslcrtd_children 5

ssl_bump server-first all

ssl_bump splice all

sslproxy_cert_error allow all



# ACL deny pour les fichiers javascript

acl denyjs urlpath_regex \.js

# ok deny all requests above

cache deny denyjs



# Leave coredumps in the first cache dir

coredump_dir /cache1/squid



# Affichage des requetes GET completes dans cache.log

strip_query_terms off



cache_mem 20480 MB

# d?but d'?viction du cache

cache_swap_low 50

# aggressivit? maximal de l'algorithme d'?viction du cache

cache_swap_high 80

# The LRU policies keeps recently referenced objects.

cache_replacement_policy lru



#

# Add any of your own refresh_pattern entries above these.

#

refresh_pattern ^ftp:                1440    20%     10080

refresh_pattern -i (/cgi-bin/|\?) 0       0%        0

refresh_pattern .                          0             20%     4320



ftp_user anonymous at xxx.fr<mailto:anonymous at xxx.fr>

#acl QUERY urlpath_regex cgi-bin \?

#no_cache deny QUERY

client_request_buffer_max_size 10240 KB

maximum_object_size 1024 MB

# to keep object in memory cache

maximum_object_size_in_memory 10240 KB

#to cause Squid to prefetch the whole file

range_offset_limit 16 MB

#quick_abort_min -1

#D?finition de la taille maximum d'un en-t?te HTTP lors d'une requ?te

reply_header_max_size 8192 KB

#taille maximum d'un en-t?te de r?ponse HTTP

reply_header_max_size 8192 KB



# Uncomment and adjust the following to add a disk cache directory.

cache_dir aufs /cache1/squid 1024000 16 256 max-size=16777216





error_directory /usr/share/squid/errors/fr

half_closed_clients off

max_filedescriptors 8192

forward_max_tries 50



#Affichage du store-id

cache_store_log daemon:/var/log/squid/store_daemon.log

cache_store_log stdio:/var/log/squid/store_stdio.log

#debug_options "ALL,3 33,7 47,7 61,7 85,7"

# Log all critical and important messages.

#debug_options ALL,1

debug_options ALL,3



# Enable SQUID's SNMP

snmp_port 3401

acl snmppublic snmp_community PASdePUBLIC

snmp_access allow snmppublic all

Best regards,

Thomas PALFRAY
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250203/5ebdda56/attachment-0001.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 43281 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250203/5ebdda56/attachment-0001.png>

From rousskov at measurement-factory.com  Mon Feb  3 16:29:30 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 3 Feb 2025 11:29:30 -0500
Subject: [squid-users] Squid 6 with ssl-bump doesn't cache binary
 content over 100 kb
In-Reply-To: <69d416c9ca9e4355b97e3856cd41ad15@numen.mg>
References: <69d416c9ca9e4355b97e3856cd41ad15@numen.mg>
Message-ID: <52908eff-6716-4bee-bb62-7b55e88a1092@measurement-factory.com>

On 2025-02-03 09:07, Thomas PALFRAY wrote:

> My team and I are working on setting up *a squid with ssl-bump* to cache 
> binary content (jpeg, png, pdf and json) on a remote site over HTTPS.
> 
> The size of the binary content can vary from a few dozen KB to several 
> hundred MB.
> 
> We had a working HTTP configuration under squid 3.14, but for security 
> reasons, all our links must now go through HTTPS.
> 
> We've tried configuring Squid 5 and Squid 6, but the behavior described 
> below is the same for both versions of the tool.
> 
> In fact, we're seeing 200/TCP_MISS_ABORTED codes for content larger than 
> around 100kb.

There is not enough information to be sure, but:

* If your client sends large requests, then this could be Bug 5405 fixed 
in v6.13.

* Otherwise, it could be Bug 5352 (also fixed in v6.13), even though the 
known manifestation of that bug is related to ICAP content inspection 
that your Squid does not use.


If you have not tested v6.13, please do.


HTH,

Alex.



> When content sizes are smaller, the expected behaviour occurs and data 
> is returned from the cache.
> 
> On the client side, for content larger than 100kb :
> 
>   * squid 5 returns x-cache = ?MISS? and x-cache-lookup = ?HIT?.
>   * squid 6 returns cache-status = ?url;detail=match?, which is
>     equivalent if my understanding is correct.
> 
> We first thought it might be linked to the following bug: 
> _https://bugs.squid-cache.org/show_bug.cgi?id=5214 
> <https://bugs.squid-cache.org/show_bug.cgi?id=5214>_, which encouraged 
> us to try version 6, but without success.
> 
>   * Is it a configuration problem that we missed?
>   * Can you help us ?
> 
> HTTP client-side headers returned by squid 6 :
> 
> //
> 
> /[2025-01-14T08:46:49.875] [TRACE] default - [0/1] getContentStream 
> (user) header: {/
> 
> /? "date": "Tue, 14 Jan 2025 05:47:30 GMT",/
> 
> /? "server": "Apache-Chemistry-OpenCMIS/1.2.0_1859862-XXXXX-1",/
> 
> /? "strict-transport-security": "max-age=15768000",/
> 
> /"x-xss-protection": "1; mode=block",/
> 
> ///"x-frame-options": "SAMEORIGIN",/
> 
> /? "x-content-type-options": "nosniff",/
> 
> /? "access-control-allow-origin": "*",/
> 
> /? "access-control-expose-headers": "Content-Disposition",/
> 
> /? "cache-control": "public, s-maxage=3600, must-revalidate",/
> 
> /? "etag": 
> "\"08bd240128b475722db82d36c7ae7f164c37cab4ad2480abae052875fe7bc3bfdfef9996197d40110a13208d39a3db3a789879bc31803c82f25211eeba505455\"",/
> 
> /? "content-disposition": "inline; filename=FILENAME.jpg",/
> 
> /? "content-type": "image/jpeg",/
> 
> /? "content-length": "2069587",/
> 
> /? "content-security-policy": "default-src 'none'; connect-src 'self'; 
> font-src 'self' fonts.gstatic.com; img-src blob: 'self'; script-src 
> 'self' 'unsafe-eval' 'unsafe-inline'; style-src 'self' 'unsafe-inline' 
> fonts.googleapis.com",/
> 
> */? "cache-status": "sv-infra-pxy4;detail=match",/*
> 
> */"via": "1.1 sv-infra-pxy4 (squid/6.10)",/*
> 
> ///"connection": "close"/
> 
> /}/
> 
> /[2025-01-14T08:46:49.875] [INFO] default - [0/1][2] getCS oId:'369926' 
> sId:*'80669'*name:' filename= FILENAME.jpg' type:'image/jpeg' 
> size:*'2021.08ko'*res:[via:true hit:false length:true]/
> 
> //
> 
> //
> 
> squid 6 acces.log extract:
> 
> //
> 
> //
> 
> //
> 
> full server configuration file :
> 
> //
> 
> /acl localnet src 0.0.0.1-0.255.255.255??????? # RFC 1122 "this" network 
> (LAN)/
> 
> /acl localnet src 10.0.0.0/8?????????????????? # RFC 1918 local private 
> network (LAN)/
> 
> /acl localnet src 100.64.0.0/10?????????????????????????? # RFC 6598 
> shared address space (CGN)/
> 
> /acl localnet src 169.254.0.0/16 ?????? # RFC 3927 link-local (directly 
> plugged) machines/
> 
> /acl localnet src 172.16.0.0/12?????????????????????????? # RFC 1918 
> local private network (LAN)/
> 
> /acl localnet src 192.168.0.0/16??????????????????????? # RFC 1918 local 
> private network (LAN)/
> 
> /acl localnet src fc00::/7?????? ? # RFC 4193 local private network range/
> 
> /acl localnet src fe80::/10????? # RFC 4291 link-local (directly 
> plugged) machines/
> 
> //
> 
> /acl SSL_ports port 443/
> 
> /acl Safe_ports port 80????????????????????????????? # http/
> 
> /acl Safe_ports port 21????????????????????????????? # ftp/
> 
> /acl Safe_ports port 443?????????????????????????? # https/
> 
> /acl Safe_ports port 70????????????????????????????? # gopher/
> 
> /acl Safe_ports port 210?????????????????????????? # wais/
> 
> /acl Safe_ports port 1025-65535?????? # unregistered ports/
> 
> /acl Safe_ports port 280?????????????????????????? # http-mgmt/
> 
> /acl Safe_ports port 488?????????????????????????? # gss-http/
> 
> /acl Safe_ports port 591?????????????????????????? # filemaker/
> 
> /acl Safe_ports port 777?????????????????????????? # multiling http/
> 
> //
> 
> /#ACL pour SmartGED/
> 
> /acl smartged-mime req_mime_type -i ^image/jpeg$/
> 
> /acl smartged-mime req_mime_type -i ^image/png$/
> 
> /acl smartged-mime req_mime_type -i ^application/pdf$/
> 
> /acl smartged-mime req_mime_type -i ^application/json$/
> 
> //
> 
> /acl intermediate_fetching transaction_initiator certificate-fetching/
> 
> //
> 
> /http_access deny !Safe_ports/
> 
> /http_access deny CONNECT !SSL_ports/
> 
> //
> 
> /# Only allow cachemgr access from localhost/
> 
> /http_access allow localhost manager/
> 
> /http_access deny manager/
> 
> /http_access allow localnet/
> 
> /http_access deny all/
> 
> //
> 
> /logformat toto %{%d/%b/%Y:%H:%M:%S}tl.%tu %>a %rm %03Hs/%Ss %6tr %ru %mt/
> 
> //
> 
> /access_log /var/log/squid/access.log toto/
> 
> //
> 
> /http_port 3128? ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=4MB tls-cert=/etc/squid/ssl_cert/xxxx_.pem 
> tls-key=/etc/squid/ssl_cert/xxxx_.key 
> tls-dh=/etc/squid/ssl_cert/dhparam.pem/
> 
> /tls_outgoing_options 
> cipher=ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384/
> 
> /sslcrtd_program /usr/lib/squid/security_file_certgen -s 
> /var/spool/squid/ssl_db -M 20MB/
> 
> /sslcrtd_children 5/
> 
> /ssl_bump server-first all/
> 
> /ssl_bump splice all/
> 
> /sslproxy_cert_error allow all/
> 
> //
> 
> /# ACL deny pour les fichiers javascript/
> 
> /acl denyjs urlpath_regex \.js/
> 
> /# ok deny all requests above/
> 
> /cache deny denyjs/
> 
> //
> 
> /# Leave coredumps in the first cache dir/
> 
> /coredump_dir /cache1/squid/
> 
> //
> 
> /# Affichage des requetes GET completes dans cache.log/
> 
> /strip_query_terms off/
> 
> //
> 
> /cache_mem 20480 MB/
> 
> /# d?but d'?viction du cache/
> 
> /cache_swap_low 50/
> 
> /# aggressivit? maximal de l'algorithme d'?viction du cache/
> 
> /cache_swap_high 80/
> 
> /# The LRU policies keeps recently referenced objects./
> 
> /cache_replacement_policy lru/
> 
> //
> 
> /#/
> 
> /# Add any of your own refresh_pattern entries above these./
> 
> /#/
> 
> /refresh_pattern ^ftp:??????????????? 1440??? 20%???? 10080/
> 
> /refresh_pattern -i (/cgi-bin/|\?) 0?????? 0%??????? 0/
> 
> /refresh_pattern .????????????????????????? 0???????????? 20%???? 4320/
> 
> //
> 
> /ftp_user _anonymous at xxx.fr <mailto:anonymous at xxx.fr>_/
> 
> /#acl QUERY urlpath_regex cgi-bin \?/
> 
> /#no_cache deny QUERY/
> 
> /client_request_buffer_max_size 10240 KB/
> 
> /maximum_object_size 1024 MB/
> 
> /# to keep object in memory cache/
> 
> /maximum_object_size_in_memory 10240 KB/
> 
> /#to cause Squid to prefetch the whole file/
> 
> /range_offset_limit 16 MB/
> 
> /#quick_abort_min -1/
> 
> /#D?finition de la taille maximum d'un en-t?te HTTP lors d'une requ?te/
> 
> /reply_header_max_size 8192 KB/
> 
> /#taille maximum d'un en-t?te de r?ponse HTTP/
> 
> /reply_header_max_size 8192 KB/
> 
> //
> 
> /# Uncomment and adjust the following to add a disk cache directory./
> 
> /cache_dir aufs /cache1/squid 1024000 16 256 max-size=16777216/
> 
> //
> 
> //
> 
> /error_directory /usr/share/squid/errors/fr/
> 
> /half_closed_clients off/
> 
> /max_filedescriptors 8192/
> 
> /forward_max_tries 50/
> 
> //
> 
> /#Affichage du store-id/
> 
> /cache_store_log daemon:/var/log/squid/store_daemon.log/
> 
> /cache_store_log stdio:/var/log/squid/store_stdio.log/
> 
> /#debug_options "ALL,3 33,7 47,7 61,7 85,7"/
> 
> /# Log all critical and important messages./
> 
> /#debug_options ALL,1/
> 
> /debug_options ALL,3/
> 
> //
> 
> /# Enable SQUID's SNMP/
> 
> /snmp_port 3401/
> 
> /acl snmppublic snmp_community PASdePUBLIC/
> 
> /snmp_access allow snmppublic all/
> 
> Best regards,
> 
> *Thomas PALFRAY*
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From Foxy_Lady_1966 at proton.me  Mon Feb  3 20:53:21 2025
From: Foxy_Lady_1966 at proton.me (Foxy Lady)
Date: Mon, 03 Feb 2025 20:53:21 +0000
Subject: [squid-users] Can SQUID change the destination address from ip to
 hostname?
Message-ID: <Q-udBue9AKhsUS1ILBn_upSHKBZHxO-o4l5tbAdn4fduyZsxoRCIcrAk6VmYsG0Qwd9nkC0QKZtjGLzaXpkWM0g_TCalzQTVRDFBwhzA5GY=@proton.me>

Hi all.
As in subject.
SQUID server has its own dns resolver.

Can SQUID change the destination address from ip to hostname?

CLIENT > SQUID > DESTINATION
192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.8.59

CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
192.168.178.50 TCP_TUNNEL/200 4126 CONNECT 104.26.9.59:443 - HIER_DIRECT/104.26.9.59

I would need,

CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.8.59

Thanks.

Inviato con l'email sicura [Proton Mail](https://proton.me/mail/home).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250203/38630ab6/attachment.htm>

From Foxy_Lady_1966 at proton.me  Mon Feb  3 21:22:34 2025
From: Foxy_Lady_1966 at proton.me (Foxy Lady)
Date: Mon, 03 Feb 2025 21:22:34 +0000
Subject: [squid-users] Can SQUID change the destination address from ip to
 hostname?
Message-ID: <gdWMCMhkSGetpDGFe7UP6fWI3Wv2EfEd971H4ZIfTammLBHpPDbSWZtV7V2cQy47oMyGnb6QuQ0oTvP8NRU9kpbbjBxS5XT01BNxzQT2X8w=@proton.me>

Sorry, resend the post in txt and correct some parts.
The question is: can i force SQUID to do a reverse dns lookup and maintain the Host Header inside (where's a ptr record is found), also if i can't find a ptr record? SOCKS5 works with 1st level tcp, so send ip addresses, i need some tool, or Squid workaround, which can force a reverse dns. I know, it's quite impossible if a ptr record is not found in dnses, but... i try..


----------


Hi all.
As in subject.
SQUID server has its own dns resolver.

Can SQUID change the destination address from ip to hostname?

CLIENT > SQUID > DESTINATION
192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.8.59

CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
192.168.178.50 TCP_TUNNEL/200 4126 CONNECT 104.26.9.59:443 - HIER_DIRECT/104.26.9.59

I would need,

CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
192.168.178.50 TCP_TUNNEL/200 4126 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.9.59

Thanks.


Inviato con l'email sicura Proton Mail.

From Foxy_Lady_1966 at proton.me  Tue Feb  4 05:17:04 2025
From: Foxy_Lady_1966 at proton.me (Foxy Lady)
Date: Tue, 04 Feb 2025 05:17:04 +0000
Subject: [squid-users] Can SQUID change the destination address from ip
 to hostname?
In-Reply-To: <gdWMCMhkSGetpDGFe7UP6fWI3Wv2EfEd971H4ZIfTammLBHpPDbSWZtV7V2cQy47oMyGnb6QuQ0oTvP8NRU9kpbbjBxS5XT01BNxzQT2X8w=@proton.me>
References: <gdWMCMhkSGetpDGFe7UP6fWI3Wv2EfEd971H4ZIfTammLBHpPDbSWZtV7V2cQy47oMyGnb6QuQ0oTvP8NRU9kpbbjBxS5XT01BNxzQT2X8w=@proton.me>
Message-ID: <_2XBjR7SBKSovKsKJ084MwVAXLNRgEIWw9wwrFujElNFkyS7juw0zxIiLO24jm8tT5FwrM4tB1pP-wYsN92DMBNshC-eHVJURIk_E4nAInU=@proton.me>

Hi again.
I finally found a tool (great tool, "GO Simple Tunnel") which can serves both HTTP(S)/SOCKS5 Proxy with dns resolution, so chaining it in the middle of Squid, Squid receives the destination in format of "domain.fqdn" and not ip "x.x.x.x",

TCP_TUNNEL/200 4118 CONNECT api.myip.com:443 username HIER_DIRECT/104.26.9.59 - "Go-http-client/1.1" [User-Agent: Go-http-client/1.1\r\nProxy-Authorization: Basic bWFyY286dHIwdHQwbGE=\r\nProxy-Connection: keep-alive\r\nHost: api.myip.com:443\r\n] [HTTP/1.1 200 Connection established\r\n\r\n]

???


Inviato con l'email sicura Proton Mail.

luned? 3 febbraio 2025 22:22, Foxy Lady <Foxy_Lady_1966 at proton.me> ha scritto:

> Sorry, resend the post in txt and correct some parts.
> The question is: can i force SQUID to do a reverse dns lookup and maintain the Host Header inside (where's a ptr record is found), also if i can't find a ptr record? SOCKS5 works with 1st level tcp, so send ip addresses, i need some tool, or Squid workaround, which can force a reverse dns. I know, it's quite impossible if a ptr record is not found in dnses, but... i try..
> 
> 
> ----------
> 
> 
> Hi all.
> As in subject.
> SQUID server has its own dns resolver.
> 
> Can SQUID change the destination address from ip to hostname?
> 
> CLIENT > SQUID > DESTINATION
> 
> 192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.8.59
> 
> CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> 
> 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT 104.26.9.59:443 - HIER_DIRECT/104.26.9.59
> 
> I would need,
> 
> CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> 
> 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.9.59
> 
> Thanks.
> 
> 
> Inviato con l'email sicura Proton Mail.

From luhliari at redhat.com  Tue Feb  4 17:29:21 2025
From: luhliari at redhat.com (Lubos Uhliarik)
Date: Tue, 4 Feb 2025 18:29:21 +0100
Subject: [squid-users] Squid 6.13 source files download
Message-ID: <CAMJdYBzn-MeGy9WWvyGpqjJmgQRx+1sUfEVkxW1aUzq=j24BXQ@mail.gmail.com>

Hello Squid users,

I wanted to ask if it is still possible to download source files and
their signatures using the previously used URLs (e.g.,
http://www.squid-cache.org/Versions/v6/squid-6.12.tar.xz), or are
these URLs no longer supported?

For Squid 6.13, I am unable to access the files through the following URLs:

http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz
http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz.asc

Neither of them seems to be working.

Regards,

-- 
Lubo? Uhliarik


From stu at spacehopper.org  Tue Feb  4 19:55:35 2025
From: stu at spacehopper.org (Stuart Henderson)
Date: Tue, 4 Feb 2025 19:55:35 -0000 (UTC)
Subject: [squid-users] Squid 6.13 source files download
References: <CAMJdYBzn-MeGy9WWvyGpqjJmgQRx+1sUfEVkxW1aUzq=j24BXQ@mail.gmail.com>
Message-ID: <slrnvq4s5n.1sb4.stu.lists@naiad.spacehopper.org>

On 2025-02-04, Lubos Uhliarik <luhliari at redhat.com> wrote:
> Hello Squid users,
>
> I wanted to ask if it is still possible to download source files and
> their signatures using the previously used URLs (e.g.,
> http://www.squid-cache.org/Versions/v6/squid-6.12.tar.xz), or are
> these URLs no longer supported?
>
> For Squid 6.13, I am unable to access the files through the following URLs:
>
> http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz
> http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz.asc
>
> Neither of them seems to be working.

Right. See this in the release announcement:

| Further details, release notes, and source archives can be found at
| https://github.com/squid-cache/squid/releases/tag/SQUID_6_13
| (look for the "Bootstrapped sources" links there).
| As a reminder, we no longer directly distribute our releases
| over FTP, rsync, or through mirrors.

And this where the change was announced:

https://lists.squid-cache.org/pipermail/squid-users/2025-January/027357.html



From gkinkie at gmail.com  Tue Feb  4 20:19:32 2025
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Tue, 4 Feb 2025 20:19:32 +0000
Subject: [squid-users] Squid 6.13 source files download
In-Reply-To: <CAMJdYBzn-MeGy9WWvyGpqjJmgQRx+1sUfEVkxW1aUzq=j24BXQ@mail.gmail.com>
References: <CAMJdYBzn-MeGy9WWvyGpqjJmgQRx+1sUfEVkxW1aUzq=j24BXQ@mail.gmail.com>
Message-ID: <CA+Y8hcMNHW6Qgo9qU=9KsY6gi6yYgDr37UVwJRYi9QQwmBT--A@mail.gmail.com>

Hi Lubos,
  I confirm that the old URLs have been retired and longer work.
If you need a direct download, the working link is:

https://github.com/squid-cache/squid/releases/download/SQUID_<version
number with dots replaced by underscores>/squid-<version number>.tar.xz

e.g.
https://github.com/squid-cache/squid/releases/download/SQUID_6_13/squid-6.13.tar.xz


Francesco


On Tue, 4 Feb 2025 at 5:29?pm, Lubos Uhliarik <luhliari at redhat.com> wrote:

> Hello Squid users,
>
> I wanted to ask if it is still possible to download source files and
> their signatures using the previously used URLs (e.g.,
> http://www.squid-cache.org/Versions/v6/squid-6.12.tar.xz), or are
> these URLs no longer supported?
>
> For Squid 6.13, I am unable to access the files through the following URLs:
>
> http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz
> http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz.asc
>
> Neither of them seems to be working.
>
> Regards,
>
> --
> Lubo? Uhliarik
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250204/d419cd86/attachment.htm>

From Foxy_Lady_1966 at proton.me  Tue Feb  4 21:22:56 2025
From: Foxy_Lady_1966 at proton.me (Foxy Lady)
Date: Tue, 04 Feb 2025 21:22:56 +0000
Subject: [squid-users] Can SQUID change the destination address from ip
 to hostname?
In-Reply-To: <_2XBjR7SBKSovKsKJ084MwVAXLNRgEIWw9wwrFujElNFkyS7juw0zxIiLO24jm8tT5FwrM4tB1pP-wYsN92DMBNshC-eHVJURIk_E4nAInU=@proton.me>
References: <gdWMCMhkSGetpDGFe7UP6fWI3Wv2EfEd971H4ZIfTammLBHpPDbSWZtV7V2cQy47oMyGnb6QuQ0oTvP8NRU9kpbbjBxS5XT01BNxzQT2X8w=@proton.me>
 <_2XBjR7SBKSovKsKJ084MwVAXLNRgEIWw9wwrFujElNFkyS7juw0zxIiLO24jm8tT5FwrM4tB1pP-wYsN92DMBNshC-eHVJURIk_E4nAInU=@proton.me>
Message-ID: <Q89xQ-jf65_S5VwIFStJolA25WA_aN7CA1DuZ0zSt1QEJZ8ER2iC8DIT-bRPPa01MAO4_oTE1UFJ823nD4D9mcWlMGStK6FFlVzcAvIez9c=@proton.me>

I try again asking the ML if

- can Squid change the destination address of a call?

I mean, something like

<url_rewrite_command> $destination $Host

original $destination is 104.26.9.59:443
$Host is the original HTTP Header "Host: xxxxx" alias "api.myip.com:443"

So, a call to
https://104.26.9.59:443/test
will become
https://api.myip.com:443/test

Thanks.

Inviato con l'email sicura Proton Mail.

marted? 4 febbraio 2025 06:17, Foxy Lady <Foxy_Lady_1966 at proton.me> ha scritto:

> Hi again.
> I finally found a tool (great tool, "GO Simple Tunnel") which can serves both HTTP(S)/SOCKS5 Proxy with dns resolution, so chaining it in the middle of Squid, Squid receives the destination in format of "domain.fqdn" and not ip "x.x.x.x",
> 
> TCP_TUNNEL/200 4118 CONNECT api.myip.com:443 username HIER_DIRECT/104.26.9.59 - "Go-http-client/1.1" [User-Agent: Go-http-client/1.1\r\nProxy-Authorization: Basic bWFyY286dHIwdHQwbGE=\r\nProxy-Connection: keep-alive\r\nHost: api.myip.com:443\r\n] [HTTP/1.1 200 Connection established\r\n\r\n]
> 
> ???
> 
> 
> Inviato con l'email sicura Proton Mail.
> 
> 
> luned? 3 febbraio 2025 22:22, Foxy Lady Foxy_Lady_1966 at proton.me ha scritto:
> 
> > Sorry, resend the post in txt and correct some parts.
> > The question is: can i force SQUID to do a reverse dns lookup and maintain the Host Header inside (where's a ptr record is found), also if i can't find a ptr record? SOCKS5 works with 1st level tcp, so send ip addresses, i need some tool, or Squid workaround, which can force a reverse dns. I know, it's quite impossible if a ptr record is not found in dnses, but... i try..
> > 
> > ----------
> > 
> > Hi all.
> > As in subject.
> > SQUID server has its own dns resolver.
> > 
> > Can SQUID change the destination address from ip to hostname?
> > 
> > CLIENT > SQUID > DESTINATION
> > 
> > 192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.8.59
> > 
> > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> > 
> > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT 104.26.9.59:443 - HIER_DIRECT/104.26.9.59
> > 
> > I would need,
> > 
> > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> > 
> > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.9.59
> > 
> > Thanks.
> > 
> > Inviato con l'email sicura Proton Mail.

From uhlar at fantomas.sk  Wed Feb  5 10:01:08 2025
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 5 Feb 2025 11:01:08 +0100
Subject: [squid-users] Can SQUID change the destination address from ip
 to hostname?
In-Reply-To: <Q89xQ-jf65_S5VwIFStJolA25WA_aN7CA1DuZ0zSt1QEJZ8ER2iC8DIT-bRPPa01MAO4_oTE1UFJ823nD4D9mcWlMGStK6FFlVzcAvIez9c=@proton.me>
References: <gdWMCMhkSGetpDGFe7UP6fWI3Wv2EfEd971H4ZIfTammLBHpPDbSWZtV7V2cQy47oMyGnb6QuQ0oTvP8NRU9kpbbjBxS5XT01BNxzQT2X8w=@proton.me>
 <_2XBjR7SBKSovKsKJ084MwVAXLNRgEIWw9wwrFujElNFkyS7juw0zxIiLO24jm8tT5FwrM4tB1pP-wYsN92DMBNshC-eHVJURIk_E4nAInU=@proton.me>
 <Q89xQ-jf65_S5VwIFStJolA25WA_aN7CA1DuZ0zSt1QEJZ8ER2iC8DIT-bRPPa01MAO4_oTE1UFJ823nD4D9mcWlMGStK6FFlVzcAvIez9c=@proton.me>
Message-ID: <Z6M25JBHFBK0Sek2@fantomas.sk>

On 04.02.25 21:22, Foxy Lady wrote:
>I try again asking the ML if
>
>- can Squid change the destination address of a call?
>
>I mean, something like
>
><url_rewrite_command> $destination $Host
>
>original $destination is 104.26.9.59:443
>$Host is the original HTTP Header "Host: xxxxx" alias "api.myip.com:443"
>
>So, a call to
>https://104.26.9.59:443/test
>will become
>https://api.myip.com:443/test

Hello,

I guess that the URL redirector could do that.
http://www.squid-cache.org/Doc/config/url_rewrite_program/

Note that it's extremely unreliable, because IP=>hostname mapping is a wild 
guess, because after client asks for IP address, you don't really know what 
hostname they want. 
So my recommendation is: don't do that.

Note that SOCKS5 protocol supports DNS resolution at server level

>marted? 4 febbraio 2025 06:17, Foxy Lady <Foxy_Lady_1966 at proton.me> ha scritto:
>
>> Hi again.
>> I finally found a tool (great tool, "GO Simple Tunnel") which can serves both HTTP(S)/SOCKS5 Proxy with dns resolution, so chaining it in the middle of Squid, Squid receives the destination in format of "domain.fqdn" and not ip "x.x.x.x",
>>
>> TCP_TUNNEL/200 4118 CONNECT api.myip.com:443 username HIER_DIRECT/104.26.9.59 - "Go-http-client/1.1" [User-Agent: Go-http-client/1.1\r\nProxy-Authorization: Basic bWFyY286dHIwdHQwbGE=\r\nProxy-Connection: keep-alive\r\nHost: api.myip.com:443\r\n] [HTTP/1.1 200 Connection established\r\n\r\n]
>>
>> ???
>>
>>
>> Inviato con l'email sicura Proton Mail.
>>
>>
>> luned? 3 febbraio 2025 22:22, Foxy Lady Foxy_Lady_1966 at proton.me ha scritto:
>>
>> > Sorry, resend the post in txt and correct some parts.
>> > The question is: can i force SQUID to do a reverse dns lookup and maintain the Host Header inside (where's a ptr record is found), also if i can't find a ptr record? SOCKS5 works with 1st level tcp, so send ip addresses, i need some tool, or Squid workaround, which can force a reverse dns. I know, it's quite impossible if a ptr record is not found in dnses, but... i try..
>> >
>> > ----------
>> >
>> > Hi all.
>> > As in subject.
>> > SQUID server has its own dns resolver.
>> >
>> > Can SQUID change the destination address from ip to hostname?
>> >
>> > CLIENT > SQUID > DESTINATION
>> >
>> > 192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.8.59
>> >
>> > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
>> >
>> > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT 104.26.9.59:443 - HIER_DIRECT/104.26.9.59
>> >
>> > I would need,
>> >
>> > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
>> >
>> > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.9.59

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
The early bird may get the worm, but the second mouse gets the cheese.

From udhayakumar at fatpipeinc.com  Wed Feb  5 10:47:08 2025
From: udhayakumar at fatpipeinc.com (udhayakumar)
Date: Wed, 5 Feb 2025 16:17:08 +0530
Subject: [squid-users] bypassing the domains
Message-ID: <37b911c2-faa0-8679-0032-76d4ab92261b@fatpipeinc.com>

Hi everyone,

		i have facing the small issue i Need to bypass the some domains like bank and  general domains google and yahoo like search engine. currently i  was doing doing ssl bump  all the sites how to bypass the domains or without decrypt the
connection how to create connection between server and client. below is my config

=================================================================

http_port 3128
http_port 3129 tproxy
https_port 3127 tproxy ssl-bump cert=/etc/squid_av/ssl_cert/squidCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:RC4:!aNULL:!eNULL:!LOW:3DES:!MD5:!EXP:!PSK:!SRP:!DSS options=ALL:NO_SSLv3

#don't verifying peer & allow accept with validate and error
#tls_outgoing_options flags=DONT_VERIFY_PEER
tls_outgoing_options flags=DONT_VERIFY_DOMAIN
tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

icp_port 0
digest_generation off
error_default_language en
#logformat icap_squid %tl %>a %>p %<A %la %lp %<la %<lp %tr %dt
#icap_log /var/log/squid/access.log
#logformat customlog (%tl) source_ip=%>a src_port=%>p user=%ui [%tl] "%rm %ru HTTP/%rv" status=%>Hs size=%<st user_agent="%{User-Agent}>h"


cache_log /var/log/squid/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable off

log_icp_queries off
logfile_rotate 1
# squid worker config optmize based on processor
workers 16
cpu_affinity_map process_numbers=1,2, cores=1,3
# certificate mimic
sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/squid/ssl_db -M 16MB -b 2048
logfile_rotate 2
debug_options rotate=2
#proxy options
hosts_file /etc/hosts
fqdncache_size 6000
visible_hostname fatpipe_proxy
collapsed_forwarding on
forwarded_for transparent
via on
httpd_suppress_version_string on
uri_whitespace strip
shutdown_lifetime 3 seconds
url_rewrite_host_header on
#loggiing strop
strip_query_terms on
#cache option Amount RAM half
cache_mem 8096 MB
memory_cache_mode always
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 4 MB
#cache allocation disk store block by block it's helps disk i/o
cache_dir rock /var/spool/rockfs/squid_cache 20000 max-size=32768 max-swap-rate=250 swap-timeout=200
max_stale 1 week
on_unsupported_protocol tunnel

offline_mode off
#cache low and high mark
cache_swap_low 90
cache_swap_high 96
cache allow all

#pipelining for HTTP pipelining
pipeline_prefetch 6
acl SSL_ports port 443          #https
acl SSL_ports port 563          #https

acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

acl HTTP proto HTTP
acl HTTPS proto HTTPS

acl purge method PURGE
acl CONNECT method CONNECT

#new tweak
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8             # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10          # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly plugged) machines
acl localnet src 172.16.0.0/12          # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16         # RFC 1918 local private network (LAN)
acl localnet src fc00::/7               # RFC 4193 local private network range
acl localnet src fe80::/10              # RFC 4291 link-local (directly plugged) machines
acl allsrc src all

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
acl windowsupdate dstdomain windowsupdate.microsoft.com
cl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com

http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet

#skip lan subnet
#acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
#sslproxy_cert_error allow localnet DomainMismatch
#sslproxy_cert_error deny all

# Define a list of websites to skip the proxy
#acl sslwhitelist ssl::server_name_regex -i "/etc/squid_av/whitelist_regex.acl"
#acl allowed_sites ssl::server_name "/etc/squid_av/whitelist.acl"
#acl local-external dstdomain .google.com .icicibank.com
#always_direct allow local-external
#acl allowed_sites ssl::server_name .foo.com .hdfcbank.com .copilot.microsoft.com
#sslproxy_cert_error allow allowed_sites
host_verify_strict off

ssl_bump peek step1
#ssl_bump splice sslwhitelist
#ssl_bump splice allowed_sites
ssl_bump bump all

http_access allow manager localhost
http_access deny manager

http_access allow purge localhost
http_access deny purge
# Deny requests to certain unsafe ports
http_access deny !Safe_ports
# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

http_access allow localnet
http_access allow localhost
#request header config
quick_abort_min 0 KB
quick_abort_max 0 KB
request_body_max_size 0 KB
#delay_pools config
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
# Throttle extensions matched in the url
#acl throttle_exts urlpath_regex -i "/var/squid/acl/throttle_exts.acl"
#delay_access 1 allow throttle_exts
#delay_access 1 deny allsrc

# Set YouTube safesearch restriction
#acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
#request_header_access YouTube-Restrict deny all
#request_header_add YouTube-Restrict moderate youtubedst
ssl_bump peek step1
ssl_bump bump all
# Allow local network(s) on interface(s)
http_access allow localnet

# Default block all to be sure
http_access deny allsrc


icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_encode off
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024


icap_service service_avi_req reqmod_precache icap://localhost:1344/squidclamav bypass=on
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache icap://localhost:1344/squidclamav bypass=off
adaptation_access service_avi_resp allow all

#debug_options ALL,1
sslproxy_cert_error allow all
negative_ttl 0 seconds
negative_dns_ttl 1 second

# Leave coredumps in the first cache dir
coredump_dir /var/log/dump/squid


/udhayakumar.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250205/cfdc7b9d/attachment-0001.htm>

From udhayakumar at fatpipeinc.com  Wed Feb  5 10:54:09 2025
From: udhayakumar at fatpipeinc.com (udhayakumar)
Date: Wed, 5 Feb 2025 16:24:09 +0530
Subject: [squid-users] bypassing the domains
In-Reply-To: <37b911c2-faa0-8679-0032-76d4ab92261b@fatpipeinc.com>
References: <37b911c2-faa0-8679-0032-76d4ab92261b@fatpipeinc.com>
Message-ID: <9fd56d1c-1cf1-0f4e-5d1f-ca15de255677@fatpipeinc.com>

Hi everyone ,

	if i put whitelist_regex in below config which domains i was try browse in browser it's says*SSL_ERROR_RX_RECORD_TOO_LONG*

Thanks,
Udhayakumar.

On 2/5/25 4:17 PM, udhayakumar wrote:
> Hi everyone,
>
> 		i have facing the small issue i Need to bypass the some domains like bank and  general domains google and yahoo like search engine. currently i  was doing doing ssl bump  all the sites how to bypass the domains or without decrypt the
> connection how to create connection between server and client. below is my config
>
> =================================================================
>
> http_port 3128
> http_port 3129 tproxy
> https_port 3127 tproxy ssl-bump cert=/etc/squid_av/ssl_cert/squidCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:RC4:!aNULL:!eNULL:!LOW:3DES:!MD5:!EXP:!PSK:!SRP:!DSS options=ALL:NO_SSLv3
>
> #don't verifying peer & allow accept with validate and error
> #tls_outgoing_options flags=DONT_VERIFY_PEER
> tls_outgoing_options flags=DONT_VERIFY_DOMAIN
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> icp_port 0
> digest_generation off
> error_default_language en
> #logformat icap_squid %tl %>a %>p %<A %la %lp %<la %<lp %tr %dt
> #icap_log /var/log/squid/access.log
> #logformat customlog (%tl) source_ip=%>a src_port=%>p user=%ui [%tl] "%rm %ru HTTP/%rv" status=%>Hs size=%<st user_agent="%{User-Agent}>h"
>
>
> cache_log /var/log/squid/cache.log
> cache_store_log none
> netdb_filename /var/squid/logs/netdb.state
> pinger_enable off
>
> log_icp_queries off
> logfile_rotate 1
> # squid worker config optmize based on processor
> workers 16
> cpu_affinity_map process_numbers=1,2, cores=1,3
> # certificate mimic
> sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/squid/ssl_db -M 16MB -b 2048
> logfile_rotate 2
> debug_options rotate=2
> #proxy options
> hosts_file /etc/hosts
> fqdncache_size 6000
> visible_hostname fatpipe_proxy
> collapsed_forwarding on
> forwarded_for transparent
> via on
> httpd_suppress_version_string on
> uri_whitespace strip
> shutdown_lifetime 3 seconds
> url_rewrite_host_header on
> #loggiing strop
> strip_query_terms on
> #cache option Amount RAM half
> cache_mem 8096 MB
> memory_cache_mode always
> maximum_object_size_in_memory 256 KB
> memory_replacement_policy heap GDSF
> cache_replacement_policy heap LFUDA
> minimum_object_size 0 KB
> maximum_object_size 4 MB
> #cache allocation disk store block by block it's helps disk i/o
> cache_dir rock /var/spool/rockfs/squid_cache 20000 max-size=32768 max-swap-rate=250 swap-timeout=200
> max_stale 1 week
> on_unsupported_protocol tunnel
>
> offline_mode off
> #cache low and high mark
> cache_swap_low 90
> cache_swap_high 96
> cache allow all
>
> #pipelining for HTTP pipelining
> pipeline_prefetch 6
> acl SSL_ports port 443          #https
> acl SSL_ports port 563          #https
>
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
>
> acl HTTP proto HTTP
> acl HTTPS proto HTTPS
>
> acl purge method PURGE
> acl CONNECT method CONNECT
>
> #new tweak
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
> acl localnet src 10.0.0.0/8             # RFC 1918 local private network (LAN)
> acl localnet src 100.64.0.0/10          # RFC 6598 shared address space (CGN)
> acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly plugged) machines
> acl localnet src 172.16.0.0/12          # RFC 1918 local private network (LAN)
> acl localnet src 192.168.0.0/16         # RFC 1918 local private network (LAN)
> acl localnet src fc00::/7               # RFC 4193 local private network range
> acl localnet src fe80::/10              # RFC 4291 link-local (directly plugged) machines
> acl allsrc src all
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> cl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomainwww.download.windowsupdate.com
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
>
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomainwww.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
>
> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet
>
> #skip lan subnet
> #acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> #sslproxy_cert_error allow localnet DomainMismatch
> #sslproxy_cert_error deny all
>
> # Define a list of websites to skip the proxy
> #acl sslwhitelist ssl::server_name_regex -i "/etc/squid_av/whitelist_regex.acl"
> #acl allowed_sites ssl::server_name "/etc/squid_av/whitelist.acl"
> #acl local-external dstdomain .google.com .icicibank.com
> #always_direct allow local-external
> #acl allowed_sites ssl::server_name .foo.com .hdfcbank.com .copilot.microsoft.com
> #sslproxy_cert_error allow allowed_sites
> host_verify_strict off
>
> ssl_bump peek step1
> #ssl_bump splice sslwhitelist
> #ssl_bump splice allowed_sites
> ssl_bump bump all
>
> http_access allow manager localhost
> http_access deny manager
>
> http_access allow purge localhost
> http_access deny purge
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> http_access allow localnet
> http_access allow localhost
> #request header config
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> request_body_max_size 0 KB
> #delay_pools config
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 -1/-1
> delay_initial_bucket_level 100
> # Throttle extensions matched in the url
> #acl throttle_exts urlpath_regex -i "/var/squid/acl/throttle_exts.acl"
> #delay_access 1 allow throttle_exts
> #delay_access 1 deny allsrc
>
> # Set YouTube safesearch restriction
> #acl youtubedst dstdomain -nwww.youtube.com  m.youtube.com youtubei.googleapis.com youtube.googleapis.comwww.youtube-nocookie.com
> #request_header_access YouTube-Restrict deny all
> #request_header_add YouTube-Restrict moderate youtubedst
> ssl_bump peek step1
> ssl_bump bump all
> # Allow local network(s) on interface(s)
> http_access allow localnet
>
> # Default block all to be sure
> http_access deny allsrc
>
>
> icap_enable on
> icap_send_client_ip on
> icap_send_client_username on
> icap_client_username_encode off
> icap_client_username_header X-Authenticated-User
> icap_preview_enable on
> icap_preview_size 1024
>
>
> icap_service service_avi_req reqmod_precache icap://localhost:1344/squidclamav bypass=on
> adaptation_access service_avi_req allow all
> icap_service service_avi_resp respmod_precache icap://localhost:1344/squidclamav bypass=off
> adaptation_access service_avi_resp allow all
>
> #debug_options ALL,1
> sslproxy_cert_error allow all
> negative_ttl 0 seconds
> negative_dns_ttl 1 second
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/log/dump/squid
>
>
> /udhayakumar.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250205/d821ddff/attachment.htm>

From ngtech1ltd at gmail.com  Wed Feb  5 11:30:00 2025
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Wed, 5 Feb 2025 13:30:00 +0200
Subject: [squid-users] Can SQUID change the destination address from ip
 to hostname?
In-Reply-To: <Z6M25JBHFBK0Sek2@fantomas.sk>
References: <gdWMCMhkSGetpDGFe7UP6fWI3Wv2EfEd971H4ZIfTammLBHpPDbSWZtV7V2cQy47oMyGnb6QuQ0oTvP8NRU9kpbbjBxS5XT01BNxzQT2X8w=@proton.me>
 <_2XBjR7SBKSovKsKJ084MwVAXLNRgEIWw9wwrFujElNFkyS7juw0zxIiLO24jm8tT5FwrM4tB1pP-wYsN92DMBNshC-eHVJURIk_E4nAInU=@proton.me>
 <Q89xQ-jf65_S5VwIFStJolA25WA_aN7CA1DuZ0zSt1QEJZ8ER2iC8DIT-bRPPa01MAO4_oTE1UFJ823nD4D9mcWlMGStK6FFlVzcAvIez9c=@proton.me>
 <Z6M25JBHFBK0Sek2@fantomas.sk>
Message-ID: <CABA8h=QrVVsz0DQf2Q2UU34uu4mQntnbd_qxok9x_FOK7UouHQ@mail.gmail.com>

Hey,

Unless you have access to the dns resolver resolved domain and ip addresses.
With these you can try(not 100%) to find the relevant domain if it's not a
multi tenant vps or cdn or waf provider.

Eliezer

?????? ??? ??, 5 ????? 2025, 12:01, ??? Matus UHLAR - fantomas ?<
uhlar at fantomas.sk>:

> On 04.02.25 21:22, Foxy Lady wrote:
> >I try again asking the ML if
> >
> >- can Squid change the destination address of a call?
> >
> >I mean, something like
> >
> ><url_rewrite_command> $destination $Host
> >
> >original $destination is 104.26.9.59:443
> >$Host is the original HTTP Header "Host: xxxxx" alias "api.myip.com:443"
> >
> >So, a call to
> >https://104.26.9.59:443/test
> >will become
> >https://api.myip.com:443/test
>
> Hello,
>
> I guess that the URL redirector could do that.
> http://www.squid-cache.org/Doc/config/url_rewrite_program/
>
> Note that it's extremely unreliable, because IP=>hostname mapping is a
> wild
> guess, because after client asks for IP address, you don't really know
> what
> hostname they want.
> So my recommendation is: don't do that.
>
> Note that SOCKS5 protocol supports DNS resolution at server level
>
> >marted? 4 febbraio 2025 06:17, Foxy Lady <Foxy_Lady_1966 at proton.me> ha
> scritto:
> >
> >> Hi again.
> >> I finally found a tool (great tool, "GO Simple Tunnel") which can
> serves both HTTP(S)/SOCKS5 Proxy with dns resolution, so chaining it in the
> middle of Squid, Squid receives the destination in format of "domain.fqdn"
> and not ip "x.x.x.x",
> >>
> >> TCP_TUNNEL/200 4118 CONNECT api.myip.com:443 username HIER_DIRECT/
> 104.26.9.59 - "Go-http-client/1.1" [User-Agent:
> Go-http-client/1.1\r\nProxy-Authorization: Basic
> bWFyY286dHIwdHQwbGE=\r\nProxy-Connection: keep-alive\r\nHost:
> api.myip.com:443\r\n] [HTTP/1.1 200 Connection established\r\n\r\n]
> >>
> >> ???
> >>
> >>
> >> Inviato con l'email sicura Proton Mail.
> >>
> >>
> >> luned? 3 febbraio 2025 22:22, Foxy Lady Foxy_Lady_1966 at proton.me ha
> scritto:
> >>
> >> > Sorry, resend the post in txt and correct some parts.
> >> > The question is: can i force SQUID to do a reverse dns lookup and
> maintain the Host Header inside (where's a ptr record is found), also if i
> can't find a ptr record? SOCKS5 works with 1st level tcp, so send ip
> addresses, i need some tool, or Squid workaround, which can force a reverse
> dns. I know, it's quite impossible if a ptr record is not found in dnses,
> but... i try..
> >> >
> >> > ----------
> >> >
> >> > Hi all.
> >> > As in subject.
> >> > SQUID server has its own dns resolver.
> >> >
> >> > Can SQUID change the destination address from ip to hostname?
> >> >
> >> > CLIENT > SQUID > DESTINATION
> >> >
> >> > 192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 -
> HIER_DIRECT/104.26.8.59
> >> >
> >> > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> >> >
> >> > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT 104.26.9.59:443 -
> HIER_DIRECT/104.26.9.59
> >> >
> >> > I would need,
> >> >
> >> > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> >> >
> >> > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT api.myip.com:443 -
> HIER_DIRECT/104.26.9.59
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> The early bird may get the worm, but the second mouse gets the cheese.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250205/dd6db4fe/attachment-0001.htm>

From rousskov at measurement-factory.com  Wed Feb  5 14:46:04 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Feb 2025 09:46:04 -0500
Subject: [squid-users] bypassing the domains
In-Reply-To: <9fd56d1c-1cf1-0f4e-5d1f-ca15de255677@fatpipeinc.com>
References: <37b911c2-faa0-8679-0032-76d4ab92261b@fatpipeinc.com>
 <9fd56d1c-1cf1-0f4e-5d1f-ca15de255677@fatpipeinc.com>
Message-ID: <422627f2-476d-4a24-b6bb-07fae6d16457@measurement-factory.com>

On 2025-02-05 05:54, udhayakumar wrote:

> if i put whitelist_regex in below config which domains i was try
> browse in browser it's says*SSL_ERROR_RX_RECORD_TOO_LONG*

IIRC, that usually happens when Squid responds with a plain text error 
page while the browser expects TLS. You may be able to confirm that by 
looking at the problematic browser-Squid transactions using wireshark or 
a similar packet analysis tool.


> ssl_bump peek step1
> ssl_bump splice sslwhitelist
> ssl_bump splice allowed_sites
 > ssl_bump bump all

Do you have http_access rules that allow TLS connections to sites 
matching sslwhitelist and allowed_sites ACLs? I do not see them. Please 
keep in mind that http_access controls access (for requests on all 
connections) while ssl_bump controls whether/when TLS connections are 
decrypted. Both sets of rules are important. For example, if http_access 
denies a request, then Squid will not splice the corresponding 
client-to-Squid and Squid-to-server connections.

Please also note that your second set of ssl_bump rules (not shown 
above) will never be reached because one of the ssl_bump rules shown 
above will always match, ending ssl_bump rule evaliation.


HTH,

Alex.


>> http_port 3128
>> http_port 3129 tproxy
>> https_port 3127 tproxy ssl-bump cert=/etc/squid_av/ssl_cert/squidCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:RC4:!aNULL:!eNULL:!LOW:3DES:!MD5:!EXP:!PSK:!SRP:!DSS options=ALL:NO_SSLv3
>>
>> #don't verifying peer & allow accept with validate and error
>> #tls_outgoing_options flags=DONT_VERIFY_PEER
>> tls_outgoing_options flags=DONT_VERIFY_DOMAIN
>> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>
>> icp_port 0
>> digest_generation off
>> error_default_language en
>> #logformat icap_squid %tl %>a %>p %<A %la %lp %<la %<lp %tr %dt
>> #icap_log /var/log/squid/access.log
>> #logformat customlog (%tl) source_ip=%>a src_port=%>p user=%ui [%tl] "%rm %ru HTTP/%rv" status=%>Hs size=%<st user_agent="%{User-Agent}>h"
>>
>>
>> cache_log /var/log/squid/cache.log
>> cache_store_log none
>> netdb_filename /var/squid/logs/netdb.state
>> pinger_enable off
>>
>> log_icp_queries off
>> logfile_rotate 1
>> # squid worker config optmize based on processor
>> workers 16
>> cpu_affinity_map process_numbers=1,2, cores=1,3
>> # certificate mimic
>> sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/squid/ssl_db -M 16MB -b 2048
>> logfile_rotate 2
>> debug_options rotate=2
>> #proxy options
>> hosts_file /etc/hosts
>> fqdncache_size 6000
>> visible_hostname fatpipe_proxy
>> collapsed_forwarding on
>> forwarded_for transparent
>> via on
>> httpd_suppress_version_string on
>> uri_whitespace strip
>> shutdown_lifetime 3 seconds
>> url_rewrite_host_header on
>> #loggiing strop
>> strip_query_terms on
>> #cache option Amount RAM half
>> cache_mem 8096 MB
>> memory_cache_mode always
>> maximum_object_size_in_memory 256 KB
>> memory_replacement_policy heap GDSF
>> cache_replacement_policy heap LFUDA
>> minimum_object_size 0 KB
>> maximum_object_size 4 MB
>> #cache allocation disk store block by block it's helps disk i/o
>> cache_dir rock /var/spool/rockfs/squid_cache 20000 max-size=32768 max-swap-rate=250 swap-timeout=200
>> max_stale 1 week
>> on_unsupported_protocol tunnel
>>
>> offline_mode off
>> #cache low and high mark
>> cache_swap_low 90
>> cache_swap_high 96
>> cache allow all
>>
>> #pipelining for HTTP pipelining
>> pipeline_prefetch 6
>> acl SSL_ports port 443          #https
>> acl SSL_ports port 563          #https
>>
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>>
>> acl HTTP proto HTTP
>> acl HTTPS proto HTTPS
>>
>> acl purge method PURGE
>> acl CONNECT method CONNECT
>>
>> #new tweak
>> acl step1 at_step SslBump1
>> acl step2 at_step SslBump2
>> acl step3 at_step SslBump3
>>
>> # Example rule allowing access from your local networks.
>> # Adapt to list your (internal) IP networks from where browsing
>> # should be allowed
>> acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
>> acl localnet src 10.0.0.0/8             # RFC 1918 local private network (LAN)
>> acl localnet src 100.64.0.0/10          # RFC 6598 shared address space (CGN)
>> acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly plugged) machines
>> acl localnet src 172.16.0.0/12          # RFC 1918 local private network (LAN)
>> acl localnet src 192.168.0.0/16         # RFC 1918 local private network (LAN)
>> acl localnet src fc00::/7               # RFC 4193 local private network range
>> acl localnet src fe80::/10              # RFC 4291 link-local (directly plugged) machines
>> acl allsrc src all
>>
>> #
>> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>> #
>> acl windowsupdate dstdomain windowsupdate.microsoft.com
>> cl windowsupdate dstdomain .update.microsoft.com
>> acl windowsupdate dstdomain download.windowsupdate.com
>> acl windowsupdate dstdomain redir.metaservices.microsoft.com
>> acl windowsupdate dstdomain images.metaservices.microsoft.com
>> acl windowsupdate dstdomain c.microsoft.com
>> acl windowsupdate dstdomainwww.download.windowsupdate.com
>> acl windowsupdate dstdomain wustat.windows.com
>> acl windowsupdate dstdomain crl.microsoft.com
>> acl windowsupdate dstdomain sls.microsoft.com
>> acl windowsupdate dstdomain productactivation.one.microsoft.com
>> acl windowsupdate dstdomain ntservicepack.microsoft.com
>>
>> acl CONNECT method CONNECT
>> acl wuCONNECT dstdomainwww.update.microsoft.com
>> acl wuCONNECT dstdomain sls.microsoft.com
>>
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow windowsupdate localnet
>>
>> #skip lan subnet
>> #acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
>> #sslproxy_cert_error allow localnet DomainMismatch
>> #sslproxy_cert_error deny all
>>
>> # Define a list of websites to skip the proxy
>> #acl sslwhitelist ssl::server_name_regex -i "/etc/squid_av/whitelist_regex.acl"
>> #acl allowed_sites ssl::server_name "/etc/squid_av/whitelist.acl"
>> #acl local-external dstdomain .google.com .icicibank.com
>> #always_direct allow local-external
>> #acl allowed_sites ssl::server_name .foo.com .hdfcbank.com .copilot.microsoft.com
>> #sslproxy_cert_error allow allowed_sites
>> host_verify_strict off
>>
>> ssl_bump peek step1
>> #ssl_bump splice sslwhitelist
>> #ssl_bump splice allowed_sites
>> ssl_bump bump all
>>
>> http_access allow manager localhost
>> http_access deny manager
>>
>> http_access allow purge localhost
>> http_access deny purge
>> # Deny requests to certain unsafe ports
>> http_access deny !Safe_ports
>> # Deny CONNECT to other than secure SSL ports
>> http_access deny CONNECT !SSL_ports
>>
>> http_access allow localnet
>> http_access allow localhost
>> #request header config
>> quick_abort_min 0 KB
>> quick_abort_max 0 KB
>> request_body_max_size 0 KB
>> #delay_pools config
>> delay_pools 1
>> delay_class 1 2
>> delay_parameters 1 -1/-1 -1/-1
>> delay_initial_bucket_level 100
>> # Throttle extensions matched in the url
>> #acl throttle_exts urlpath_regex -i "/var/squid/acl/throttle_exts.acl"
>> #delay_access 1 allow throttle_exts
>> #delay_access 1 deny allsrc
>>
>> # Set YouTube safesearch restriction
>> #acl youtubedst dstdomain -nwww.youtube.com  m.youtube.com youtubei.googleapis.com youtube.googleapis.comwww.youtube-nocookie.com
>> #request_header_access YouTube-Restrict deny all
>> #request_header_add YouTube-Restrict moderate youtubedst
>> ssl_bump peek step1
>> ssl_bump bump all
>> # Allow local network(s) on interface(s)
>> http_access allow localnet
>>
>> # Default block all to be sure
>> http_access deny allsrc
>>
>>
>> icap_enable on
>> icap_send_client_ip on
>> icap_send_client_username on
>> icap_client_username_encode off
>> icap_client_username_header X-Authenticated-User
>> icap_preview_enable on
>> icap_preview_size 1024
>>
>>
>> icap_service service_avi_req reqmod_precache icap://localhost:1344/squidclamav bypass=on
>> adaptation_access service_avi_req allow all
>> icap_service service_avi_resp respmod_precache icap://localhost:1344/squidclamav bypass=off
>> adaptation_access service_avi_resp allow all
>>
>> #debug_options ALL,1
>> sslproxy_cert_error allow all
>> negative_ttl 0 seconds
>> negative_dns_ttl 1 second
>>
>> # Leave coredumps in the first cache dir
>> coredump_dir /var/log/dump/squid
>>
>>
>> /udhayakumar.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From luhliari at redhat.com  Wed Feb  5 16:36:31 2025
From: luhliari at redhat.com (Lubos Uhliarik)
Date: Wed, 5 Feb 2025 17:36:31 +0100
Subject: [squid-users] Squid 6.13 source files download
In-Reply-To: <CA+Y8hcMNHW6Qgo9qU=9KsY6gi6yYgDr37UVwJRYi9QQwmBT--A@mail.gmail.com>
References: <CAMJdYBzn-MeGy9WWvyGpqjJmgQRx+1sUfEVkxW1aUzq=j24BXQ@mail.gmail.com>
 <CA+Y8hcMNHW6Qgo9qU=9KsY6gi6yYgDr37UVwJRYi9QQwmBT--A@mail.gmail.com>
Message-ID: <CAMJdYBzOSXpkef82X-CVOnHPYMKja=83GzDdvvRYk_RU-sWBMA@mail.gmail.com>

Hello Francesco and Stuart,

I'm sorry for the fuss; I missed the announcement [0] about the transition
to GitHub. Thanks for pointing that out.

[0]
https://lists.squid-cache.org/pipermail/squid-users/2025-January/027357.html

On Tue, Feb 4, 2025 at 9:19?PM Francesco Chemolli <gkinkie at gmail.com> wrote:

> Hi Lubos,
>   I confirm that the old URLs have been retired and longer work.
> If you need a direct download, the working link is:
>
> https://github.com/squid-cache/squid/releases/download/SQUID_<version
> number with dots replaced by underscores>/squid-<version number>.tar.xz
>
> e.g.
>
> https://github.com/squid-cache/squid/releases/download/SQUID_6_13/squid-6.13.tar.xz
>
>
> Francesco
>
>
> On Tue, 4 Feb 2025 at 5:29?pm, Lubos Uhliarik <luhliari at redhat.com> wrote:
>
>> Hello Squid users,
>>
>> I wanted to ask if it is still possible to download source files and
>> their signatures using the previously used URLs (e.g.,
>> http://www.squid-cache.org/Versions/v6/squid-6.12.tar.xz), or are
>> these URLs no longer supported?
>>
>> For Squid 6.13, I am unable to access the files through the following
>> URLs:
>>
>> http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz
>> http://www.squid-cache.org/Versions/v6/squid-6.13.tar.xz.asc
>>
>> Neither of them seems to be working.
>>
>> Regards,
>>
>> --
>> Lubo? Uhliarik
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>>
>

Best,

-- 

Lubo? Uhliarik
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250205/cbaa230a/attachment.htm>

From Foxy_Lady_1966 at proton.me  Wed Feb  5 20:15:46 2025
From: Foxy_Lady_1966 at proton.me (Foxy Lady)
Date: Wed, 05 Feb 2025 20:15:46 +0000
Subject: [squid-users] Can SQUID change the destination address from ip
 to hostname?
In-Reply-To: <Z6M25JBHFBK0Sek2@fantomas.sk>
References: <gdWMCMhkSGetpDGFe7UP6fWI3Wv2EfEd971H4ZIfTammLBHpPDbSWZtV7V2cQy47oMyGnb6QuQ0oTvP8NRU9kpbbjBxS5XT01BNxzQT2X8w=@proton.me>
 <_2XBjR7SBKSovKsKJ084MwVAXLNRgEIWw9wwrFujElNFkyS7juw0zxIiLO24jm8tT5FwrM4tB1pP-wYsN92DMBNshC-eHVJURIk_E4nAInU=@proton.me>
 <Q89xQ-jf65_S5VwIFStJolA25WA_aN7CA1DuZ0zSt1QEJZ8ER2iC8DIT-bRPPa01MAO4_oTE1UFJ823nD4D9mcWlMGStK6FFlVzcAvIez9c=@proton.me>
 <Z6M25JBHFBK0Sek2@fantomas.sk>
Message-ID: <aAcOQDF3ze5Ckayk99aI9XBQMOYZy6ewsiqJNpBPjjVViZ61Oz-9Szm97mTZF2UaTChgxmDqX7BfMORhwosgLf7AqCsZUiP8rz0PWb_AW-c=@proton.me>

Thanks, i'll try.
Better will be to make Squid listen also to a SOCKS5 port. I know there was a project years ago, seems to be broken and never implemented.

The real problem is that all proxifiers tools use ip:port as destination at first instance (redsocks, ts-warp, for example).

Inviato con l'email sicura Proton Mail.

mercoled? 5 febbraio 2025 11:01, Matus UHLAR - fantomas <uhlar at fantomas.sk> ha scritto:

> On 04.02.25 21:22, Foxy Lady wrote:
> 
> > I try again asking the ML if
> > 
> > - can Squid change the destination address of a call?
> > 
> > I mean, something like
> > 
> > <url_rewrite_command> $destination $Host
> > 
> > original $destination is 104.26.9.59:443
> > $Host is the original HTTP Header "Host: xxxxx" alias "api.myip.com:443"
> > 
> > So, a call to
> > https://104.26.9.59:443/test
> > will become
> > https://api.myip.com:443/test
> 
> 
> Hello,
> 
> I guess that the URL redirector could do that.
> http://www.squid-cache.org/Doc/config/url_rewrite_program/
> 
> Note that it's extremely unreliable, because IP=>hostname mapping is a wild
> 
> guess, because after client asks for IP address, you don't really know what
> hostname they want.
> So my recommendation is: don't do that.
> 
> Note that SOCKS5 protocol supports DNS resolution at server level
> 
> > marted? 4 febbraio 2025 06:17, Foxy Lady Foxy_Lady_1966 at proton.me ha scritto:
> > 
> > > Hi again.
> > > I finally found a tool (great tool, "GO Simple Tunnel") which can serves both HTTP(S)/SOCKS5 Proxy with dns resolution, so chaining it in the middle of Squid, Squid receives the destination in format of "domain.fqdn" and not ip "x.x.x.x",
> > > 
> > > TCP_TUNNEL/200 4118 CONNECT api.myip.com:443 username HIER_DIRECT/104.26.9.59 - "Go-http-client/1.1" [User-Agent: Go-http-client/1.1\r\nProxy-Authorization: Basic bWFyY286dHIwdHQwbGE=\r\nProxy-Connection: keep-alive\r\nHost: api.myip.com:443\r\n] [HTTP/1.1 200 Connection established\r\n\r\n]
> > > 
> > > ???
> > > 
> > > Inviato con l'email sicura Proton Mail.
> > > 
> > > luned? 3 febbraio 2025 22:22, Foxy Lady Foxy_Lady_1966 at proton.me ha scritto:
> > > 
> > > > Sorry, resend the post in txt and correct some parts.
> > > > The question is: can i force SQUID to do a reverse dns lookup and maintain the Host Header inside (where's a ptr record is found), also if i can't find a ptr record? SOCKS5 works with 1st level tcp, so send ip addresses, i need some tool, or Squid workaround, which can force a reverse dns. I know, it's quite impossible if a ptr record is not found in dnses, but... i try..
> > > > 
> > > > ----------
> > > > 
> > > > Hi all.
> > > > As in subject.
> > > > SQUID server has its own dns resolver.
> > > > 
> > > > Can SQUID change the destination address from ip to hostname?
> > > > 
> > > > CLIENT > SQUID > DESTINATION
> > > > 
> > > > 192.168.178.2 TCP_TUNNEL/200 4120 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.8.59
> > > > 
> > > > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> > > > 
> > > > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT 104.26.9.59:443 - HIER_DIRECT/104.26.9.59
> > > > 
> > > > I would need,
> > > > 
> > > > CLIENT > SOCKS5 PROXY > SQUID > DESTINATION
> > > > 
> > > > 192.168.178.50 TCP_TUNNEL/200 4126 CONNECT api.myip.com:443 - HIER_DIRECT/104.26.9.59
> 
> 
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> The early bird may get the worm, but the second mouse gets the cheese.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

From squid at digi.ninja  Fri Feb  7 10:15:47 2025
From: squid at digi.ninja (Robin Wood)
Date: Fri, 7 Feb 2025 10:15:47 +0000
Subject: [squid-users] test ICAP server
Message-ID: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>

Hi
I want to write my own ICAP server, but all the sample code I've found is
failing, the majority with this error from squidclient:

squidclient -h 192.168.0.7 -p 1344 icap://192.168.0.7:1344/request_mod
ICAP/1.0 400 Bad Request

And this error when accessed through Squid itself:

ICAP protocol error.

The system returned: [No Error]

This means that some aspect of the ICAP communication failed.

I've got this in my squid.conf:

# Enable ICAP for request and response modification
icap_enable on
icap_service service_req reqmod_precache icap://192.168.0.7:1344/request_mod
icap_service service_resp respmod_precache icap://
192.168.0.7:1344/response_mod

# ICAP adaptation rules
adaptation_access service_req allow all
adaptation_access service_resp allow all

And I've tried running both Python and Ruby servers taken from various
places. A lot are logging that they've received and replied to requests:

Received request: OPTIONS icap://192.168.0.7:1344/request_mod ICAP/1.0
Responded to OPTIONS request

The servers are all listening, I've checked that:

$ ss -antp | grep 1344
LISTEN     0      4096                       0.0.0.0:1344
 0.0.0.0:*     users:(("ruby",pid=563029,fd=5))

The closest I've got is this one:

https://gist.github.com/digininja/a98b3567e0aeb218d37cdd337bb12f34

It seems to be working as it sees the headers and says it has returned data:

Received request: REQMOD icap://192.168.0.7:1344/request_mod ICAP/1.0
Original Headers:
Host: 192.168.0.7:1344
Date: Fri, 07 Feb 2025 10:10:30 GMT
Encapsulated: req-hdr=0, null-body=91
Preview: 0
Allow: 204, trailers
Modified request sent back

But I still get errors.

What could be wrong?

Does someone have some example server code they know works that I can test
to help debug it?

Robin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250207/a30913c9/attachment.htm>

From squid at digi.ninja  Fri Feb  7 12:29:06 2025
From: squid at digi.ninja (Robin Wood)
Date: Fri, 7 Feb 2025 12:29:06 +0000
Subject: [squid-users] test ICAP server
In-Reply-To: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>
References: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>
Message-ID: <CALmccy5GtVq+i42izy6rizEzF_0+KjLifMr4Yn9XLdLCaeq4OA@mail.gmail.com>

I've got a bit further with this and I'm starting to understand ICAP talk.

I've got a Go server working which I can talk to through netcat:

$ nc localhost 1344
REQMOD icap://192.168.0.7/ ICAP/1.0
GET / HTTP/1.1
Host: dvwa.test
Accept: text/html, text/plain, image/gif
Accept-Encoding: gzip, compress

ICAP/1.0 200 OK
Encapsulated: req-hdr=0, null-body=141

GET / HTTP/1.1
Host: dvwa.test
Accept: text/html, text/plain, image/gif
Accept-Encoding: gzip, compress
X-Modified-By: Go ICAP Server


On the server side I see:

This is the request

REQMOD icap://192.168.0.7/ ICAP/1.0

Received request: REQMOD icap://192.168.0.7/ ICAP/1.0
Original Request Headers:
GET / HTTP/1.1
Host: dvwa.test
Accept: text/html, text/plain, image/gif
Accept-Encoding: gzip, compress


Modified request sent back

ICAP/1.0 200 OK
Encapsulated: req-hdr=0, null-body=141

GET / HTTP/1.1
Host: dvwa.test
Accept: text/html, text/plain, image/gif
Accept-Encoding: gzip, compress
X-Modified-By: Go ICAP Server


If I try to use curl through Squid pointing at that server:

$ curl "http://dvwa.test/a?xsa" --proxy localhost:3128

dvwa.test is at 192.168.0.42.

I get this in the ICAP server:

This is the request

REQMOD icap://192.168.0.7:1344/ ICAP/1.0

Received request: REQMOD icap://192.168.0.7:1344/ ICAP/1.0
Original Request Headers:
Host: 192.168.0.7:1344
Date: Fri, 07 Feb 2025 12:26:25 GMT
Encapsulated: req-hdr=0, null-body=93
Allow: 204, trailers


Modified request sent back

ICAP/1.0 200 OK
Encapsulated: req-hdr=0, null-body=155

Host: 192.168.0.7:1344
Date: Fri, 07 Feb 2025 12:26:25 GMT
Encapsulated: req-hdr=0, null-body=93
Allow: 204, trailers
X-Modified-By: Go ICAP Server

Squid then gives the same error as before, ERR_ICAP_FAILURE.

Robin

On Fri, 7 Feb 2025 at 10:15, Robin Wood <squid at digi.ninja> wrote:

> Hi
> I want to write my own ICAP server, but all the sample code I've found is
> failing, the majority with this error from squidclient:
>
> squidclient -h 192.168.0.7 -p 1344 icap://192.168.0.7:1344/request_mod
> ICAP/1.0 400 Bad Request
>
> And this error when accessed through Squid itself:
>
> ICAP protocol error.
>
> The system returned: [No Error]
>
> This means that some aspect of the ICAP communication failed.
>
> I've got this in my squid.conf:
>
> # Enable ICAP for request and response modification
> icap_enable on
> icap_service service_req reqmod_precache icap://
> 192.168.0.7:1344/request_mod
> icap_service service_resp respmod_precache icap://
> 192.168.0.7:1344/response_mod
>
> # ICAP adaptation rules
> adaptation_access service_req allow all
> adaptation_access service_resp allow all
>
> And I've tried running both Python and Ruby servers taken from various
> places. A lot are logging that they've received and replied to requests:
>
> Received request: OPTIONS icap://192.168.0.7:1344/request_mod ICAP/1.0
> Responded to OPTIONS request
>
> The servers are all listening, I've checked that:
>
> $ ss -antp | grep 1344
> LISTEN     0      4096                       0.0.0.0:1344
>  0.0.0.0:*     users:(("ruby",pid=563029,fd=5))
>
> The closest I've got is this one:
>
> https://gist.github.com/digininja/a98b3567e0aeb218d37cdd337bb12f34
>
> It seems to be working as it sees the headers and says it has returned
> data:
>
> Received request: REQMOD icap://192.168.0.7:1344/request_mod ICAP/1.0
> Original Headers:
> Host: 192.168.0.7:1344
> Date: Fri, 07 Feb 2025 10:10:30 GMT
> Encapsulated: req-hdr=0, null-body=91
> Preview: 0
> Allow: 204, trailers
> Modified request sent back
>
> But I still get errors.
>
> What could be wrong?
>
> Does someone have some example server code they know works that I can test
> to help debug it?
>
> Robin
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250207/e8d883b1/attachment.htm>

From rousskov at measurement-factory.com  Fri Feb  7 14:56:45 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 7 Feb 2025 09:56:45 -0500
Subject: [squid-users] test ICAP server
In-Reply-To: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>
References: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>
Message-ID: <c4ba49c6-6419-4a2e-9e1a-2da10ec44929@measurement-factory.com>

On 2025-02-07 05:15, Robin Wood wrote:

> I want to write my own ICAP server

FWIW, nearly all attempts to quickly write a production-quality ICAP 
server (that I have seen) have failed. The protocol is much more complex 
than it seems. In most cases, folks looking for a free ICAP server 
should be reusing existing c-icap.


> but all the sample code I've found 
> is failing, the majority with this error from squidclient:

squidclient does not really support ICAP.


> Does someone have some example server code they know works that I can 
> test to help debug it?

Consider c-icap: https://c-icap.sourceforge.net/


HTH,

Alex.


From squid at digi.ninja  Fri Feb  7 15:35:42 2025
From: squid at digi.ninja (Robin Wood)
Date: Fri, 7 Feb 2025 15:35:42 +0000
Subject: [squid-users] test ICAP server
In-Reply-To: <c4ba49c6-6419-4a2e-9e1a-2da10ec44929@measurement-factory.com>
References: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>
 <c4ba49c6-6419-4a2e-9e1a-2da10ec44929@measurement-factory.com>
Message-ID: <CALmccy7DvtVKqv9Hz5YEqHsksw+H051Ujz0zMXOr2TcJzv=FBA@mail.gmail.com>

Hi
I wouldn't risk trying to do a production quality one server!

I'm a security tester and I want a way to automatically modify traffic that
I'm sending to and from sites. I've got plenty of other ways to do it, but
as all my testing traffic already goes through a Squid box I just wanted to
have a play to see if I could get it to do simple things like add a new
header or something like that.  When I saw some really simple servers
written in Python and Go I thought it would be a fun bit of learning.

I've just grabbed a copy of c-icap, the build instructions could do with
some work, I've got it built, but it wasn't obvious what needed doing. I'll
have a play, it won't be as flexible as I wanted, but I'll hopefully learn
something, and that might help debug the other servers.

Robin

On Fri, 7 Feb 2025 at 14:56, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 2025-02-07 05:15, Robin Wood wrote:
>
> > I want to write my own ICAP server
>
> FWIW, nearly all attempts to quickly write a production-quality ICAP
> server (that I have seen) have failed. The protocol is much more complex
> than it seems. In most cases, folks looking for a free ICAP server
> should be reusing existing c-icap.
>
>
> > but all the sample code I've found
> > is failing, the majority with this error from squidclient:
>
> squidclient does not really support ICAP.
>
>
> > Does someone have some example server code they know works that I can
> > test to help debug it?
>
> Consider c-icap: https://c-icap.sourceforge.net/
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250207/617fd0f2/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb  7 21:11:48 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Feb 2025 10:11:48 +1300
Subject: [squid-users] test ICAP server
In-Reply-To: <CALmccy7DvtVKqv9Hz5YEqHsksw+H051Ujz0zMXOr2TcJzv=FBA@mail.gmail.com>
References: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>
 <c4ba49c6-6419-4a2e-9e1a-2da10ec44929@measurement-factory.com>
 <CALmccy7DvtVKqv9Hz5YEqHsksw+H051Ujz0zMXOr2TcJzv=FBA@mail.gmail.com>
Message-ID: <87f9d94f-c88b-467f-8d8a-3f865d0e5a4d@treenet.co.nz>

On 8/02/25 04:35, Robin Wood wrote:
> Hi
> I wouldn't risk trying to do a production quality one server!
> 
> I'm a security tester and I want a way to automatically modify traffic 
> that I'm sending to and from sites. I've got plenty of other ways to do 
> it, but as all my testing traffic already goes through a Squid box I 
> just wanted to have a play to see if I could get it to do simple 
> things?like add a new header or something like that.

Please be aware that Squid normalizes and performs security sanitization 
on the HTTP messages that it receives. Regardless of whether they are 
arrive from client, server, or ICAP. That means a lot of traffic 
malformation needed for proper security tests will not work at all.


HTH
Amos


From squid at digi.ninja  Fri Feb  7 21:54:15 2025
From: squid at digi.ninja (Robin Wood)
Date: Fri, 7 Feb 2025 21:54:15 +0000
Subject: [squid-users] test ICAP server
In-Reply-To: <87f9d94f-c88b-467f-8d8a-3f865d0e5a4d@treenet.co.nz>
References: <CALmccy71n_j=P3xHOJHwfqPeZ=pM+32ZhoSiqHHHRKPgYU9BqA@mail.gmail.com>
 <c4ba49c6-6419-4a2e-9e1a-2da10ec44929@measurement-factory.com>
 <CALmccy7DvtVKqv9Hz5YEqHsksw+H051Ujz0zMXOr2TcJzv=FBA@mail.gmail.com>
 <87f9d94f-c88b-467f-8d8a-3f865d0e5a4d@treenet.co.nz>
Message-ID: <CALmccy7hDgmDtv98xj2ek8ERipQKvH9=9UZWftk6mnyA5pn5Gg@mail.gmail.com>

I'm more looking at things like always adding extra headers such as auth
tokens. I want to create some scripts that will go and get things like JWTs
so I can run dumb tools through them and not have to worry about doing it
by hand and then getting the tool to accept extra headers.

And I know there are other ways to do this, but this is more a curiosity
project now, especially as it didn't work first time and there is a new
protocol to learn.

Robin

On Fri, 7 Feb 2025, 21:12 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 8/02/25 04:35, Robin Wood wrote:
> > Hi
> > I wouldn't risk trying to do a production quality one server!
> >
> > I'm a security tester and I want a way to automatically modify traffic
> > that I'm sending to and from sites. I've got plenty of other ways to do
> > it, but as all my testing traffic already goes through a Squid box I
> > just wanted to have a play to see if I could get it to do simple
> > things like add a new header or something like that.
>
> Please be aware that Squid normalizes and performs security sanitization
> on the HTTP messages that it receives. Regardless of whether they are
> arrive from client, server, or ICAP. That means a lot of traffic
> malformation needed for proper security tests will not work at all.
>
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250207/e4a8635d/attachment-0001.htm>

From jonathanlee571 at gmail.com  Fri Feb  7 23:41:40 2025
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 7 Feb 2025 23:41:40 +0000
Subject: [squid-users] To Do List (smart pointer examples)
Message-ID: <DS0PR19MB7270A3499EB6611AC897D07CA7F12@DS0PR19MB7270.namprd19.prod.outlook.com>

Hello Fellow Squid Users,

I am currently a computer science major and I would love to have the honor of helping this project, plus learn at the same time.

Can someone show me an example of doing one of these requests on the to do list? I am currently taking a class that on the syllabus states we are going to learn pointers within Unix this semester.

Leading to, I would like to help with the migration to smart pointers.

Do anyone have an example plus the section of the code on gethub needs all the changes, (I am a student, and the code base is massive) What I am looking for is a single example and I will do more of them.

On Squid's easy to do list it states...


  1.  update a HttpRequest raw pointer to a HttpRequest::Pointer. Including all code performing locking on it
  2.  update a HttpReply raw pointer to a HttpReply::Pointer. Including all code performing locking on it
  3.  update a HttpMsg raw pointer to a HttpMsg::Pointer. Including all code performing locking on it
  4.  update a CBDATA raw pointer to a CbcPointer. Including all code performing validation tests and locking on it.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250207/d807276e/attachment.htm>

From rousskov at measurement-factory.com  Tue Feb 11 22:05:11 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Feb 2025 17:05:11 -0500
Subject: [squid-users] To Do List (smart pointer examples)
In-Reply-To: <DS0PR19MB7270A3499EB6611AC897D07CA7F12@DS0PR19MB7270.namprd19.prod.outlook.com>
References: <DS0PR19MB7270A3499EB6611AC897D07CA7F12@DS0PR19MB7270.namprd19.prod.outlook.com>
Message-ID: <5680db0b-f876-4cf9-abd7-321c93c1bdbc@measurement-factory.com>

On 2025-02-07 18:41, Jonathan Lee wrote:

> Can someone show me an example of doing one of these requests on the to 
> do list?

Please direct future development questions and followups to squid-dev 
mailing list! This squid-users mailing list is meant for Squid operators 
or administrators rather than developers.


> Do anyone have an example plus the section of the code on gethub needs 
> all the changes, (I am a student, and the code base is massive) What I 
> am looking for is a single example and I will do more of them.

These TODOs may be too difficult to implement and test correctly without 
understanding of smart pointers and associated pitfalls, but you can 
look through past git commits to find similar pointer conversion examples:

* f05e4f37: Upgrade ACLFilledChecklist::request to smart Pointer
* 2d5ac435: Do not use raw pointers to index sourcehash CachePeers
* e7959b56: Do not use raw pointers to index CARP CachePeers
* d603e3c2: Cleanup: make Client::request a Pointer
* a0c227a9: Cleanup: convert MemObject::_reply to ReplyPointer
* c43405e7: Cleanup: convert MemObject::request to Pointer

Disclaimer: I have used commit messages to find the examples above. I 
did not revisit each commit to assess whether it is indeed a good 
example for the remaining TODOs quoted below.

If you decide to convert a raw pointer, my recommendation is to start 
with a class data member that is _not_ used in many places, so that you 
do not have to modify a lot of code. However, that recommendation alone 
is probably enough to avoid the pitfalls often present in such conversions!


HTH,

Alex.


> On Squid's easy to do list it states...
> 
>  1. update a /HttpRequest/?raw pointer to a |HttpRequest::Pointer|.
>     Including all code performing locking on it
>  2. update a |HttpReply|?raw pointer to a |HttpReply::Pointer|.
>     Including all code performing locking on it
>  3. update a |HttpMsg|?raw pointer to a |HttpMsg::Pointer|. Including
>     all code performing locking on it
>  4. update a CBDATA raw pointer to a CbcPointer. Including all code
>     performing validation tests and locking on it.



From rafael.akchurin at diladele.com  Wed Feb 12 13:02:38 2025
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 12 Feb 2025 13:02:38 +0000
Subject: [squid-users] Ubuntu 22.04 LTS repository for Squid 6.13 (rebuilt
 from sources in Debian)
Message-ID: <HE1PR0402MB3579E22F887DF2DC535EEE008FFC2@HE1PR0402MB3579.eurprd04.prod.outlook.com>

Hello everyone,

Online repository with latest Squid 6.13 (rebuilt from sources in Debian) for Ubuntu 22.04 LTS 64-bit is available at https://squid613.diladele.com/.
Github repo https://github.com/diladele/squid-ubuntu contains all the scripts we used to make this compilation.

Here are simple instructions how to use the repo. For more information see readme at https://github.com/diladele/squid-ubuntu .

# add diladele apt key
wget -qO - https://packages.diladele.com/diladele_pub.asc | sudo apt-key add -

# add new repo
echo "deb https://squid613.diladele.com/ubuntu/ jammy main" \
    > /etc/apt/sources.list.d/squid613.diladele.com.list

# and install
apt-get update && apt-get install -y \
    squid-common \
    squid-openssl \
    squidclient \
    libecap3 libecap3-dev

# optional - switch to openssl based squid
update-alternatives --set squid /usr/sbin/squid-openssl

This version of Squid will be part of Web Safety 9.4 being released during February 2025.  If you have some spare time and are interested in Admin UI for Squid and ICAP web filtering, consider downloading a Web Safety appliance for VMware ESXi/vSphere<https://packages.diladele.com/websafety-va/9.4/websafety.zip> , Microsoft Hyper-V<https://packages.diladele.com/websafety-va/9.4/websafety-hyperv.zip>, Proxmox<https://packages.diladele.com/websafety-va/9.4/websafety-proxmox.zip> or even deploy it directly on Microsoft Azure<https://azuremarketplace.microsoft.com/en-us/marketplace/apps/diladele.websafety> and Amazon AWS<https://aws.amazon.com/marketplace/pp/prodview-ixvbzugrltcqq>.

Hope you will find this useful.

Best regards,
Rafael Akchurin
Diladele B.V.



-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 19644 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250212/276fc28b/attachment-0001.bin>

From benjamin.delannoy at adeo.com  Mon Feb 17 15:02:45 2025
From: benjamin.delannoy at adeo.com (BENJAMIN DELANNOY)
Date: Mon, 17 Feb 2025 16:02:45 +0100
Subject: [squid-users] Need clarifications on custom log timestamps
Message-ID: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>

Hello !

I try to figure out what is exactly measured with the <pt & <tt timings. I
don't get what are the difference between them, what is the difference
between "peer response time" & "time spent forwarding to origin servers",
what is the "last I/O with the last peer", etc.

For information, I aim to calculate the time spent on the client-side & by
squid processing time,  excluding the server-side time spent (=what I don't
manage).

We do not use squid for caching but only for http & ssl proxy/filtering.

Thanks a lot !


Cordialement, Regards,


Benjamin DELANNOY

Cloud Network Engineer

NETWORK SOLUTIONS - GTDP

Mobile +33 (0)6 16 98 23 72

135 rue Sadi Carnot ? CS 00001 ? 59790 Ronchin ? FRANCE

positivetech.adeo.com

adeolinkedin <https://www.linkedin.com/company/groupe-adeo>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250217/fc2f11c4/attachment.htm>

From rousskov at measurement-factory.com  Mon Feb 17 15:47:27 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Feb 2025 10:47:27 -0500
Subject: [squid-users] Need clarifications on custom log timestamps
In-Reply-To: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
References: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
Message-ID: <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>

On 2025-02-17 10:02, BENJAMIN DELANNOY wrote:

> I try to figure out what is exactly measured with the <pt & <tt timings. 
> I don't get what are the difference between them, what is the difference 
> between "peer response time" & "time spent forwarding to origin 
> servers", 

Have you seen %<pt and %<tt descriptions at [1]? %<tt description was 
updated in August 2024, and squid.conf.documented in Squid v6 and 
earlier does not have those documentation updates (and the corresponding 
bug fixes)...

[1] http://www.squid-cache.org/Doc/config/logformat/


> what is the "last I/O with the last peer", etc.

When forwarding a single client request, Squid may talk to multiple 
cache_peer and origin server addresses (collectively called "peers"). 
Talking to a given peer may include multiple socket reading and writing 
(i.e. I/O) events. Does this clarify?



> For information, I aim to calculate the time spent on the client-side & 
> by squid processing time,? excluding the server-side time spent (=what I 
> don't manage).

This kind of calculation is a common need. Please keep in mind that 
Squid may spend time on the client side (e.g., awaiting the next request 
body byte) while also spending time on the server side (e.g., awaiting 
the next response body byte), complicating things.

If existing %codes are not enough, please detail your needs in terms of 
events that Squid can recognize (e.g., receiving the first response 
header byte or sending the last request body byte).


HTH,

Alex.




> We do not use squid for caching but only for http & ssl proxy/filtering.
> 
> Thanks a lot !
> 
> 
> Cordialement, Regards,
> 
> 
> Benjamin DELANNOY
> 
> Cloud Network Engineer
> 
> NETWORK SOLUTIONS - GTDP
> 
> Mobile +33 (0)6 16 98 23 72
> 
> 
> 135 rue Sadi Carnot ? CS 00001 ? 59790 Ronchin ? FRANCE
> 
> positivetech.adeo.com <https://positivetech.adeo.com/>
> 
> adeolinkedin <https://www.linkedin.com/company/groupe-adeo>
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From cursedboss at gmail.com  Mon Feb 17 21:00:36 2025
From: cursedboss at gmail.com (Cursed Boss)
Date: Tue, 18 Feb 2025 00:00:36 +0300
Subject: [squid-users] Authentication of Domain PC
Message-ID: <CAA64F+OfaFH1oFO7YcSq-WEtsURrq0cc=WsOv127zuPDaztyDA@mail.gmail.com>

Good day. Could you please ask, is it possible to authenticate and give
Internet access via domain computer name.

For example I have group in my AD - PrivateServers. I want all servers in
this group grant access to Internet and it doesn?t matter which users work
on them or from which users the services are running.

I know squid have acl to control which ip addresses can get access, but I
don't know which ips these servers will have. All I know that it is domain
servers and workstations.

If possible how could I reach these?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250218/53471391/attachment.htm>

From mehmedfeyziaktas at gmail.com  Mon Feb 17 22:22:18 2025
From: mehmedfeyziaktas at gmail.com (Mehmed Feyzi Aktas)
Date: Mon, 17 Feb 2025 23:22:18 +0100
Subject: [squid-users] Latency in REST API messages
Message-ID: <CA+EuJCqdrXMDgrWp4x7XAQUMgMj0PU2rJ_TAgExcMu8_UD8Crg@mail.gmail.com>

Dear community,

I set up a proxy server using Squid. From my main server, I use redsocks as
a tunnel to route traffic through my proxy server. Websockets messages
coming from Squid proxy shows expected latency numbers, however, when I
send REST API messages through that channel I observe a very high latency.
What might be the reason for that and can I solve it by configuring Squid
or should I check redsocks configs?

Thank you in advance and your patience.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250217/35a85b97/attachment.htm>

From gkinkie at gmail.com  Tue Feb 18 06:01:12 2025
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Tue, 18 Feb 2025 14:01:12 +0800
Subject: [squid-users] Authentication of Domain PC
In-Reply-To: <CAA64F+OfaFH1oFO7YcSq-WEtsURrq0cc=WsOv127zuPDaztyDA@mail.gmail.com>
References: <CAA64F+OfaFH1oFO7YcSq-WEtsURrq0cc=WsOv127zuPDaztyDA@mail.gmail.com>
Message-ID: <CA+Y8hcNMYwj6To4QxxeLd=ceDykgKxyZENnauet2UBVpmGUwNQ@mail.gmail.com>

Hi,
  it should be possible using an external ACL helper which gets the
IP, queries DNS or AD to get the computer name to IP mapping , and
grants access as appropriate. You'll want to cache the results, but
then be aware that there might improperly give access if a computer
changes IP address.

On Tue, Feb 18, 2025 at 9:47?AM Cursed Boss <cursedboss at gmail.com> wrote:
>
> Good day. Could you please ask, is it possible to authenticate and give Internet access via domain computer name.
>
> For example I have group in my AD - PrivateServers. I want all servers in this group grant access to Internet and it doesn?t matter which users work on them or from which users the services are running.
>
> I know squid have acl to control which ip addresses can get access, but I don't know which ips these servers will have. All I know that it is domain servers and workstations.
>
> If possible how could I reach these?
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco

From ankor2023 at gmail.com  Tue Feb 18 07:28:17 2025
From: ankor2023 at gmail.com (Andrey K)
Date: Tue, 18 Feb 2025 10:28:17 +0300
Subject: [squid-users] Authentication of Domain PC
In-Reply-To: <CA+Y8hcNMYwj6To4QxxeLd=ceDykgKxyZENnauet2UBVpmGUwNQ@mail.gmail.com>
References: <CAA64F+OfaFH1oFO7YcSq-WEtsURrq0cc=WsOv127zuPDaztyDA@mail.gmail.com>
 <CA+Y8hcNMYwj6To4QxxeLd=ceDykgKxyZENnauet2UBVpmGUwNQ@mail.gmail.com>
Message-ID: <CADJd0Y23CQym5YZt=hZiS0TtFpzOHO0U68pXTNpoJ4o51734dQ@mail.gmail.com>

Hello,

> it should be possible using an external ACL helper which gets the
> IP, queries DNS or AD to get the computer name to IP mapping , and
> grants access as appropriate.

This ACL should also make a query to AD LDAP to check if the computer is a
member of the PrivateServers group.
I think this is authorization rather than authentication.

Kind regards,
      Ankor.


??, 18 ????. 2025??. ? 09:12, Francesco Chemolli <gkinkie at gmail.com>:

> Hi,
>   it should be possible using an external ACL helper which gets the
> IP, queries DNS or AD to get the computer name to IP mapping , and
> grants access as appropriate. You'll want to cache the results, but
> then be aware that there might improperly give access if a computer
> changes IP address.
>
> On Tue, Feb 18, 2025 at 9:47?AM Cursed Boss <cursedboss at gmail.com> wrote:
> >
> > Good day. Could you please ask, is it possible to authenticate and give
> Internet access via domain computer name.
> >
> > For example I have group in my AD - PrivateServers. I want all servers
> in this group grant access to Internet and it doesn?t matter which users
> work on them or from which users the services are running.
> >
> > I know squid have acl to control which ip addresses can get access, but
> I don't know which ips these servers will have. All I know that it is
> domain servers and workstations.
> >
> > If possible how could I reach these?
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > https://lists.squid-cache.org/listinfo/squid-users
>
>
>
> --
>     Francesco
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250218/3897b573/attachment.htm>

From cursedboss at gmail.com  Tue Feb 18 08:12:07 2025
From: cursedboss at gmail.com (Cursed Boss)
Date: Tue, 18 Feb 2025 11:12:07 +0300
Subject: [squid-users] Authentication of Domain PC
In-Reply-To: <CA+Y8hcNMYwj6To4QxxeLd=ceDykgKxyZENnauet2UBVpmGUwNQ@mail.gmail.com>
References: <CAA64F+OfaFH1oFO7YcSq-WEtsURrq0cc=WsOv127zuPDaztyDA@mail.gmail.com>
 <CA+Y8hcNMYwj6To4QxxeLd=ceDykgKxyZENnauet2UBVpmGUwNQ@mail.gmail.com>
Message-ID: <CAA64F+O2N_9erL8pkpDL3nNOGtUO+FnjyWxLJf7o6Y4_VVjNvQ@mail.gmail.com>

thanks for the response any idea which helper could do this? find nothing
from Internet.

??, 18 ????. 2025??. ? 09:12, Francesco Chemolli <gkinkie at gmail.com>:

> Hi,
>   it should be possible using an external ACL helper which gets the
> IP, queries DNS or AD to get the computer name to IP mapping , and
> grants access as appropriate. You'll want to cache the results, but
> then be aware that there might improperly give access if a computer
> changes IP address.
>
> On Tue, Feb 18, 2025 at 9:47?AM Cursed Boss <cursedboss at gmail.com> wrote:
> >
> > Good day. Could you please ask, is it possible to authenticate and give
> Internet access via domain computer name.
> >
> > For example I have group in my AD - PrivateServers. I want all servers
> in this group grant access to Internet and it doesn?t matter which users
> work on them or from which users the services are running.
> >
> > I know squid have acl to control which ip addresses can get access, but
> I don't know which ips these servers will have. All I know that it is
> domain servers and workstations.
> >
> > If possible how could I reach these?
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > https://lists.squid-cache.org/listinfo/squid-users
>
>
>
> --
>     Francesco
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250218/806d748a/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Feb 18 10:21:51 2025
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 18 Feb 2025 10:21:51 +0000
Subject: [squid-users] Authentication of Domain PC
In-Reply-To: <CAA64F+O2N_9erL8pkpDL3nNOGtUO+FnjyWxLJf7o6Y4_VVjNvQ@mail.gmail.com>
References: <CAA64F+OfaFH1oFO7YcSq-WEtsURrq0cc=WsOv127zuPDaztyDA@mail.gmail.com>
 <CA+Y8hcNMYwj6To4QxxeLd=ceDykgKxyZENnauet2UBVpmGUwNQ@mail.gmail.com>
 <CAA64F+O2N_9erL8pkpDL3nNOGtUO+FnjyWxLJf7o6Y4_VVjNvQ@mail.gmail.com>
Message-ID: <5f3e468f-59a4-44f3-9d25-859a7d265ad7@urlfilterdb.com>

ufdbGuard supports filtering based on a dynamically updated list of hostnames (with the execdomainlist feature).
See the Reference Manual at https://www.urlfilterdb.com for more information.

Marcus


On 18/02/2025 08:12, Cursed Boss wrote:
> thanks for the response any idea which helper could do this? find nothing from Internet.
>
> ??, 18 ????. 2025??. ? 09:12, Francesco Chemolli <gkinkie at gmail.com>:
>
>     Hi,
>     ? it should be possible using an external ACL helper which gets the
>     IP, queries DNS or AD to get the computer name to IP mapping , and
>     grants access as appropriate. You'll want to cache the results, but
>     then be aware that there might improperly give access if a computer
>     changes IP address.
>
>     On Tue, Feb 18, 2025 at 9:47?AM Cursed Boss <cursedboss at gmail.com> wrote:
>     >
>     > Good day. Could you please ask, is it possible to authenticate and give Internet access via domain computer name.
>     >
>     > For example I have group in my AD - PrivateServers. I want all servers in this group grant access to Internet and it doesn?t matter which users work on them or from which users the services
>     are running.
>     >
>     > I know squid have acl to control which ip addresses can get access, but I don't know which ips these servers will have. All I know that it is domain servers and workstations.
>     >
>     > If possible how could I reach these?
>     > _______________________________________________
>     > squid-users mailing list
>     > squid-users at lists.squid-cache.org
>     > https://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     -- 
>     ? ? Francesco
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     https://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250218/dae882e5/attachment.htm>

From uhlar at fantomas.sk  Tue Feb 18 10:34:09 2025
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 18 Feb 2025 11:34:09 +0100
Subject: [squid-users] Latency in REST API messages
In-Reply-To: <CA+EuJCqdrXMDgrWp4x7XAQUMgMj0PU2rJ_TAgExcMu8_UD8Crg@mail.gmail.com>
References: <CA+EuJCqdrXMDgrWp4x7XAQUMgMj0PU2rJ_TAgExcMu8_UD8Crg@mail.gmail.com>
Message-ID: <Z7RiIZaWqpQRg9lI@fantomas.sk>

On 17.02.25 23:22, Mehmed Feyzi Aktas wrote:
>I set up a proxy server using Squid. From my main server, I use redsocks as
>a tunnel to route traffic through my proxy server. Websockets messages
>coming from Squid proxy shows expected latency numbers, however, when I
>send REST API messages through that channel I observe a very high latency.
>What might be the reason for that and can I solve it by configuring Squid
>or should I check redsocks configs?

I recommend looking to your redsocks log first.
If not, packet capture could explain where the latency comes from.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
I drive way too fast to worry about cholesterol.

From benjamin.delannoy at adeo.com  Wed Feb 19 11:26:50 2025
From: benjamin.delannoy at adeo.com (BENJAMIN DELANNOY)
Date: Wed, 19 Feb 2025 12:26:50 +0100
Subject: [squid-users] Need clarifications on custom log timestamps
In-Reply-To: <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>
References: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
 <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>
Message-ID: <CAPUgoGtWGNSmiji5ObB8Af-oZTabBR3XD0bK2wENwZk8=LPtbg@mail.gmail.com>

Thanks for the answer.

Yes I saw the updates for %<pt and %<tt but I still don't get it.
For %<pt : " The timer starts when the last request byte is sent to the
next hop and stops when the last response byte is received."  Are we
talking of last request / last response of a single TCP connection on
server side ? Do we agree that we are purely talking about request/response
on HTTP, and thus this time does not take into account the time spent with
SSL negotiation / squid actions before ?

For %<tt : I understand that all the time spent sending requests & waiting
responses from the Origin are added. It would also means that if I subtract
this timer to %tr, I would have only the ClientSide time before first
packet is sent to Origin by the squid & after the last packet is received
from the Origin ?

Actually, what I want to monitor, is the time between the first client
packet received on the Squid and the time the squid makes its choice :
- based on SNI for SSL Splice
- based on HTTP ACL (HTTP traffic or HTTPS traffic with SSL Bump)
Based on this, I would be able to check if a squid server is taking too
much time making a decision.

Is this something feasible?


Cordialement, Regards,


Benjamin DELANNOY



On Mon, Feb 17, 2025 at 4:47?PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2025-02-17 10:02, BENJAMIN DELANNOY wrote:
>
> > I try to figure out what is exactly measured with the <pt & <tt timings.
> > I don't get what are the difference between them, what is the difference
> > between "peer response time" & "time spent forwarding to origin
> > servers",
>
> Have you seen %<pt and %<tt descriptions at [1]? %<tt description was
> updated in August 2024, and squid.conf.documented in Squid v6 and
> earlier does not have those documentation updates (and the corresponding
> bug fixes)...
>
> [1] http://www.squid-cache.org/Doc/config/logformat/
>
>
> > what is the "last I/O with the last peer", etc.
>
> When forwarding a single client request, Squid may talk to multiple
> cache_peer and origin server addresses (collectively called "peers").
> Talking to a given peer may include multiple socket reading and writing
> (i.e. I/O) events. Does this clarify?
>
>
>
> > For information, I aim to calculate the time spent on the client-side &
> > by squid processing time,  excluding the server-side time spent (=what I
> > don't manage).
>
> This kind of calculation is a common need. Please keep in mind that
> Squid may spend time on the client side (e.g., awaiting the next request
> body byte) while also spending time on the server side (e.g., awaiting
> the next response body byte), complicating things.
>
> If existing %codes are not enough, please detail your needs in terms of
> events that Squid can recognize (e.g., receiving the first response
> header byte or sending the last request body byte).
>
>
> HTH,
>
> Alex.
>
>
>
>
> > We do not use squid for caching but only for http & ssl proxy/filtering.
> >
> > Thanks a lot !
> >
> >
> > Cordialement, Regards,
> >
> >
> > Benjamin DELANNOY
> >
> > Cloud Network Engineer
> >
> > NETWORK SOLUTIONS - GTDP
> >
> > Mobile +33 (0)6 16 98 23 72
> >
> >
> > 135 rue Sadi Carnot ? CS 00001 ? 59790 Ronchin ? FRANCE
> >
> > positivetech.adeo.com <https://positivetech.adeo.com/>
> >
> > adeolinkedin <https://www.linkedin.com/company/groupe-adeo>
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > https://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250219/642aefd4/attachment.htm>

From rousskov at measurement-factory.com  Wed Feb 19 16:39:34 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 19 Feb 2025 11:39:34 -0500
Subject: [squid-users] Need clarifications on custom log timestamps
In-Reply-To: <CAPUgoGtWGNSmiji5ObB8Af-oZTabBR3XD0bK2wENwZk8=LPtbg@mail.gmail.com>
References: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
 <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>
 <CAPUgoGtWGNSmiji5ObB8Af-oZTabBR3XD0bK2wENwZk8=LPtbg@mail.gmail.com>
Message-ID: <c6adf5db-11e2-456c-9df1-1e1ac3072f9a@measurement-factory.com>

On 2025-02-19 06:26, BENJAMIN DELANNOY wrote:

> For %<pt : "The timer starts when the last request byte is sent to the 
> next hop and stops when the last response byte is received."? Are we 
> talking of last request / last response of a single TCP connection on 
> server side ?

I believe the short answer is "no": If Squid uses multiple TCP 
Squid-peer connections to forward a single client request, then the last 
connection used for that request forwarding should determine overall 
transaction outcome and %<pt values in access.log.


> Do we agree that we are purely talking about 
> request/response on HTTP, and thus this time does not take into account 
> the time spent with SSL negotiation?/ squid actions before ?

I believe the short answer is "yes": Today, %<pt timer starts after the 
HTTP (or FTP) request is written to the peer, so TLS handshake (if any) 
would happen before that timer starts. AFAIK, Squid does not support 
0-RTT TLS.


> For %<tt : I understand that all the time spent?sending?requests & 
> waiting responses from the Origin are added. It would also means that if 
> I subtract this timer to %tr, I would have only the ClientSide time 
> before first packet is sent to Origin by the squid & after the last 
> packet is received from the Origin ?

Yes, but "before" and "after" can be misleading here (in general) 
because there may be periods of time when Squid is _not_ talking to a 
peer but is working on what you call "ClientSide". For example, there is 
code that decides whether to revalidate a received peer response. From 
Squid point of view, that code runs on "ClientSide" -- %<tt timers may 
be stopped when that code runs. Since you are not caching, that 
particular code is not relevant to you.

Also, please keep in mind that a slow client may effectively stall 
Squid-to-peer I/O by not consuming response data fast enough, filling 
Squid response buffers (see read_ahead_gap). If one only looks at "%tr - 
%<tt" difference in such cases, one would observe near-0 values and may 
mistakenly conclude that the slow client is super fast!



> Actually, what I want?to monitor, is the time between the first client 
> packet received on the Squid and the time the squid makes its choice :
> - based on SNI for SSL Splice
> - based on HTTP ACL (HTTP traffic or HTTPS traffic with SSL Bump)
> Based on this, I would be able to check if a squid server is taking too 
> much time making a decision.
> 
> Is this something feasible?

Please detail what you mean by "choice" or "decision". For example, do 
you want to stop the timer when Squid makes its final http_access decision?


Thank you,

Alex.


> On Mon, Feb 17, 2025 at 4:47?PM Alex Rousskov wrote:
> 
>     On 2025-02-17 10:02, BENJAMIN DELANNOY wrote:
> 
>      > I try to figure out what is exactly measured with the <pt & <tt
>     timings.
>      > I don't get what are the difference between them, what is the
>     difference
>      > between "peer response time" & "time spent forwarding to origin
>      > servers",
> 
>     Have you seen %<pt and %<tt descriptions at [1]? %<tt description was
>     updated in August 2024, and squid.conf.documented in Squid v6 and
>     earlier does not have those documentation updates (and the
>     corresponding
>     bug fixes)...
> 
>     [1] http://www.squid-cache.org/Doc/config/logformat/
>     <http://www.squid-cache.org/Doc/config/logformat/>
> 
> 
>      > what is the "last I/O with the last peer", etc.
> 
>     When forwarding a single client request, Squid may talk to multiple
>     cache_peer and origin server addresses (collectively called "peers").
>     Talking to a given peer may include multiple socket reading and writing
>     (i.e. I/O) events. Does this clarify?
> 
> 
> 
>      > For information, I aim to calculate the time spent on the
>     client-side &
>      > by squid processing time,? excluding the server-side time spent
>     (=what I
>      > don't manage).
> 
>     This kind of calculation is a common need. Please keep in mind that
>     Squid may spend time on the client side (e.g., awaiting the next
>     request
>     body byte) while also spending time on the server side (e.g., awaiting
>     the next response body byte), complicating things.
> 
>     If existing %codes are not enough, please detail your needs in terms of
>     events that Squid can recognize (e.g., receiving the first response
>     header byte or sending the last request body byte).
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
> 
> 
>      > We do not use squid for caching but only for http & ssl
>     proxy/filtering.
>      >
>      > Thanks a lot !
>      >
>      >
>      > Cordialement, Regards,
>      >
>      >
>      > Benjamin DELANNOY
>      >
>      > Cloud Network Engineer
>      >
>      > NETWORK SOLUTIONS - GTDP
>      >
>      > Mobile +33 (0)6 16 98 23 72
>      >
>      >
>      > 135 rue Sadi Carnot ? CS 00001 ? 59790 Ronchin ? FRANCE
>      >
>      > positivetech.adeo.com <http://positivetech.adeo.com>
>     <https://positivetech.adeo.com/ <https://positivetech.adeo.com/>>
>      >
>      > adeolinkedin <https://www.linkedin.com/company/groupe-adeo
>     <https://www.linkedin.com/company/groupe-adeo>>
>      >
>      >
>      >
>      > _______________________________________________
>      > squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      > https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
> 
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
> 


From uhlar at fantomas.sk  Thu Feb 20 16:31:51 2025
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 20 Feb 2025 17:31:51 +0100
Subject: [squid-users] squid 6.13 debian package
Message-ID: <Z7dY9xAwSPBwaT26@fantomas.sk>

Hello guys,

I am trying to manually backport squid-6.13 to Debian 12.

looks like newest squid-openssl Pre-Depends: on "squid"
however "squid" is in conflict with "squid-openssl"

Is this a bug in control package or did something change since 6.10
(which I backported successfully)
  ?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Christian Science Programming: "Let God Debug It!".

From squid3 at treenet.co.nz  Sat Feb 22 08:25:33 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 22 Feb 2025 21:25:33 +1300
Subject: [squid-users] squid 6.13 debian package
In-Reply-To: <Z7dY9xAwSPBwaT26@fantomas.sk>
References: <Z7dY9xAwSPBwaT26@fantomas.sk>
Message-ID: <04427622-9d28-4b8b-a25c-118448852b60@treenet.co.nz>

On 21/02/25 05:31, Matus UHLAR - fantomas wrote:
> Hello guys,
> 
> I am trying to manually backport squid-6.13 to Debian 12.
> 
> looks like newest squid-openssl Pre-Depends: on "squid"
> however "squid" is in conflict with "squid-openssl"
> 
> Is this a bug in control package or did something change since 6.10
> (which I backported successfully)
>  ??
> 


That is correct. The Debian 'squid-openssl' package now extends the 
default 'squid' package with OpenSSL support binaries instead of 
replacing everything.


The backport needs to supply both 'squid' and 'squid-openssl' built from 
the 6.13 sources.

Amos


From uhlar at fantomas.sk  Sat Feb 22 09:21:47 2025
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sat, 22 Feb 2025 10:21:47 +0100
Subject: [squid-users] squid 6.13 debian package
In-Reply-To: <04427622-9d28-4b8b-a25c-118448852b60@treenet.co.nz>
References: <Z7dY9xAwSPBwaT26@fantomas.sk>
 <04427622-9d28-4b8b-a25c-118448852b60@treenet.co.nz>
Message-ID: <Z7mXKyaC011jiztw@fantomas.sk>

>On 21/02/25 05:31, Matus UHLAR - fantomas wrote:
>>I am trying to manually backport squid-6.13 to Debian 12.
>>
>>looks like newest squid-openssl Pre-Depends: on "squid"
>>however "squid" is in conflict with "squid-openssl"
>>
>>Is this a bug in control package or did something change since 6.10
>>(which I backported successfully)
>> ??

On 22.02.25 21:25, Amos Jeffries wrote:
>That is correct. The Debian 'squid-openssl' package now extends the 
>default 'squid' package with OpenSSL support binaries instead of 
>replacing everything.
>
>The backport needs to supply both 'squid' and 'squid-openssl' built 
>from the 6.13 sources.

Pre-Depends requires dependent package "squid" (without openssl  support) 
being fully configured before squid-openssl gets installed.

Doesn't that mean that squid will be restarted twice, and first instance 
will run squid without openssl support and thus without required 
functionality?

Thanks.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Spam = (S)tupid (P)eople's (A)dvertising (M)ethod

From squid3 at treenet.co.nz  Sat Feb 22 11:39:20 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 23 Feb 2025 00:39:20 +1300
Subject: [squid-users] squid 6.13 debian package
In-Reply-To: <Z7mXKyaC011jiztw@fantomas.sk>
References: <Z7dY9xAwSPBwaT26@fantomas.sk>
 <04427622-9d28-4b8b-a25c-118448852b60@treenet.co.nz>
 <Z7mXKyaC011jiztw@fantomas.sk>
Message-ID: <6cd95685-a19e-414c-a59d-44be59eaadb0@treenet.co.nz>

On 22/02/25 22:21, Matus UHLAR - fantomas wrote:
>> On 21/02/25 05:31, Matus UHLAR - fantomas wrote:
>>> I am trying to manually backport squid-6.13 to Debian 12.
>>>
>>> looks like newest squid-openssl Pre-Depends: on "squid"
>>> however "squid" is in conflict with "squid-openssl"
>>>
>>> Is this a bug in control package or did something change since 6.10
>>> (which I backported successfully)
>>> ??
> 
> On 22.02.25 21:25, Amos Jeffries wrote:
>> That is correct. The Debian 'squid-openssl' package now extends the 
>> default 'squid' package with OpenSSL support binaries instead of 
>> replacing everything.
>>
>> The backport needs to supply both 'squid' and 'squid-openssl' built 
>> from the 6.13 sources.
> 
> Pre-Depends requires dependent package "squid" (without openssl  
> support) being fully configured before squid-openssl gets installed.
> 
> Doesn't that mean that squid will be restarted twice, and first instance 
> will run squid without openssl support and thus without required 
> functionality?


Maybe, I do not recall what upgrade tests showed for apt output.

AFAIK it should only be restarted once. The 'Conflicts' on older 
squid-openssl packages forces apt/dpkg to treat them as a pair on 
transition.
After transition 'squid' is an alias to whichever is preferred.

Amos


From squid.org at bloms.de  Mon Feb 24 07:14:00 2025
From: squid.org at bloms.de (Dieter Bloms)
Date: Mon, 24 Feb 2025 08:14:00 +0100
Subject: [squid-users] certificate missmatch for https://squid-cache.org/
Message-ID: <jz373ya2l6ivqsza5cd4prihiasz5pgiajogbvv7fhul4xbpwd@ifgefe72won4>

Hello,

There is an A Record entry (104.130.201.120) for squid-cache.org as well as for www.squid-cache.org.
However, there is an error message ?Certificate name mismatch?.
See also https://www.ssllabs.com/ssltest/analyze.html?d=squid-cache.org
Many users enter the destination without www, i.e. ?squid-cache.org? instead of ?www.squid-cache.org?.
Is it possible that the certificate also contains the DNS name ?squid-cache.org??


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.

From gkinkie at gmail.com  Mon Feb 24 08:42:10 2025
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Mon, 24 Feb 2025 16:42:10 +0800
Subject: [squid-users] certificate missmatch for https://squid-cache.org/
In-Reply-To: <jz373ya2l6ivqsza5cd4prihiasz5pgiajogbvv7fhul4xbpwd@ifgefe72won4>
References: <jz373ya2l6ivqsza5cd4prihiasz5pgiajogbvv7fhul4xbpwd@ifgefe72won4>
Message-ID: <CA+Y8hcOwmWhbhNvvnGXbR3-DYe4ijA_nWr1qwyyOrCEDmvFTUw@mail.gmail.com>

Hi Dieter,
  I have refreshed the site certificate, it works for me now. Can you
check it works for you as well?

Thanks

On Mon, Feb 24, 2025 at 3:22?PM Dieter Bloms <squid.org at bloms.de> wrote:
>
> Hello,
>
> There is an A Record entry (104.130.201.120) for squid-cache.org as well as for www.squid-cache.org.
> However, there is an error message ?Certificate name mismatch?.
> See also https://www.ssllabs.com/ssltest/analyze.html?d=squid-cache.org
> Many users enter the destination without www, i.e. ?squid-cache.org? instead of ?www.squid-cache.org?.
> Is it possible that the certificate also contains the DNS name ?squid-cache.org??
>
>
> --
> Regards
>
>   Dieter
>
> --
> I do not get viruses because I do not use MS software.
> If you use Outlook then please do not put my email address in your
> address-book so that WHEN you get a virus it won't use my address in the
> From field.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco

From jyboisiaud-ext at ecritel.net  Mon Feb 24 15:38:54 2025
From: jyboisiaud-ext at ecritel.net (BOISIAUD Jean-Yves)
Date: Mon, 24 Feb 2025 15:38:54 +0000
Subject: [squid-users] ssl-bump with url_regex
Message-ID: <dae32b85c95c4c0e88ff5ed5d71dc473@ecritel.net>

Hello,


I am using Squid 5.7 on a Debian 12 system.


I would like to grant only some given URL path for a site using HTTPS.


For example, in the following configuration:

...

http_port 3128 ssl-bump tcpkeepalive=60,30,3 \
    cert=/etc/squid/certs/signingCA.crt \
    key=/etc/squid/certs/signingCA.key \
    tls-cafile=/etc/squid/certs/chain.pem \
    generate-host-certificates=on \
    dynamic_cert_mem_cache_size=20MB \
    cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS \
    options=NO_TLSv1,NO_SSLv3 \
    tls-dh=prime256v1:/etc/squid/certs/dhparam.pem


acl intermediate_fetching transaction_initiator certificate-fetching

acl SSLBumpSites ssl::server_name www.example.com<http://www.example.com>

acl server src 192.168.1.1

acl path urlpath_regex ^/valid_path/$

...

http_access allow  src path

...

ssl_bump peek all
ssl_bump bump SSLBumpSites
ssl_bump slice all

http_access deny all

cache deny all

Works with http (curl http://www.example.com/valid_path/):
- TCP_MISS/200 467686 GET http://www.example.com/valid_path/ - HIER_DIRECT/151.101.122.132

Does not work with HTTPS (curl https://www.example.com/valid_path/):
- TCP_DENIED/200 0 CONNECT www.example.com:443 - HIER_NONE/- - bump
- NONE_NONE/403 3894 GET https://www.example.com/valid_path/ - HIER_NONE/- text/html -

Other https requests work fine:

- TCP_TUNNEL/200 - splice


What is wrong in my configuration ?


Thank you for your help.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250224/aefd930a/attachment.htm>

From jyboisiaud-ext at ecritel.net  Mon Feb 24 17:22:36 2025
From: jyboisiaud-ext at ecritel.net (BOISIAUD Jean-Yves)
Date: Mon, 24 Feb 2025 17:22:36 +0000
Subject: [squid-users] ssl-bump with url_regex [SOLVED]
In-Reply-To: <dae32b85c95c4c0e88ff5ed5d71dc473@ecritel.net>
References: <dae32b85c95c4c0e88ff5ed5d71dc473@ecritel.net>
Message-ID: <a1a245b79e594054b73a7ab99bffb142@ecritel.net>

Solution:


It is the error message 'TCP_DENIED/200 0 CONNECT' wich showed me the way.


Directive is too restrictive:

http_access deny CONNECT !SSL_ports

It works now with:
http_access allow CONNECT safe_ports

where safe ports are:
80, 443, 1025-65535 (maybe too large)

________________________________
De : squid-users <squid-users-bounces at lists.squid-cache.org> de la part de BOISIAUD Jean-Yves <jyboisiaud-ext at ecritel.net>
Envoy? : lundi 24 f?vrier 2025 16:38
? : squid-users at lists.squid-cache.org
Objet : [squid-users] ssl-bump with url_regex


Hello,


I am using Squid 5.7 on a Debian 12 system.


I would like to grant only some given URL path for a site using HTTPS.


For example, in the following configuration:

...

http_port 3128 ssl-bump tcpkeepalive=60,30,3 \
    cert=/etc/squid/certs/signingCA.crt \
    key=/etc/squid/certs/signingCA.key \
    tls-cafile=/etc/squid/certs/chain.pem \
    generate-host-certificates=on \
    dynamic_cert_mem_cache_size=20MB \
    cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS \
    options=NO_TLSv1,NO_SSLv3 \
    tls-dh=prime256v1:/etc/squid/certs/dhparam.pem


acl intermediate_fetching transaction_initiator certificate-fetching

acl SSLBumpSites ssl::server_name www.example.com<http://www.example.com>

acl server src 192.168.1.1

acl path urlpath_regex ^/valid_path/$

...

http_access allow  src path

...

ssl_bump peek all
ssl_bump bump SSLBumpSites
ssl_bump slice all

http_access deny all

cache deny all

Works with http (curl http://www.example.com/valid_path/):
- TCP_MISS/200 467686 GET http://www.example.com/valid_path/ - HIER_DIRECT/151.101.122.132

Does not work with HTTPS (curl https://www.example.com/valid_path/):
- TCP_DENIED/200 0 CONNECT www.example.com:443 - HIER_NONE/- - bump
- NONE_NONE/403 3894 GET https://www.example.com/valid_path/ - HIER_NONE/- text/html -

Other https requests work fine:

- TCP_TUNNEL/200 - splice


What is wrong in my configuration ?


Thank you for your help.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250224/8c1e0b97/attachment.htm>

From squid.org at bloms.de  Mon Feb 24 17:42:55 2025
From: squid.org at bloms.de (Dieter Bloms)
Date: Mon, 24 Feb 2025 18:42:55 +0100
Subject: [squid-users] certificate missmatch for https://squid-cache.org/
In-Reply-To: <jz373ya2l6ivqsza5cd4prihiasz5pgiajogbvv7fhul4xbpwd@ifgefe72won4>
References: <jz373ya2l6ivqsza5cd4prihiasz5pgiajogbvv7fhul4xbpwd@ifgefe72won4>
Message-ID: <h7b6ogfczfjzur3rtauspk264yajaqjszrx2fns6cep7wipj6h@t5vguf5uopdh>

Hello Francesco,

> I have refreshed the site certificate, it works for me now. Can you
> check it works for you as well?

yes, the certificate is correct now, but the correct content is not
displayed:

"Nothing to see here, for now"

it would be nice if the same content was displayed as at www.squid-cache.org.


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.

From squid3 at treenet.co.nz  Mon Feb 24 20:30:38 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 25 Feb 2025 09:30:38 +1300
Subject: [squid-users] ssl-bump with url_regex [SOLVED]
In-Reply-To: <a1a245b79e594054b73a7ab99bffb142@ecritel.net>
References: <dae32b85c95c4c0e88ff5ed5d71dc473@ecritel.net>
 <a1a245b79e594054b73a7ab99bffb142@ecritel.net>
Message-ID: <3b912f4d-33ab-470a-9bc3-bbb8865f1415@treenet.co.nz>

I do not think this solution is correct.

The SSL_Ports ACL should already contain "443". So the traffic was 
**not** being blocked by this line:
   "deny CONNECT !SSL_Ports"


AFAICS the lack of URL-path details on the CONNECT request was failing 
to match the urlpath_regex ACL.

FYI;

While most of the time we think of Squid access controls as boolean 
conditions, they actually have a tri-state logic (allow, deny, skip).


One option here instead of requiring that path to exist (allow X), is to 
reject invalid paths (deny !X). Like so:

   http_access deny src !path

.. in which case the other access controls later will handle the CONNECT 
requests.


Another option is to allow all CONNECT attempts from the given client. 
Like this:

   http_access deny CONNECT !Safe_ports
   http_access allow CONNECT src

.. in which case you rely on the ssl_bump rules to correctly handle the 
CONNECT, and http_access to correctly handle the decrypted traffic.



Amos


On 25/02/25 06:22, BOISIAUD Jean-Yves wrote:
> Solution:
> 
> 
> It is the error message 'TCP_DENIED/200 0 CONNECT' wich showed me the way.
> 
> 
> Directive?is too restrictive:
> 
> http_access deny CONNECT !SSL_ports
> 
> 
> It works now with:
> http_access allow CONNECT safe_ports
> 
> where safe ports are:
> 80, 443, 1025-65535 (maybe too large)
> 
> ------------------------------------------------------------------------
> *De :* squid-users <squid-users-bounces at lists.squid-cache.org> de la 
> part de BOISIAUD Jean-Yves <jyboisiaud-ext at ecritel.net>
> *Envoy? :* lundi 24 f?vrier 2025 16:38
> *? :* squid-users at lists.squid-cache.org
> *Objet :* [squid-users] ssl-bump with url_regex
> 
> Hello,
> 
> 
> I am using Squid 5.7 on a Debian 12 system.
> 
> 
> I would like to grant only some given URL path for a site using HTTPS.
> 
> 
> For example, in the following configuration:
> 
> ...
> 
> http_port 3128 ssl-bump tcpkeepalive=60,30,3 \
>  ??? cert=/etc/squid/certs/signingCA.crt \
>  ??? key=/etc/squid/certs/signingCA.key \
>  ??? tls-cafile=/etc/squid/certs/chain.pem \
>  ??? generate-host-certificates=on \
>  ??? dynamic_cert_mem_cache_size=20MB \
>  ??? cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS \
>  ??? options=NO_TLSv1,NO_SSLv3 \
>  ??? tls-dh=prime256v1:/etc/squid/certs/dhparam.pem
> 
> acl intermediate_fetching transaction_initiator certificate-fetching
> 
> acl SSLBumpSites ssl::server_name www.example.com <http://www.example.com>
> 
> acl server src 192.168.1.1
> 
> acl path urlpath_regex ^/valid_path/$
> 
> ...
> 
> http_access allow??src path
> 
> ...
> 
> ssl_bump peek all
> ssl_bump bump SSLBumpSites
> ssl_bump slice all
> 
> http_access deny all
> 
> cache deny all
> 
> Works with http (curl http://www.example.com <http://www.example.com>/ 
> valid_path/):
> - TCP_MISS/200 467686 GET http://www.example.com/valid_path/ - 
> HIER_DIRECT/151.101.122.132
> 
> Does not work with HTTPS (curl https://www.example.com/valid_path/ 
> <https://www.example.com/valid_path/>):
> - TCP_DENIED/200 0 CONNECT www.example.com:443 - HIER_NONE/- - bump
> - NONE_NONE/403 3894 GET https://www.example.com/valid_path/ - 
> HIER_NONE/- text/html -
> 
> Other https requests work fine:
> 
> - TCP_TUNNEL/200 - splice
> 
> 
> What is wrong in my configuration ?
> 
> 
> Thank you for your help.
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From kinkie at squid-cache.org  Tue Feb 25 08:54:05 2025
From: kinkie at squid-cache.org (Francesco Chemolli)
Date: Tue, 25 Feb 2025 16:54:05 +0800
Subject: [squid-users] Squid 7.0.1 BETA is available
Message-ID: <CA+Y8hcPcNESQhehzBVP1izzXR5hDT6FcYZGW=-n_yYxxPjb0pA@mail.gmail.com>

The Squid Web Cache team is very pleased to announce the
availability of the Squid 7.0.1 beta release!

This new 7.x series of Squid brings useful new features, changes
and bug fixes over earlier release series

More detailed descriptions of the major new features downloadable
files and release signatures are are available at:
   <https://github.com/squid-cache/squid/releases/tag/SQUID_7_0_1>

Detailed lists of the ./configure build and squid.conf changes can also
be found in the release notes.

This code is released as beta for wider testing purposes and potential
use. There are no more planned alterations to the existing features,
./configure options or squid.conf options for release 7.

We routinely test Squid for compatibility with major Operating Systems
and hardware platforms, including most current Linux distributions,
FreeBSD, OpenBSD, and MacOS/Homebrew


Major features dropped:

 * Edge Side Include (ESI): no longer used widely enough to justify
   the ongoing effort of maintaining it
 * ident protocol: an insecure relic of earlier Internet days
 * cache_object protocol support: replaced by HTTP and the well-known
   URL prefix /squid-internal-mgr/
 * 'cachemgr.cgi', 'purge' and 'squidclient' tools: their functions can
   now be implemented using standard HTTP clients such as curl


Changes in distribution channels:

Squid is no longer distributed via ftp or rsync.
The only channel for releases is now github, at the URL:
   <https://github.com/squid-cache/squid/releases/tag/SQUID_7_0_1>


We encourage early adopters and testers to try this version out
and provide feedback about bugs and issues at
   <https://bugs.squid-cache.org/>

    Francesco Chemolli

From Foxy_Lady_1966 at proton.me  Tue Feb 25 10:59:18 2025
From: Foxy_Lady_1966 at proton.me (Foxy Lady)
Date: Tue, 25 Feb 2025 10:59:18 +0000
Subject: [squid-users] Clients Header User-Agent replace?
Message-ID: <zUOQDX3qr6uUCGJd8o11UaThl2WB2OZkXa11yZu7n5e1M2zwCy5xlxyT_WwQg2gR9GWSyjG83xYZXDRxMo4fyg-ocIM53QlfLW4opfe9Omg=@proton.me>

Hi all.
Can't figure out how to remove original clients UA from calls.
Tried out something like,

#USER AGENT
header_access Allow allow all
header_access Authorization allow all
header_access Cache-Control allow all
header_access Content-Encoding allow all
header_access Content-Length allow all
header_access Content-Type allow all
header_access Date allow all
header_access Expires allow all
header_access Host allow all
header_access If-Modified-Since allow all
header_access Last-Modified allow all
header_access Location allow all
header_access Pragma allow all
header_access Accept allow all
header_access Accept-Enncoding allow all
header_access Accept-Language allow all
header_access Content-Language allow all
header_access Mime-Version allow all
header_access Cookie allow all
header_access Set_Cookie allow all
header_access Retry-After allow all
header_access Title allow all
header_access Connection allow all
header_access Proxy-Connection allow all
request_header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)
header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)

But it doesn't work.
Original client(s) UA always arrives to WebApplication.

Any solution?

Thanks.


Inviato con l'email sicura Proton Mail.

From benjamin.delannoy at adeo.com  Tue Feb 25 11:33:24 2025
From: benjamin.delannoy at adeo.com (BENJAMIN DELANNOY)
Date: Tue, 25 Feb 2025 12:33:24 +0100
Subject: [squid-users] Need clarifications on custom log timestamps
In-Reply-To: <c6adf5db-11e2-456c-9df1-1e1ac3072f9a@measurement-factory.com>
References: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
 <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>
 <CAPUgoGtWGNSmiji5ObB8Af-oZTabBR3XD0bK2wENwZk8=LPtbg@mail.gmail.com>
 <c6adf5db-11e2-456c-9df1-1e1ac3072f9a@measurement-factory.com>
Message-ID: <CAPUgoGtZPb3rpufJDrxKpFr6KL9MAEY_dprxTx-UufqUmFs6oQ@mail.gmail.com>

> Please detail what you mean by "choice" or "decision". For example, do
> you want to stop the timer when Squid makes its final http_access
decision?

I mean I want to monitor the latency on what I could manage : the
communication between client & squid, the time squid uses to process
requests. But not the time spent by the destination server as I don't
manage it.
This could be multiple monitors if 1 is too complicated or not possible. So
yes for example a timer that stop when Squid makes its final http_access
decision (in case of http or bumped https) or its final ssl_bump splice
decision.

Thanks a lot for your time !


Cordialement, Regards,


Benjamin DELANNOY

On Wed, Feb 19, 2025 at 5:39?PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2025-02-19 06:26, BENJAMIN DELANNOY wrote:
>
> > For %<pt : "The timer starts when the last request byte is sent to the
> > next hop and stops when the last response byte is received."  Are we
> > talking of last request / last response of a single TCP connection on
> > server side ?
>
> I believe the short answer is "no": If Squid uses multiple TCP
> Squid-peer connections to forward a single client request, then the last
> connection used for that request forwarding should determine overall
> transaction outcome and %<pt values in access.log.
>
>
> > Do we agree that we are purely talking about
> > request/response on HTTP, and thus this time does not take into account
> > the time spent with SSL negotiation / squid actions before ?
>
> I believe the short answer is "yes": Today, %<pt timer starts after the
> HTTP (or FTP) request is written to the peer, so TLS handshake (if any)
> would happen before that timer starts. AFAIK, Squid does not support
> 0-RTT TLS.
>
>
> > For %<tt : I understand that all the time spent sending requests &
> > waiting responses from the Origin are added. It would also means that if
> > I subtract this timer to %tr, I would have only the ClientSide time
> > before first packet is sent to Origin by the squid & after the last
> > packet is received from the Origin ?
>
> Yes, but "before" and "after" can be misleading here (in general)
> because there may be periods of time when Squid is _not_ talking to a
> peer but is working on what you call "ClientSide". For example, there is
> code that decides whether to revalidate a received peer response. From
> Squid point of view, that code runs on "ClientSide" -- %<tt timers may
> be stopped when that code runs. Since you are not caching, that
> particular code is not relevant to you.
>
> Also, please keep in mind that a slow client may effectively stall
> Squid-to-peer I/O by not consuming response data fast enough, filling
> Squid response buffers (see read_ahead_gap). If one only looks at "%tr -
> %<tt" difference in such cases, one would observe near-0 values and may
> mistakenly conclude that the slow client is super fast!
>
>
>
> > Actually, what I want to monitor, is the time between the first client
> > packet received on the Squid and the time the squid makes its choice :
> > - based on SNI for SSL Splice
> > - based on HTTP ACL (HTTP traffic or HTTPS traffic with SSL Bump)
> > Based on this, I would be able to check if a squid server is taking too
> > much time making a decision.
> >
> > Is this something feasible?
>
> Please detail what you mean by "choice" or "decision". For example, do
> you want to stop the timer when Squid makes its final http_access decision?
>
>
> Thank you,
>
> Alex.
>
>
> > On Mon, Feb 17, 2025 at 4:47?PM Alex Rousskov wrote:
> >
> >     On 2025-02-17 10:02, BENJAMIN DELANNOY wrote:
> >
> >      > I try to figure out what is exactly measured with the <pt & <tt
> >     timings.
> >      > I don't get what are the difference between them, what is the
> >     difference
> >      > between "peer response time" & "time spent forwarding to origin
> >      > servers",
> >
> >     Have you seen %<pt and %<tt descriptions at [1]? %<tt description was
> >     updated in August 2024, and squid.conf.documented in Squid v6 and
> >     earlier does not have those documentation updates (and the
> >     corresponding
> >     bug fixes)...
> >
> >     [1] http://www.squid-cache.org/Doc/config/logformat/
> >     <http://www.squid-cache.org/Doc/config/logformat/>
> >
> >
> >      > what is the "last I/O with the last peer", etc.
> >
> >     When forwarding a single client request, Squid may talk to multiple
> >     cache_peer and origin server addresses (collectively called "peers").
> >     Talking to a given peer may include multiple socket reading and
> writing
> >     (i.e. I/O) events. Does this clarify?
> >
> >
> >
> >      > For information, I aim to calculate the time spent on the
> >     client-side &
> >      > by squid processing time,  excluding the server-side time spent
> >     (=what I
> >      > don't manage).
> >
> >     This kind of calculation is a common need. Please keep in mind that
> >     Squid may spend time on the client side (e.g., awaiting the next
> >     request
> >     body byte) while also spending time on the server side (e.g.,
> awaiting
> >     the next response body byte), complicating things.
> >
> >     If existing %codes are not enough, please detail your needs in terms
> of
> >     events that Squid can recognize (e.g., receiving the first response
> >     header byte or sending the last request body byte).
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >
> >
> >      > We do not use squid for caching but only for http & ssl
> >     proxy/filtering.
> >      >
> >      > Thanks a lot !
> >      >
> >      >
> >      > Cordialement, Regards,
> >      >
> >      >
> >      > Benjamin DELANNOY
> >      >
> >      > Cloud Network Engineer
> >      >
> >      > NETWORK SOLUTIONS - GTDP
> >      >
> >      > Mobile +33 (0)6 16 98 23 72
> >      >
> >      >
> >      > 135 rue Sadi Carnot ? CS 00001 ? 59790 Ronchin ? FRANCE
> >      >
> >      > positivetech.adeo.com <http://positivetech.adeo.com>
> >     <https://positivetech.adeo.com/ <https://positivetech.adeo.com/>>
> >      >
> >      > adeolinkedin <https://www.linkedin.com/company/groupe-adeo
> >     <https://www.linkedin.com/company/groupe-adeo>>
> >      >
> >      >
> >      >
> >      > _______________________________________________
> >      > squid-users mailing list
> >      > squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >      > https://lists.squid-cache.org/listinfo/squid-users
> >     <https://lists.squid-cache.org/listinfo/squid-users>
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     https://lists.squid-cache.org/listinfo/squid-users
> >     <https://lists.squid-cache.org/listinfo/squid-users>
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250225/d759fb9e/attachment.htm>

From tpal at numen.mg  Tue Feb 25 14:47:14 2025
From: tpal at numen.mg (Thomas PALFRAY)
Date: Tue, 25 Feb 2025 14:47:14 +0000
Subject: [squid-users] Squid 6 with ssl-bump doesn't cache binary
 content over 100 kb
In-Reply-To: <69d416c9ca9e4355b97e3856cd41ad15@numen.mg>
References: <69d416c9ca9e4355b97e3856cd41ad15@numen.mg>
Message-ID: <050734f96a8c4d2d919b2cdcc82dfaf5@numen.mg>

Hello Alex,

>If you have not tested v6.13, please do.

Thanks for your first reply, we tried version 6.13 as recommended, but the behavior is the same.
What additional information would you need to understand the the problem and correct our config file ?

BR,

Thomas PALFRAY

De : squid-users <squid-users-bounces at lists.squid-cache.org> De la part de Thomas PALFRAY
Envoy? : lundi 3 f?vrier 2025 17:08
? : squid-users at lists.squid-cache.org
Objet : [squid-users] Squid 6 with ssl-bump doesn't cache binary content over 100 kb


Hello everyone,



My team and I are working on setting up a squid with ssl-bump to cache binary content (jpeg, png, pdf and json) on a remote site over HTTPS.

The size of the binary content can vary from a few dozen KB to several hundred MB.



We had a working HTTP configuration under squid 3.14, but for security reasons, all our links must now go through HTTPS.



We've tried configuring Squid 5 and Squid 6, but the behavior described below is the same for both versions of the tool.



In fact, we're seeing 200/TCP_MISS_ABORTED codes for content larger than around 100kb.

When content sizes are smaller, the expected behaviour occurs and data is returned from the cache.



On the client side, for content larger than 100kb :

  *   squid 5 returns x-cache = "MISS" and x-cache-lookup = "HIT".
  *   squid 6 returns cache-status = "url;detail=match", which is equivalent if my understanding is correct.



We first thought it might be linked to the following bug: https://bugs.squid-cache.org/show_bug.cgi?id=5214, which encouraged us to try version 6, but without success.



  *   Is it a configuration problem that we missed?
  *   Can you help us ?



HTTP client-side headers returned by squid 6 :



[2025-01-14T08:46:49.875] [TRACE] default - [0/1] getContentStream (user) header: {

  "date": "Tue, 14 Jan 2025 05:47:30 GMT",

  "server": "Apache-Chemistry-OpenCMIS/1.2.0_1859862-XXXXX-1",

  "strict-transport-security": "max-age=15768000",

  "x-xss-protection": "1; mode=block",

  "x-frame-options": "SAMEORIGIN",

  "x-content-type-options": "nosniff",

  "access-control-allow-origin": "*",

  "access-control-expose-headers": "Content-Disposition",

  "cache-control": "public, s-maxage=3600, must-revalidate",

  "etag": "\"08bd240128b475722db82d36c7ae7f164c37cab4ad2480abae052875fe7bc3bfdfef9996197d40110a13208d39a3db3a789879bc31803c82f25211eeba505455\"",

  "content-disposition": "inline; filename=FILENAME.jpg",

  "content-type": "image/jpeg",

  "content-length": "2069587",

  "content-security-policy": "default-src 'none'; connect-src 'self'; font-src 'self' fonts.gstatic.com; img-src blob: 'self'; script-src 'self' 'unsafe-eval' 'unsafe-inline'; style-src 'self' 'unsafe-inline' fonts.googleapis.com",

  "cache-status": "sv-infra-pxy4;detail=match",

  "via": "1.1 sv-infra-pxy4 (squid/6.10)",

  "connection": "close"

}

[2025-01-14T08:46:49.875] [INFO] default - [0/1][2] getCS oId:'369926' sId:'80669' name:' filename= FILENAME.jpg' type:'image/jpeg' size:'2021.08ko' res:[via:true hit:false length:true]





squid 6 acces.log extract:



[cid:image001.png at 01DB87AD.4D373FC0]



full server configuration file :



acl localnet src 0.0.0.1-0.255.255.255        # RFC 1122 "this" network (LAN)

acl localnet src 10.0.0.0/8                   # RFC 1918 local private network (LAN)

acl localnet src 100.64.0.0/10                           # RFC 6598 shared address space (CGN)

acl localnet src 169.254.0.0/16        # RFC 3927 link-local (directly plugged) machines

acl localnet src 172.16.0.0/12                           # RFC 1918 local private network (LAN)

acl localnet src 192.168.0.0/16                        # RFC 1918 local private network (LAN)

acl localnet src fc00::/7         # RFC 4193 local private network range

acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines



acl SSL_ports port 443

acl Safe_ports port 80                              # http

acl Safe_ports port 21                              # ftp

acl Safe_ports port 443                           # https

acl Safe_ports port 70                              # gopher

acl Safe_ports port 210                           # wais

acl Safe_ports port 1025-65535       # unregistered ports

acl Safe_ports port 280                           # http-mgmt

acl Safe_ports port 488                           # gss-http

acl Safe_ports port 591                           # filemaker

acl Safe_ports port 777                           # multiling http



#ACL pour SmartGED

acl smartged-mime req_mime_type -i ^image/jpeg$

acl smartged-mime req_mime_type -i ^image/png$

acl smartged-mime req_mime_type -i ^application/pdf$

acl smartged-mime req_mime_type -i ^application/json$



acl intermediate_fetching transaction_initiator certificate-fetching



http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports



# Only allow cachemgr access from localhost

http_access allow localhost manager

http_access deny manager

http_access allow localnet

http_access deny all



logformat toto %{%d/%b/%Y:%H:%M:%S}tl.%tu %>a %rm %03Hs/%Ss %6tr %ru %mt



access_log /var/log/squid/access.log toto



http_port 3128  ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB tls-cert=/etc/squid/ssl_cert/xxxx_.pem tls-key=/etc/squid/ssl_cert/xxxx_.key tls-dh=/etc/squid/ssl_cert/dhparam.pem

tls_outgoing_options cipher=ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384

sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/spool/squid/ssl_db -M 20MB

sslcrtd_children 5

ssl_bump server-first all

ssl_bump splice all

sslproxy_cert_error allow all



# ACL deny pour les fichiers javascript

acl denyjs urlpath_regex \.js

# ok deny all requests above

cache deny denyjs



# Leave coredumps in the first cache dir

coredump_dir /cache1/squid



# Affichage des requetes GET completes dans cache.log

strip_query_terms off



cache_mem 20480 MB

# d?but d'?viction du cache

cache_swap_low 50

# aggressivit? maximal de l'algorithme d'?viction du cache

cache_swap_high 80

# The LRU policies keeps recently referenced objects.

cache_replacement_policy lru



#

# Add any of your own refresh_pattern entries above these.

#

refresh_pattern ^ftp:                1440    20%     10080

refresh_pattern -i (/cgi-bin/|\?) 0       0%        0

refresh_pattern .                          0             20%     4320



ftp_user anonymous at xxx.fr<mailto:anonymous at xxx.fr>

#acl QUERY urlpath_regex cgi-bin \?

#no_cache deny QUERY

client_request_buffer_max_size 10240 KB

maximum_object_size 1024 MB

# to keep object in memory cache

maximum_object_size_in_memory 10240 KB

#to cause Squid to prefetch the whole file

range_offset_limit 16 MB

#quick_abort_min -1

#D?finition de la taille maximum d'un en-t?te HTTP lors d'une requ?te

reply_header_max_size 8192 KB

#taille maximum d'un en-t?te de r?ponse HTTP

reply_header_max_size 8192 KB



# Uncomment and adjust the following to add a disk cache directory.

cache_dir aufs /cache1/squid 1024000 16 256 max-size=16777216





error_directory /usr/share/squid/errors/fr

half_closed_clients off

max_filedescriptors 8192

forward_max_tries 50



#Affichage du store-id

cache_store_log daemon:/var/log/squid/store_daemon.log

cache_store_log stdio:/var/log/squid/store_stdio.log

#debug_options "ALL,3 33,7 47,7 61,7 85,7"

# Log all critical and important messages.

#debug_options ALL,1

debug_options ALL,3



# Enable SQUID's SNMP

snmp_port 3401

acl snmppublic snmp_community PASdePUBLIC

snmp_access allow snmppublic all

Best regards,

Thomas PALFRAY
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250225/a3f4a87e/attachment-0001.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 43281 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250225/a3f4a87e/attachment-0001.png>

From rousskov at measurement-factory.com  Tue Feb 25 14:56:21 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 25 Feb 2025 09:56:21 -0500
Subject: [squid-users] Squid 6 with ssl-bump doesn't cache binary
 content over 100 kb
In-Reply-To: <050734f96a8c4d2d919b2cdcc82dfaf5@numen.mg>
References: <69d416c9ca9e4355b97e3856cd41ad15@numen.mg>
 <050734f96a8c4d2d919b2cdcc82dfaf5@numen.mg>
Message-ID: <85452ce2-c395-4f54-b602-c1f906378efb@measurement-factory.com>

On 2025-02-25 09:47, Thomas PALFRAY wrote:

> we tried version 6.13 as recommended, but the behavior is the same.

Thank you for testing v6.13. That test eliminates many suspects.


> What additional information would you need to understand the the problem 

For the next step in triage, I can offer a free private review of your 
cache.log file collected while reproducing the problem using as few 
transactions as possible and enabling full debugging (e.g., setting 
debug_options to ALL,9). More hints are available at
https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction

If you would like to proceed with the above analysis, please email me a 
link to the corresponding compressed cache.log.


Thank you,

Alex.


> *De?:*squid-users <squid-users-bounces at lists.squid-cache.org> *De la 
> part de* Thomas PALFRAY
> *Envoy??:* lundi 3 f?vrier 2025 17:08
> *??:* squid-users at lists.squid-cache.org
> *Objet?:* [squid-users] Squid 6 with ssl-bump doesn't cache binary 
> content over 100 kb
> 
> Hello everyone,
> 
> My team and I are working on setting up *a squid with ssl-bump* to cache 
> binary content (jpeg, png, pdf and json) on a remote site over HTTPS.
> 
> The size of the binary content can vary from a few dozen KB to several 
> hundred MB.
> 
> We had a working HTTP configuration under squid 3.14, but for security 
> reasons, all our links must now go through HTTPS.
> 
> We've tried configuring Squid 5 and Squid 6, but the behavior described 
> below is the same for both versions of the tool.
> 
> In fact, we're seeing 200/TCP_MISS_ABORTED codes for content larger than 
> around 100kb.
> 
> When content sizes are smaller, the expected behaviour occurs and data 
> is returned from the cache.
> 
> On the client side, for content larger than 100kb :
> 
>   * squid 5 returns x-cache = ?MISS? and x-cache-lookup = ?HIT?.
>   * squid 6 returns cache-status = ?url;detail=match?, which is
>     equivalent if my understanding is correct.
> 
> We first thought it might be linked to the following bug: 
> _https://bugs.squid-cache.org/show_bug.cgi?id=5214 
> <https://bugs.squid-cache.org/show_bug.cgi?id=5214>_, which encouraged 
> us to try version 6, but without success.
> 
>   * Is it a configuration problem that we missed?
>   * Can you help us ?
> 
> HTTP client-side headers returned by squid 6 :
> 
> //
> 
> /[2025-01-14T08:46:49.875] [TRACE] default - [0/1] getContentStream 
> (user) header: {/
> 
> /? "date": "Tue, 14 Jan 2025 05:47:30 GMT",/
> 
> /? "server": "Apache-Chemistry-OpenCMIS/1.2.0_1859862-XXXXX-1",/
> 
> /? "strict-transport-security": "max-age=15768000",/
> 
> /"x-xss-protection": "1; mode=block",/
> 
> ///"x-frame-options": "SAMEORIGIN",/
> 
> /? "x-content-type-options": "nosniff",/
> 
> /? "access-control-allow-origin": "*",/
> 
> /? "access-control-expose-headers": "Content-Disposition",/
> 
> /? "cache-control": "public, s-maxage=3600, must-revalidate",/
> 
> /? "etag": 
> "\"08bd240128b475722db82d36c7ae7f164c37cab4ad2480abae052875fe7bc3bfdfef9996197d40110a13208d39a3db3a789879bc31803c82f25211eeba505455\"",/
> 
> /? "content-disposition": "inline; filename=FILENAME.jpg",/
> 
> /? "content-type": "image/jpeg",/
> 
> /? "content-length": "2069587",/
> 
> /? "content-security-policy": "default-src 'none'; connect-src 'self'; 
> font-src 'self' fonts.gstatic.com; img-src blob: 'self'; script-src 
> 'self' 'unsafe-eval' 'unsafe-inline'; style-src 'self' 'unsafe-inline' 
> fonts.googleapis.com",/
> 
> */? "cache-status": "sv-infra-pxy4;detail=match",/*
> 
> */"via": "1.1 sv-infra-pxy4 (squid/6.10)",/*
> 
> ///"connection": "close"/
> 
> /}/
> 
> /[2025-01-14T08:46:49.875] [INFO] default - [0/1][2] getCS oId:'369926' 
> sId:*'80669'*name:' filename= FILENAME.jpg' type:'image/jpeg' 
> size:*'2021.08ko'*res:[via:true hit:false length:true]/
> 
> //
> 
> //
> 
> squid 6 acces.log extract:
> 
> //
> 
> //
> 
> //
> 
> full server configuration file :
> 
> //
> 
> /acl localnet src 0.0.0.1-0.255.255.255??????? # RFC 1122 "this" network 
> (LAN)/
> 
> /acl localnet src 10.0.0.0/8?????????????????? # RFC 1918 local private 
> network (LAN)/
> 
> /acl localnet src 100.64.0.0/10?????????????????????????? # RFC 6598 
> shared address space (CGN)/
> 
> /acl localnet src 169.254.0.0/16 ?????? # RFC 3927 link-local (directly 
> plugged) machines/
> 
> /acl localnet src 172.16.0.0/12?????????????????????????? # RFC 1918 
> local private network (LAN)/
> 
> /acl localnet src 192.168.0.0/16??????????????????????? # RFC 1918 local 
> private network (LAN)/
> 
> /acl localnet src fc00::/7?????? ? # RFC 4193 local private network range/
> 
> /acl localnet src fe80::/10????? # RFC 4291 link-local (directly 
> plugged) machines/
> 
> //
> 
> /acl SSL_ports port 443/
> 
> /acl Safe_ports port 80????????????????????????????? # http/
> 
> /acl Safe_ports port 21????????????????????????????? # ftp/
> 
> /acl Safe_ports port 443?????????????????????????? # https/
> 
> /acl Safe_ports port 70????????????????????????????? # gopher/
> 
> /acl Safe_ports port 210?????????????????????????? # wais/
> 
> /acl Safe_ports port 1025-65535?????? # unregistered ports/
> 
> /acl Safe_ports port 280?????????????????????????? # http-mgmt/
> 
> /acl Safe_ports port 488?????????????????????????? # gss-http/
> 
> /acl Safe_ports port 591?????????????????????????? # filemaker/
> 
> /acl Safe_ports port 777?????????????????????????? # multiling http/
> 
> //
> 
> /#ACL pour SmartGED/
> 
> /acl smartged-mime req_mime_type -i ^image/jpeg$/
> 
> /acl smartged-mime req_mime_type -i ^image/png$/
> 
> /acl smartged-mime req_mime_type -i ^application/pdf$/
> 
> /acl smartged-mime req_mime_type -i ^application/json$/
> 
> //
> 
> /acl intermediate_fetching transaction_initiator certificate-fetching/
> 
> //
> 
> /http_access deny !Safe_ports/
> 
> /http_access deny CONNECT !SSL_ports/
> 
> //
> 
> /# Only allow cachemgr access from localhost/
> 
> /http_access allow localhost manager/
> 
> /http_access deny manager/
> 
> /http_access allow localnet/
> 
> /http_access deny all/
> 
> //
> 
> /logformat toto %{%d/%b/%Y:%H:%M:%S}tl.%tu %>a %rm %03Hs/%Ss %6tr %ru %mt/
> 
> //
> 
> /access_log /var/log/squid/access.log toto/
> 
> //
> 
> /http_port 3128? ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=4MB tls-cert=/etc/squid/ssl_cert/xxxx_.pem 
> tls-key=/etc/squid/ssl_cert/xxxx_.key 
> tls-dh=/etc/squid/ssl_cert/dhparam.pem/
> 
> /tls_outgoing_options 
> cipher=ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384/
> 
> /sslcrtd_program /usr/lib/squid/security_file_certgen -s 
> /var/spool/squid/ssl_db -M 20MB/
> 
> /sslcrtd_children 5/
> 
> /ssl_bump server-first all/
> 
> /ssl_bump splice all/
> 
> /sslproxy_cert_error allow all/
> 
> //
> 
> /# ACL deny pour les fichiers javascript/
> 
> /acl denyjs urlpath_regex \.js/
> 
> /# ok deny all requests above/
> 
> /cache deny denyjs/
> 
> //
> 
> /# Leave coredumps in the first cache dir/
> 
> /coredump_dir /cache1/squid/
> 
> //
> 
> /# Affichage des requetes GET completes dans cache.log/
> 
> /strip_query_terms off/
> 
> //
> 
> /cache_mem 20480 MB/
> 
> /# d?but d'?viction du cache/
> 
> /cache_swap_low 50/
> 
> /# aggressivit? maximal de l'algorithme d'?viction du cache/
> 
> /cache_swap_high 80/
> 
> /# The LRU policies keeps recently referenced objects./
> 
> /cache_replacement_policy lru/
> 
> //
> 
> /#/
> 
> /# Add any of your own refresh_pattern entries above these./
> 
> /#/
> 
> /refresh_pattern ^ftp:??????????????? 1440??? 20%???? 10080/
> 
> /refresh_pattern -i (/cgi-bin/|\?) 0?????? 0%??????? 0/
> 
> /refresh_pattern .????????????????????????? 0???????????? 20%???? 4320/
> 
> //
> 
> /ftp_user _anonymous at xxx.fr <mailto:anonymous at xxx.fr>_/
> 
> /#acl QUERY urlpath_regex cgi-bin \?/
> 
> /#no_cache deny QUERY/
> 
> /client_request_buffer_max_size 10240 KB/
> 
> /maximum_object_size 1024 MB/
> 
> /# to keep object in memory cache/
> 
> /maximum_object_size_in_memory 10240 KB/
> 
> /#to cause Squid to prefetch the whole file/
> 
> /range_offset_limit 16 MB/
> 
> /#quick_abort_min -1/
> 
> /#D?finition de la taille maximum d'un en-t?te HTTP lors d'une requ?te/
> 
> /reply_header_max_size 8192 KB/
> 
> /#taille maximum d'un en-t?te de r?ponse HTTP/
> 
> /reply_header_max_size 8192 KB/
> 
> //
> 
> /# Uncomment and adjust the following to add a disk cache directory./
> 
> /cache_dir aufs /cache1/squid 1024000 16 256 max-size=16777216/
> 
> //
> 
> //
> 
> /error_directory /usr/share/squid/errors/fr/
> 
> /half_closed_clients off/
> 
> /max_filedescriptors 8192/
> 
> /forward_max_tries 50/
> 
> //
> 
> /#Affichage du store-id/
> 
> /cache_store_log daemon:/var/log/squid/store_daemon.log/
> 
> /cache_store_log stdio:/var/log/squid/store_stdio.log/
> 
> /#debug_options "ALL,3 33,7 47,7 61,7 85,7"/
> 
> /# Log all critical and important messages./
> 
> /#debug_options ALL,1/
> 
> /debug_options ALL,3/
> 
> //
> 
> /# Enable SQUID's SNMP/
> 
> /snmp_port 3401/
> 
> /acl snmppublic snmp_community PASdePUBLIC/
> 
> /snmp_access allow snmppublic all/
> 
> Best regards,
> 
> *Thomas PALFRAY*
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Tue Feb 25 16:57:33 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 25 Feb 2025 11:57:33 -0500
Subject: [squid-users] Squid 6 with ssl-bump doesn't cache binary
 content over 100 kb
In-Reply-To: <85452ce2-c395-4f54-b602-c1f906378efb@measurement-factory.com>
References: <69d416c9ca9e4355b97e3856cd41ad15@numen.mg>
 <050734f96a8c4d2d919b2cdcc82dfaf5@numen.mg>
 <85452ce2-c395-4f54-b602-c1f906378efb@measurement-factory.com>
Message-ID: <c614d620-2f8a-4504-acfd-7f5fbf3c741b@measurement-factory.com>

On 2025-02-25 09:56, Alex Rousskov wrote:
> On 2025-02-25 09:47, Thomas PALFRAY wrote:
> 
>> we tried version 6.13 as recommended, but the behavior is the same.
> 
> Thank you for testing v6.13. That test eliminates many suspects.
> 
> 
>> What additional information would you need to understand the the problem 
> 
> For the next step in triage, I can offer a free private review of your 
> cache.log file collected while reproducing the problem

Thank you for sharing those logs.

AFAICT, the client just closes its TCP connection to Squid after Squid 
successfully sends that client a few HTTP response parts. There are no 
I/O or TLS errors associated with that TCP closure. There are no visible 
timeouts either. Squid has successfully bumped that connection earlier. 
On Squid side, I see no signs of trouble before that client-initiated 
closure. FWIW, the client essentially violates TLS and HTTP protocols by 
closing the connection like that.

Do you control or have access to the client? We need to figure out why 
that client is closing its connection while receiving Squid responses.

Alex.


>> *De?:*squid-users <squid-users-bounces at lists.squid-cache.org> *De la 
>> part de* Thomas PALFRAY
>> *Envoy??:* lundi 3 f?vrier 2025 17:08
>> *??:* squid-users at lists.squid-cache.org
>> *Objet?:* [squid-users] Squid 6 with ssl-bump doesn't cache binary 
>> content over 100 kb
>>
>> Hello everyone,
>>
>> My team and I are working on setting up *a squid with ssl-bump* to 
>> cache binary content (jpeg, png, pdf and json) on a remote site over 
>> HTTPS.
>>
>> The size of the binary content can vary from a few dozen KB to several 
>> hundred MB.
>>
>> We had a working HTTP configuration under squid 3.14, but for security 
>> reasons, all our links must now go through HTTPS.
>>
>> We've tried configuring Squid 5 and Squid 6, but the behavior 
>> described below is the same for both versions of the tool.
>>
>> In fact, we're seeing 200/TCP_MISS_ABORTED codes for content larger 
>> than around 100kb.
>>
>> When content sizes are smaller, the expected behaviour occurs and data 
>> is returned from the cache.
>>
>> On the client side, for content larger than 100kb :
>>
>> ? * squid 5 returns x-cache = ?MISS? and x-cache-lookup = ?HIT?.
>> ? * squid 6 returns cache-status = ?url;detail=match?, which is
>> ??? equivalent if my understanding is correct.
>>
>> We first thought it might be linked to the following bug: 
>> _https://bugs.squid-cache.org/show_bug.cgi?id=5214 
>> <https://bugs.squid-cache.org/show_bug.cgi?id=5214>_, which encouraged 
>> us to try version 6, but without success.
>>
>> ? * Is it a configuration problem that we missed?
>> ? * Can you help us ?
>>
>> HTTP client-side headers returned by squid 6 :
>>
>> //
>>
>> /[2025-01-14T08:46:49.875] [TRACE] default - [0/1] getContentStream 
>> (user) header: {/
>>
>> /? "date": "Tue, 14 Jan 2025 05:47:30 GMT",/
>>
>> /? "server": "Apache-Chemistry-OpenCMIS/1.2.0_1859862-XXXXX-1",/
>>
>> /? "strict-transport-security": "max-age=15768000",/
>>
>> /"x-xss-protection": "1; mode=block",/
>>
>> ///"x-frame-options": "SAMEORIGIN",/
>>
>> /? "x-content-type-options": "nosniff",/
>>
>> /? "access-control-allow-origin": "*",/
>>
>> /? "access-control-expose-headers": "Content-Disposition",/
>>
>> /? "cache-control": "public, s-maxage=3600, must-revalidate",/
>>
>> /? "etag": 
>> "\"08bd240128b475722db82d36c7ae7f164c37cab4ad2480abae052875fe7bc3bfdfef9996197d40110a13208d39a3db3a789879bc31803c82f25211eeba505455\"",/
>>
>> /? "content-disposition": "inline; filename=FILENAME.jpg",/
>>
>> /? "content-type": "image/jpeg",/
>>
>> /? "content-length": "2069587",/
>>
>> /? "content-security-policy": "default-src 'none'; connect-src 'self'; 
>> font-src 'self' fonts.gstatic.com; img-src blob: 'self'; script-src 
>> 'self' 'unsafe-eval' 'unsafe-inline'; style-src 'self' 'unsafe-inline' 
>> fonts.googleapis.com",/
>>
>> */? "cache-status": "sv-infra-pxy4;detail=match",/*
>>
>> */"via": "1.1 sv-infra-pxy4 (squid/6.10)",/*
>>
>> ///"connection": "close"/
>>
>> /}/
>>
>> /[2025-01-14T08:46:49.875] [INFO] default - [0/1][2] getCS 
>> oId:'369926' sId:*'80669'*name:' filename= FILENAME.jpg' 
>> type:'image/jpeg' size:*'2021.08ko'*res:[via:true hit:false length:true]/
>>
>> //
>>
>> //
>>
>> squid 6 acces.log extract:
>>
>> //
>>
>> //
>>
>> //
>>
>> full server configuration file :
>>
>> //
>>
>> /acl localnet src 0.0.0.1-0.255.255.255??????? # RFC 1122 "this" 
>> network (LAN)/
>>
>> /acl localnet src 10.0.0.0/8?????????????????? # RFC 1918 local 
>> private network (LAN)/
>>
>> /acl localnet src 100.64.0.0/10?????????????????????????? # RFC 6598 
>> shared address space (CGN)/
>>
>> /acl localnet src 169.254.0.0/16 ?????? # RFC 3927 link-local 
>> (directly plugged) machines/
>>
>> /acl localnet src 172.16.0.0/12?????????????????????????? # RFC 1918 
>> local private network (LAN)/
>>
>> /acl localnet src 192.168.0.0/16??????????????????????? # RFC 1918 
>> local private network (LAN)/
>>
>> /acl localnet src fc00::/7?????? ? # RFC 4193 local private network 
>> range/
>>
>> /acl localnet src fe80::/10????? # RFC 4291 link-local (directly 
>> plugged) machines/
>>
>> //
>>
>> /acl SSL_ports port 443/
>>
>> /acl Safe_ports port 80????????????????????????????? # http/
>>
>> /acl Safe_ports port 21????????????????????????????? # ftp/
>>
>> /acl Safe_ports port 443?????????????????????????? # https/
>>
>> /acl Safe_ports port 70????????????????????????????? # gopher/
>>
>> /acl Safe_ports port 210?????????????????????????? # wais/
>>
>> /acl Safe_ports port 1025-65535?????? # unregistered ports/
>>
>> /acl Safe_ports port 280?????????????????????????? # http-mgmt/
>>
>> /acl Safe_ports port 488?????????????????????????? # gss-http/
>>
>> /acl Safe_ports port 591?????????????????????????? # filemaker/
>>
>> /acl Safe_ports port 777?????????????????????????? # multiling http/
>>
>> //
>>
>> /#ACL pour SmartGED/
>>
>> /acl smartged-mime req_mime_type -i ^image/jpeg$/
>>
>> /acl smartged-mime req_mime_type -i ^image/png$/
>>
>> /acl smartged-mime req_mime_type -i ^application/pdf$/
>>
>> /acl smartged-mime req_mime_type -i ^application/json$/
>>
>> //
>>
>> /acl intermediate_fetching transaction_initiator certificate-fetching/
>>
>> //
>>
>> /http_access deny !Safe_ports/
>>
>> /http_access deny CONNECT !SSL_ports/
>>
>> //
>>
>> /# Only allow cachemgr access from localhost/
>>
>> /http_access allow localhost manager/
>>
>> /http_access deny manager/
>>
>> /http_access allow localnet/
>>
>> /http_access deny all/
>>
>> //
>>
>> /logformat toto %{%d/%b/%Y:%H:%M:%S}tl.%tu %>a %rm %03Hs/%Ss %6tr %ru 
>> %mt/
>>
>> //
>>
>> /access_log /var/log/squid/access.log toto/
>>
>> //
>>
>> /http_port 3128? ssl-bump generate-host-certificates=on 
>> dynamic_cert_mem_cache_size=4MB tls-cert=/etc/squid/ssl_cert/xxxx_.pem 
>> tls-key=/etc/squid/ssl_cert/xxxx_.key 
>> tls-dh=/etc/squid/ssl_cert/dhparam.pem/
>>
>> /tls_outgoing_options 
>> cipher=ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384/
>>
>> /sslcrtd_program /usr/lib/squid/security_file_certgen -s 
>> /var/spool/squid/ssl_db -M 20MB/
>>
>> /sslcrtd_children 5/
>>
>> /ssl_bump server-first all/
>>
>> /ssl_bump splice all/
>>
>> /sslproxy_cert_error allow all/
>>
>> //
>>
>> /# ACL deny pour les fichiers javascript/
>>
>> /acl denyjs urlpath_regex \.js/
>>
>> /# ok deny all requests above/
>>
>> /cache deny denyjs/
>>
>> //
>>
>> /# Leave coredumps in the first cache dir/
>>
>> /coredump_dir /cache1/squid/
>>
>> //
>>
>> /# Affichage des requetes GET completes dans cache.log/
>>
>> /strip_query_terms off/
>>
>> //
>>
>> /cache_mem 20480 MB/
>>
>> /# d?but d'?viction du cache/
>>
>> /cache_swap_low 50/
>>
>> /# aggressivit? maximal de l'algorithme d'?viction du cache/
>>
>> /cache_swap_high 80/
>>
>> /# The LRU policies keeps recently referenced objects./
>>
>> /cache_replacement_policy lru/
>>
>> //
>>
>> /#/
>>
>> /# Add any of your own refresh_pattern entries above these./
>>
>> /#/
>>
>> /refresh_pattern ^ftp:??????????????? 1440??? 20%???? 10080/
>>
>> /refresh_pattern -i (/cgi-bin/|\?) 0?????? 0%??????? 0/
>>
>> /refresh_pattern .????????????????????????? 0???????????? 20%???? 4320/
>>
>> //
>>
>> /ftp_user _anonymous at xxx.fr <mailto:anonymous at xxx.fr>_/
>>
>> /#acl QUERY urlpath_regex cgi-bin \?/
>>
>> /#no_cache deny QUERY/
>>
>> /client_request_buffer_max_size 10240 KB/
>>
>> /maximum_object_size 1024 MB/
>>
>> /# to keep object in memory cache/
>>
>> /maximum_object_size_in_memory 10240 KB/
>>
>> /#to cause Squid to prefetch the whole file/
>>
>> /range_offset_limit 16 MB/
>>
>> /#quick_abort_min -1/
>>
>> /#D?finition de la taille maximum d'un en-t?te HTTP lors d'une requ?te/
>>
>> /reply_header_max_size 8192 KB/
>>
>> /#taille maximum d'un en-t?te de r?ponse HTTP/
>>
>> /reply_header_max_size 8192 KB/
>>
>> //
>>
>> /# Uncomment and adjust the following to add a disk cache directory./
>>
>> /cache_dir aufs /cache1/squid 1024000 16 256 max-size=16777216/
>>
>> //
>>
>> //
>>
>> /error_directory /usr/share/squid/errors/fr/
>>
>> /half_closed_clients off/
>>
>> /max_filedescriptors 8192/
>>
>> /forward_max_tries 50/
>>
>> //
>>
>> /#Affichage du store-id/
>>
>> /cache_store_log daemon:/var/log/squid/store_daemon.log/
>>
>> /cache_store_log stdio:/var/log/squid/store_stdio.log/
>>
>> /#debug_options "ALL,3 33,7 47,7 61,7 85,7"/
>>
>> /# Log all critical and important messages./
>>
>> /#debug_options ALL,1/
>>
>> /debug_options ALL,3/
>>
>> //
>>
>> /# Enable SQUID's SNMP/
>>
>> /snmp_port 3401/
>>
>> /acl snmppublic snmp_community PASdePUBLIC/
>>
>> /snmp_access allow snmppublic all/
>>
>> Best regards,
>>
>> *Thomas PALFRAY*
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Wed Feb 26 05:43:04 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Feb 2025 18:43:04 +1300
Subject: [squid-users] Clients Header User-Agent replace?
In-Reply-To: <zUOQDX3qr6uUCGJd8o11UaThl2WB2OZkXa11yZu7n5e1M2zwCy5xlxyT_WwQg2gR9GWSyjG83xYZXDRxMo4fyg-ocIM53QlfLW4opfe9Omg=@proton.me>
References: <zUOQDX3qr6uUCGJd8o11UaThl2WB2OZkXa11yZu7n5e1M2zwCy5xlxyT_WwQg2gR9GWSyjG83xYZXDRxMo4fyg-ocIM53QlfLW4opfe9Omg=@proton.me>
Message-ID: <c29bb64a-7c17-4cb3-ba6e-a3b4d3dbef03@treenet.co.nz>

On 25/02/25 23:59, Foxy Lady wrote:
> Hi all.
> Can't figure out how to remove original clients UA from calls.
> Tried out something like,
> 
> #USER AGENT
> header_access Allow allow all
> header_access Authorization allow all
> header_access Cache-Control allow all
> header_access Content-Encoding allow all
> header_access Content-Length allow all
> header_access Content-Type allow all
> header_access Date allow all
> header_access Expires allow all
> header_access Host allow all
> header_access If-Modified-Since allow all
> header_access Last-Modified allow all
> header_access Location allow all
> header_access Pragma allow all
> header_access Accept allow all
> header_access Accept-Enncoding allow all
> header_access Accept-Language allow all
> header_access Content-Language allow all
> header_access Mime-Version allow all
> header_access Cookie allow all
> header_access Set_Cookie allow all
> header_access Retry-After allow all
> header_access Title allow all
> header_access Connection allow all
> header_access Proxy-Connection allow all


FYI, the directive "header_access" is deprecated, typos in the header 
names, and you don't have anything forbidden for these rules to re-allow.
    In short, those rules appear to be doing nothing.


> request_header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)
> header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)
> 

You first have to prevent the clients header from being allowed, then 
provide the replacement. Like so;


  request_header_access User-Agent deny all
  request_header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)


Cheers
Amos

From squid3 at treenet.co.nz  Wed Feb 26 06:58:53 2025
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Feb 2025 19:58:53 +1300
Subject: [squid-users] Need clarifications on custom log timestamps
In-Reply-To: <CAPUgoGtZPb3rpufJDrxKpFr6KL9MAEY_dprxTx-UufqUmFs6oQ@mail.gmail.com>
References: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
 <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>
 <CAPUgoGtWGNSmiji5ObB8Af-oZTabBR3XD0bK2wENwZk8=LPtbg@mail.gmail.com>
 <c6adf5db-11e2-456c-9df1-1e1ac3072f9a@measurement-factory.com>
 <CAPUgoGtZPb3rpufJDrxKpFr6KL9MAEY_dprxTx-UufqUmFs6oQ@mail.gmail.com>
Message-ID: <583cac24-900d-4638-84fa-8c12a25d55ab@treenet.co.nz>

On 26/02/25 00:33, BENJAMIN DELANNOY wrote:
>  > Please detail what you mean by "choice" or "decision". For example, do
>> you want to stop the timer when Squid makes its final http_access decision?
> 
> I mean I want to monitor the latency on what I could manage : the 
> communication between client & squid, the time squid uses to process 
> requests. But not the time spent by the destination server as I don't 
> manage it.
> This could be multiple monitors if 1 is too complicated or not possible. 
> So yes for example a timer that stop when Squid makes its 
> final?http_access decision (in case of http or bumped https) or its 
> final ssl_bump splice decision.
> 

In theory what you want is the %busy_time logformat.

However, the calculations for that are still apparently inaccurate. So 
you would be best also logging these for comparison measures:

  %dt = DNS latency

  %<tt - %<pt = forwarding-latency
     .. the time spent by Squid fetching the response.
     .. excluding time waiting for it to arrive from the upstream server
     .. also excluding anything that happens while the server is 
delivering response (eg. for responses >4KB).

  %tr - %<pt = total Squid latency
     .. including delays from parallel traffic
     .. excluding same as forwarding-latency above


HTH
Amos


From Foxy_Lady_1966 at proton.me  Wed Feb 26 10:02:00 2025
From: Foxy_Lady_1966 at proton.me (Foxy Lady)
Date: Wed, 26 Feb 2025 10:02:00 +0000
Subject: [squid-users] Clients Header User-Agent replace?
In-Reply-To: <c29bb64a-7c17-4cb3-ba6e-a3b4d3dbef03@treenet.co.nz>
References: <zUOQDX3qr6uUCGJd8o11UaThl2WB2OZkXa11yZu7n5e1M2zwCy5xlxyT_WwQg2gR9GWSyjG83xYZXDRxMo4fyg-ocIM53QlfLW4opfe9Omg=@proton.me>
 <c29bb64a-7c17-4cb3-ba6e-a3b4d3dbef03@treenet.co.nz>
Message-ID: <lEAcD1s47B9BG564bS2-5-Ey4mkbE1xrPbc7XAT6mYRA0cRIAb-Dnw1GOEO1DWIlLmVywR7pg5mlEmBVnt93nssTRCOudfLwAhnBzUHNg0o=@proton.me>

Perfectly works.

While Squid logs the original UA, remote webserver receives the modified one,

x.x.x.x my.domain.com my.domain.com [TLSv1.3] - - [26/Feb/2025:10:58:41 +0100] "GET / HTTP/1.1" [301] 357 0 19 19361 "-" "Mozilla/5.0 (Personal-Test_DevOPS)"

Sorry for my old documentation!

Many thanks!!!


Inviato con l'email sicura Proton Mail.

mercoled? 26 febbraio 2025 06:43, Amos Jeffries <squid3 at treenet.co.nz> ha scritto:

> On 25/02/25 23:59, Foxy Lady wrote:
> 
> > Hi all.
> > Can't figure out how to remove original clients UA from calls.
> > Tried out something like,
> > 
> > #USER AGENT
> > header_access Allow allow all
> > header_access Authorization allow all
> > header_access Cache-Control allow all
> > header_access Content-Encoding allow all
> > header_access Content-Length allow all
> > header_access Content-Type allow all
> > header_access Date allow all
> > header_access Expires allow all
> > header_access Host allow all
> > header_access If-Modified-Since allow all
> > header_access Last-Modified allow all
> > header_access Location allow all
> > header_access Pragma allow all
> > header_access Accept allow all
> > header_access Accept-Enncoding allow all
> > header_access Accept-Language allow all
> > header_access Content-Language allow all
> > header_access Mime-Version allow all
> > header_access Cookie allow all
> > header_access Set_Cookie allow all
> > header_access Retry-After allow all
> > header_access Title allow all
> > header_access Connection allow all
> > header_access Proxy-Connection allow all
> 
> 
> 
> FYI, the directive "header_access" is deprecated, typos in the header
> names, and you don't have anything forbidden for these rules to re-allow.
> In short, those rules appear to be doing nothing.
> 
> > request_header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)
> > header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)
> 
> 
> You first have to prevent the clients header from being allowed, then
> provide the replacement. Like so;
> 
> 
> request_header_access User-Agent deny all
> request_header_replace User-Agent Mozilla/5.0 (Personal-Test_DevOPS)
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

From uhlar at fantomas.sk  Wed Feb 26 12:05:41 2025
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 26 Feb 2025 13:05:41 +0100
Subject: [squid-users] disable/block ipv6 requests
Message-ID: <Z78DlZHsY8S-E1d7@fantomas.sk>

Hello,

I maintain a few servers that currently do not have IPv6 connectivity.

Until we fix this, I'd like squid to avoid considering using ipv6, 
because even if any ipv6 attempt failed, there still were some being made
... at least I assume so from squid logs:

1740062747.503      0 192.0.2.1 NONE_NONE/503 0 CONNECT ad.turn.com:443 - HIER_DIRECT/2001:678:cb4:bbbb::11 -

As I understand it, I can build squid without ipv6 support. 
Is there any other way to disable outgoing ipv6 communication?


 From what I read in archives using "acl" makes no sense, as it decides 
whether to block request or not:
https://marc.info/?l=squid-users&m=168180685516039&w=2

...and the directive dns_v4_first is long obsolete:
https://marc.info/?l=squid-users&m=168181162219573&w=2


What I have tried:

1. disabling ipv6 by setting (linux) 
net.ipv6.conf.all.disable_ipv6=1

but in logs squid complains:

2025/02/24 00:00:10| WARNING: BCP 177 violation. Detected non-functional IPv6 loopback.

2. reboot linux kernel with option "ipv6.disable=1"

(at least the ipv6 attempts stopped)

After either of last two attempts, squid seems to crash too often. 

#4  0x00007f028a174eb2 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6
#5  0x0000564f2a77e824 in Ip::Address::getAddrInfo(addrinfo*&, int) const ()

I have squid 5.7 on Debian 12

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
I'm not interested in your website anymore.
If you need cookies, bake them yourself.

From lists at compuniverse.de  Wed Feb 26 13:27:16 2025
From: lists at compuniverse.de (Amon Ott)
Date: Wed, 26 Feb 2025 14:27:16 +0100
Subject: [squid-users] disable/block ipv6 requests
In-Reply-To: <Z78DlZHsY8S-E1d7@fantomas.sk>
References: <Z78DlZHsY8S-E1d7@fantomas.sk>
Message-ID: <d459d0ca-4d3d-493e-a897-03bee548a172@compuniverse.de>

Am 26.02.25 um 13:05 schrieb Matus UHLAR - fantomas:
> As I understand it, I can build squid without ipv6 support. Is there any 
> other way to disable outgoing ipv6 communication?

Try tcp_outgoing_address 0.0.0.0

Amon Ott
-- 
Dr. Amon Ott
m-privacy GmbH           Tel: +49 30 24342334
Werner-Vo?-Damm 62       Fax: +49 30 99296856
12101 Berlin             http://www.m-privacy.de

Amtsgericht Charlottenburg, HRB 84946

Gesch?ftsf?hrer:
  Dipl.-Kfm. Holger Maczkowsky,
  Roman Maczkowsky

GnuPG-Key-ID: 0x2DD3A649


From uhlar at fantomas.sk  Wed Feb 26 13:44:49 2025
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 26 Feb 2025 14:44:49 +0100
Subject: [squid-users] disable/block ipv6 requests
In-Reply-To: <d459d0ca-4d3d-493e-a897-03bee548a172@compuniverse.de>
References: <Z78DlZHsY8S-E1d7@fantomas.sk>
 <d459d0ca-4d3d-493e-a897-03bee548a172@compuniverse.de>
Message-ID: <Z78a0XQtMWx3rmVB@fantomas.sk>

>Am 26.02.25 um 13:05 schrieb Matus UHLAR - fantomas:
>>As I understand it, I can build squid without ipv6 support. Is there 
>>any other way to disable outgoing ipv6 communication?

On 26.02.25 14:27, Amon Ott wrote:
>Try tcp_outgoing_address 0.0.0.0

according to:
https://marc.info/?l=squid-users&m=154843206109164&w=2

it's only applied for ipv4, so it wouldn't help either

and I think I forgot to link to this thread before

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
M$ Win's are shit, do not use it !

From codemarauder at gmail.com  Wed Feb 26 14:17:20 2025
From: codemarauder at gmail.com (Nishant Sharma)
Date: Wed, 26 Feb 2025 14:17:20 +0000
Subject: [squid-users] disable/block ipv6 requests
In-Reply-To: <Z78a0XQtMWx3rmVB@fantomas.sk>
References: <Z78DlZHsY8S-E1d7@fantomas.sk>
 <d459d0ca-4d3d-493e-a897-03bee548a172@compuniverse.de>
 <Z78a0XQtMWx3rmVB@fantomas.sk>
Message-ID: <F9F2D9D7-35D0-449B-8DE8-DBBD312E334A@gmail.com>



On 26 February 2025 1:44:49?pm UTC, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>> Am 26.02.25 um 13:05 schrieb Matus UHLAR - fantomas:
>>> As I understand it, I can build squid without ipv6 support. Is there any other way to disable outgoing ipv6 communication?

You may want to disable AAAA replies from your DNS server. 

Dnsmasq has the option to filter AAAA responses. And if squid doesn't get IPv6 address, it won't try to connect to IPv6.

Regards,
Nishant

From jonathanlee571 at gmail.com  Wed Feb 26 14:27:11 2025
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 26 Feb 2025 06:27:11 -0800
Subject: [squid-users] disable/block ipv6 requests
In-Reply-To: <F9F2D9D7-35D0-449B-8DE8-DBBD312E334A@gmail.com>
References: <F9F2D9D7-35D0-449B-8DE8-DBBD312E334A@gmail.com>
Message-ID: <B29B0A98-0E97-4655-9A44-C4C13CD4963F@gmail.com>

Try this too
acl to_ipv6 dst ipv6
acl from_ipv6 dst ipv6

After just block it with another acl like ? 
http_access deny to_ipv6
http_access deny from_ipv6

Sent from my iPhone

> On Feb 26, 2025, at 06:17, Nishant Sharma <codemarauder at gmail.com> wrote:
> 
> ?
> 
> On 26 February 2025 1:44:49?pm UTC, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>>> Am 26.02.25 um 13:05 schrieb Matus UHLAR - fantomas:
>>>> As I understand it, I can build squid without ipv6 support. Is there any other way to disable outgoing ipv6 communication?
> 
> You may want to disable AAAA replies from your DNS server.
> 
> Dnsmasq has the option to filter AAAA responses. And if squid doesn't get IPv6 address, it won't try to connect to IPv6.
> 
> Regards,
> Nishant
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

From rousskov at measurement-factory.com  Wed Feb 26 14:42:55 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 26 Feb 2025 09:42:55 -0500
Subject: [squid-users] disable/block ipv6 requests
In-Reply-To: <Z78DlZHsY8S-E1d7@fantomas.sk>
References: <Z78DlZHsY8S-E1d7@fantomas.sk>
Message-ID: <bf7d2662-7acb-44b0-8be1-ddeeac9acdd0@measurement-factory.com>

On 2025-02-26 07:05, Matus UHLAR - fantomas wrote:

> I'd like squid to avoid considering using ipv6, 
> because even if any ipv6 attempt failed, there still were some being made
> ... at least I assume so from squid logs:
> 
> 1740062747.503????? 0 192.0.2.1 NONE_NONE/503 0 CONNECT ad.turn.com:443 
> - HIER_DIRECT/2001:678:cb4:bbbb::11 -
> 
> As I understand it, I can build squid without ipv6 support. Is there any 
> other way to disable outgoing ipv6 communication?

Yes, for some definition of "ipv6 communication". Modern Squids[1] 
should not open connections to IPv6 addresses after deciding (at 
startup) that IPv6 is not supported. When that "not supported" decision 
is made, you should get a level-0 "BCP 177 violation" WARNING in 
cache.log. Unfortunately, that diagnostics is not provided for some use 
cases.

[1] Here, "modern Squids" are Squids with a Bug 5154 fix (e.g., v5.10, 
v6.13, and v7.0.1; see master commit 97bbba61 for details).


>  From what I read in archives using "acl" makes no sense, as it decides 
> whether to block request or not

Using http_access to block requests to IPv6 addresses makes sense in 
some cases, but it is difficult to get right, and it cannot cover all 
use cases, so I would not recommend that solution in most cases.


> ...and the directive dns_v4_first is long obsolete

Correct. It is ignored (with a warning).


> What I have tried:
> 
> 1. disabling ipv6 by setting (linux) net.ipv6.conf.all.disable_ipv6=1
> 
> but in logs squid complains:
> 
> 2025/02/24 00:00:10| WARNING: BCP 177 violation. Detected non-functional 
> IPv6 loopback.

This warning is a positive sign for your use case: Modern Squids[1] 
should not open connections to IPv6 addresses after the above warning.


> 2. reboot linux kernel with option "ipv6.disable=1"
> 
> (at least the ipv6 attempts stopped)

I have not checked, but I am guessing that this OS configuration results 
in the same overall outcome as net.ipv6.conf.all.disable_ipv6=1 but 
without a BCP 177 violation warning at level-1. Check level-2 cache.log 
for an "IPv6 not supported on this machine. Auto-Disabled" line. If that 
line is there, Squid has disabled IPv6 use just like it does when 
printing BCP 177 warning.


> After either of last two attempts, squid seems to crash too often.
> #5? 0x0000564f2a77e824 in Ip::Address::getAddrInfo(addrinfo*&, int) 

Your old Squid is suffering from Bug 5154 (at least):
https://bugs.squid-cache.org/show_bug.cgi?id=5154


> I have squid 5.7 on Debian 12

Consider upgrading to a modern Squid[1].


HTH,

Alex.


From rousskov at measurement-factory.com  Wed Feb 26 16:06:35 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 26 Feb 2025 11:06:35 -0500
Subject: [squid-users] Need clarifications on custom log timestamps
In-Reply-To: <CAPUgoGtZPb3rpufJDrxKpFr6KL9MAEY_dprxTx-UufqUmFs6oQ@mail.gmail.com>
References: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
 <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>
 <CAPUgoGtWGNSmiji5ObB8Af-oZTabBR3XD0bK2wENwZk8=LPtbg@mail.gmail.com>
 <c6adf5db-11e2-456c-9df1-1e1ac3072f9a@measurement-factory.com>
 <CAPUgoGtZPb3rpufJDrxKpFr6KL9MAEY_dprxTx-UufqUmFs6oQ@mail.gmail.com>
Message-ID: <18d7623a-dd1f-444a-b08c-3e3c6b7f1e70@measurement-factory.com>

On 2025-02-25 06:33, BENJAMIN DELANNOY wrote:
>  > Please detail what you mean by "choice" or "decision". For example, do
>> you want to stop the timer when Squid makes its final http_access decision?
> 
> I want to monitor the latency on what I could manage : the 
> communication between client & squid, the time squid uses to process 
> requests. But not the time spent by the destination server as I don't 
> manage it.


Just to clarify why I keep asking about specifics: I believe I 
understand your overall goals, but to offer a specific solution, those 
high-level goals needs to be distilled into something Squid can measure.


> This could be multiple monitors if 1 is too complicated or not possible. 
> So yes for example a timer that stop when Squid makes its 
> final?http_access decision (in case of http or bumped https) or its 
> final ssl_bump splice decision.

Today, Squid does not record the time when those events happen, but 
there is work in progress to add the necessary framework. You can 
approximate those times by appending an external always-matching ACL 
(that would report current time in the form of transaction annotation 
that can be logged). Here is a rough sketch for http_access case:

     # external ACL that returns access_decision_time_=time annotation
     external_acl_type AccessDecisionTimeRecorder ...
     acl recordAccessDecisionTime external AccessDecisionTimeRecorder

     # recordAccessDecisionTime appended to all http_access rules
     http_access allow ... recordAccessDecisionTime
     http_access deny all recordAccessDecisionTime

     logformat myAccessLogRecordFormat ... %note{access_decision_time_}
     access_log ... logformat=myAccessLogRecordFormat

The same approach can be used for ssl_bump rules.

However, this is not pretty (i.e. this workaround is clearly bad UX), 
and I the precision of that solution may not be high enough for your 
needs (external ACLs will add at least a few milliseconds of delays). We 
need to (and will) do better!

https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squid-feature-enhance-of-fix-something


HTH,

Alex.



> On Wed, Feb 19, 2025 at 5:39?PM Alex Rousskov wrote:
> 
>     On 2025-02-19 06:26, BENJAMIN DELANNOY wrote:
> 
>      > For %<pt : "The timer starts when the last request byte is sent
>     to the
>      > next hop and stops when the last response byte is received."? Are we
>      > talking of last request / last response of a single TCP
>     connection on
>      > server side ?
> 
>     I believe the short answer is "no": If Squid uses multiple TCP
>     Squid-peer connections to forward a single client request, then the
>     last
>     connection used for that request forwarding should determine overall
>     transaction outcome and %<pt values in access.log.
> 
> 
>      > Do we agree that we are purely talking about
>      > request/response on HTTP, and thus this time does not take into
>     account
>      > the time spent with SSL negotiation?/ squid actions before ?
> 
>     I believe the short answer is "yes": Today, %<pt timer starts after the
>     HTTP (or FTP) request is written to the peer, so TLS handshake (if any)
>     would happen before that timer starts. AFAIK, Squid does not support
>     0-RTT TLS.
> 
> 
>      > For %<tt : I understand that all the time spent?sending?requests &
>      > waiting responses from the Origin are added. It would also means
>     that if
>      > I subtract this timer to %tr, I would have only the ClientSide time
>      > before first packet is sent to Origin by the squid & after the last
>      > packet is received from the Origin ?
> 
>     Yes, but "before" and "after" can be misleading here (in general)
>     because there may be periods of time when Squid is _not_ talking to a
>     peer but is working on what you call "ClientSide". For example,
>     there is
>     code that decides whether to revalidate a received peer response. From
>     Squid point of view, that code runs on "ClientSide" -- %<tt timers may
>     be stopped when that code runs. Since you are not caching, that
>     particular code is not relevant to you.
> 
>     Also, please keep in mind that a slow client may effectively stall
>     Squid-to-peer I/O by not consuming response data fast enough, filling
>     Squid response buffers (see read_ahead_gap). If one only looks at
>     "%tr -
>     %<tt" difference in such cases, one would observe near-0 values and may
>     mistakenly conclude that the slow client is super fast!
> 
> 
> 
>      > Actually, what I want?to monitor, is the time between the first
>     client
>      > packet received on the Squid and the time the squid makes its
>     choice :
>      > - based on SNI for SSL Splice
>      > - based on HTTP ACL (HTTP traffic or HTTPS traffic with SSL Bump)
>      > Based on this, I would be able to check if a squid server is
>     taking too
>      > much time making a decision.
>      >
>      > Is this something feasible?
> 
>     Please detail what you mean by "choice" or "decision". For example, do
>     you want to stop the timer when Squid makes its final http_access
>     decision?
> 
> 
>     Thank you,
> 
>     Alex.
> 
> 
>      > On Mon, Feb 17, 2025 at 4:47?PM Alex Rousskov wrote:
>      >
>      >? ? ?On 2025-02-17 10:02, BENJAMIN DELANNOY wrote:
>      >
>      >? ? ? > I try to figure out what is exactly measured with the <pt
>     & <tt
>      >? ? ?timings.
>      >? ? ? > I don't get what are the difference between them, what is the
>      >? ? ?difference
>      >? ? ? > between "peer response time" & "time spent forwarding to
>     origin
>      >? ? ? > servers",
>      >
>      >? ? ?Have you seen %<pt and %<tt descriptions at [1]? %<tt
>     description was
>      >? ? ?updated in August 2024, and squid.conf.documented in Squid v6 and
>      >? ? ?earlier does not have those documentation updates (and the
>      >? ? ?corresponding
>      >? ? ?bug fixes)...
>      >
>      >? ? ?[1] http://www.squid-cache.org/Doc/config/logformat/
>     <http://www.squid-cache.org/Doc/config/logformat/>
>      >? ? ?<http://www.squid-cache.org/Doc/config/logformat/
>     <http://www.squid-cache.org/Doc/config/logformat/>>
>      >
>      >
>      >? ? ? > what is the "last I/O with the last peer", etc.
>      >
>      >? ? ?When forwarding a single client request, Squid may talk to
>     multiple
>      >? ? ?cache_peer and origin server addresses (collectively called
>     "peers").
>      >? ? ?Talking to a given peer may include multiple socket reading
>     and writing
>      >? ? ?(i.e. I/O) events. Does this clarify?
>      >
>      >
>      >
>      >? ? ? > For information, I aim to calculate the time spent on the
>      >? ? ?client-side &
>      >? ? ? > by squid processing time,? excluding the server-side time
>     spent
>      >? ? ?(=what I
>      >? ? ? > don't manage).
>      >
>      >? ? ?This kind of calculation is a common need. Please keep in
>     mind that
>      >? ? ?Squid may spend time on the client side (e.g., awaiting the next
>      >? ? ?request
>      >? ? ?body byte) while also spending time on the server side (e.g.,
>     awaiting
>      >? ? ?the next response body byte), complicating things.
>      >
>      >? ? ?If existing %codes are not enough, please detail your needs
>     in terms of
>      >? ? ?events that Squid can recognize (e.g., receiving the first
>     response
>      >? ? ?header byte or sending the last request body byte).
>      >
>      >
>      >? ? ?HTH,
>      >
>      >? ? ?Alex.
>      >
>      >
>      >
>      >
>      >? ? ? > We do not use squid for caching but only for http & ssl
>      >? ? ?proxy/filtering.
>      >? ? ? >
>      >? ? ? > Thanks a lot !
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > Cordialement, Regards,
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > Benjamin DELANNOY
>      >? ? ? >
>      >? ? ? > Cloud Network Engineer
>      >? ? ? >
>      >? ? ? > NETWORK SOLUTIONS - GTDP
>      >? ? ? >
>      >? ? ? > Mobile +33 (0)6 16 98 23 72
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > 135 rue Sadi Carnot ? CS 00001 ? 59790 Ronchin ? FRANCE
>      >? ? ? >
>      >? ? ? > positivetech.adeo.com <http://positivetech.adeo.com>
>     <http://positivetech.adeo.com <http://positivetech.adeo.com>>
>      >? ? ?<https://positivetech.adeo.com/
>     <https://positivetech.adeo.com/> <https://positivetech.adeo.com/
>     <https://positivetech.adeo.com/>>>
>      >? ? ? >
>      >? ? ? > adeolinkedin <https://www.linkedin.com/company/groupe-adeo
>     <https://www.linkedin.com/company/groupe-adeo>
>      >? ? ?<https://www.linkedin.com/company/groupe-adeo
>     <https://www.linkedin.com/company/groupe-adeo>>>
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > _______________________________________________
>      >? ? ? > squid-users mailing list
>      >? ? ? > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >? ? ?<mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >? ? ? > https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >? ? ?<https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >
>      >? ? ?_______________________________________________
>      >? ? ?squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >? ? ?<mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      > https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >? ? ?<https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >
> 


From rousskov at measurement-factory.com  Wed Feb 26 16:14:56 2025
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 26 Feb 2025 11:14:56 -0500
Subject: [squid-users] Need clarifications on custom log timestamps
In-Reply-To: <583cac24-900d-4638-84fa-8c12a25d55ab@treenet.co.nz>
References: <CAPUgoGsE3Dy-kqo7-KPB+-xn-EDhxrmm=93S_bGfvQE43A7HwA@mail.gmail.com>
 <ed9ef166-2248-4bd2-a86f-a01448789700@measurement-factory.com>
 <CAPUgoGtWGNSmiji5ObB8Af-oZTabBR3XD0bK2wENwZk8=LPtbg@mail.gmail.com>
 <c6adf5db-11e2-456c-9df1-1e1ac3072f9a@measurement-factory.com>
 <CAPUgoGtZPb3rpufJDrxKpFr6KL9MAEY_dprxTx-UufqUmFs6oQ@mail.gmail.com>
 <583cac24-900d-4638-84fa-8c12a25d55ab@treenet.co.nz>
Message-ID: <97aa91cc-2bef-4270-a629-c7edf8dceec6@measurement-factory.com>

On 2025-02-26 01:58, Amos Jeffries wrote:
> On 26/02/25 00:33, BENJAMIN DELANNOY wrote:
>> ?> Please detail what you mean by "choice" or "decision". For example, do
>>> you want to stop the timer when Squid makes its final http_access 
>>> decision?
>>
>> I mean I want to monitor the latency on what I could manage : the 
>> communication between client & squid, the time squid uses to process 
>> requests. But not the time spent by the destination server as I don't 
>> manage it.
>> This could be multiple monitors if 1 is too complicated or not 
>> possible. So yes for example a timer that stop when Squid makes its 
>> final?http_access decision (in case of http or bumped https) or its 
>> final ssl_bump splice decision.
>>
> 
> In theory what you want is the %busy_time logformat.

Please note that %busy_time

* includes the time spent on origin server-driven work (which Benjamin 
may want to _exclude_) and

* excludes the time spent waiting for client I/O (which Benjamin may 
want to _include_).

Alex.


> However, the calculations for that are still apparently inaccurate. So 
> you would be best also logging these for comparison measures:
> 
>  ?%dt = DNS latency
> 
>  ?%<tt - %<pt = forwarding-latency
>  ??? .. the time spent by Squid fetching the response.
>  ??? .. excluding time waiting for it to arrive from the upstream server
>  ??? .. also excluding anything that happens while the server is 
> delivering response (eg. for responses >4KB).
> 
>  ?%tr - %<pt = total Squid latency
>  ??? .. including delays from parallel traffic
>  ??? .. excluding same as forwarding-latency above
> 
> 
> HTH
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From jonathanlee571 at gmail.com  Wed Feb 26 18:24:06 2025
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 26 Feb 2025 10:24:06 -0800
Subject: [squid-users] disable/block ipv6 requests
In-Reply-To: <B29B0A98-0E97-4655-9A44-C4C13CD4963F@gmail.com>
References: <F9F2D9D7-35D0-449B-8DE8-DBBD312E334A@gmail.com>
 <B29B0A98-0E97-4655-9A44-C4C13CD4963F@gmail.com>
Message-ID: <61895334-61E0-475B-87B1-2A2F4CC49A09@gmail.com>

You know like..

localnet deny to_ipv6
localnet deny from_ipv6

Or any acl at that point any network what ever acl you want with it.

> On Feb 26, 2025, at 06:27, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Try this too
> acl to_ipv6 dst ipv6
> acl from_ipv6 dst ipv6
> 
> After just block it with another acl like ? 
> http_access deny to_ipv6
> http_access deny from_ipv6
> 
> Sent from my iPhone
> 
>> On Feb 26, 2025, at 06:17, Nishant Sharma <codemarauder at gmail.com> wrote:
>> 
>> ?
>> 
>> On 26 February 2025 1:44:49?pm UTC, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>>>> Am 26.02.25 um 13:05 schrieb Matus UHLAR - fantomas:
>>>>> As I understand it, I can build squid without ipv6 support. Is there any other way to disable outgoing ipv6 communication?
>> 
>> You may want to disable AAAA replies from your DNS server.
>> 
>> Dnsmasq has the option to filter AAAA responses. And if squid doesn't get IPv6 address, it won't try to connect to IPv6.
>> 
>> Regards,
>> Nishant
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users


From Josh.Piana at hexcel.com  Fri Feb 28 14:54:35 2025
From: Josh.Piana at hexcel.com (Piana, Josh)
Date: Fri, 28 Feb 2025 14:54:35 +0000
Subject: [squid-users] ACL block_user List
Message-ID: <e779fd4812df49b7a72d931274bb6419@hexcel.com>

Hello,

I am attempting to setup an ACL block list based on usernames from a windows AD environment.

When I have this added to my squid.conf file, all outbound connections stop working:

acl block_user proxy_auth_regex -i "/etc/squid/block_user"
http_access deny block_user

I have also tried "!block_user".

As you can see, I have it set so if a Windows username is on the "block_user" list, Squid will deny internet access to that user. Unfortunately, this doesn't work in practice. I have a working Kerberos back-end setup, handling authentication. What am I doing wrong with this setup?

Thank you,
Josh


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20250228/657c5677/attachment.htm>

